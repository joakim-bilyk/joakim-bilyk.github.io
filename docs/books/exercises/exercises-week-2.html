<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.2 Exercises Week 2 | Exercises</title>
  <meta name="description" content="2.2 Exercises Week 2 | Exercises" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="2.2 Exercises Week 2 | Exercises" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.2 Exercises Week 2 | Exercises" />
  
  
  

<meta name="author" content="Joakim Bilyk" />


<meta name="date" content="2023-02-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="exercises-week-1.html"/>
<link rel="next" href="exercises-week-3.html"/>
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="https://code.jquery.com/jquery-1.9.1.js"></script>

<script>
    $(function() {
        var element = document.body;
        if (localStorage.chkbx && localStorage.chkbx != '') {
            $('#remember_me').attr('checked', 'checked');
            element.classList.toggle("dark-mode");
            document.querySelector('.book-header.fixed').click();
        } else {
            $('#remember_me').removeAttr('checked');
            document.querySelector('.book-header.fixed').click();
        }

        $('#remember_me').click(function() {

            if ($('#remember_me').is(':checked')) {
                // save username and password
                localStorage.chkbx = $('#remember_me').val();
                element.classList.toggle("dark-mode");
                document.querySelector('.book-header.fixed').click();
            } else {
                localStorage.chkbx = '';
                element.classList.toggle("dark-mode");
                document.querySelector('.book-header.fixed').click();
            }
        });
    });

</script>

<div class = "sticky-darkmode-toggle">
  <label class="switch">
  <input type="checkbox" value="remember-me" id="remember_me">
  <span class="slider round">
  </span>
  </label>
</div>

<script>
$(function() {
  $('body').after($('.sticky-darkmode-toggle'));
})
</script>

<style>

.sticky-darkmode-toggle {
  position: fixed;
  right: 20px;
  bottom: 20px;
}
</style>




<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Exercises</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="abbreviations.html"><a href="abbreviations.html"><i class="fa fa-check"></i><b>1.1</b> Abbreviations</a></li>
<li class="chapter" data-level="1.2" data-path="to-do-work.html"><a href="to-do-work.html"><i class="fa fa-check"></i><b>1.2</b> To-do work</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html"><i class="fa fa-check"></i><b>2</b> Continuous Time Finance</a>
<ul>
<li class="chapter" data-level="2.1" data-path="exercises-week-1.html"><a href="exercises-week-1.html"><i class="fa fa-check"></i><b>2.1</b> Exercises Week 1</a></li>
<li class="chapter" data-level="2.2" data-path="exercises-week-2.html"><a href="exercises-week-2.html"><i class="fa fa-check"></i><b>2.2</b> Exercises Week 2</a></li>
<li class="chapter" data-level="2.3" data-path="exercises-week-3.html"><a href="exercises-week-3.html"><i class="fa fa-check"></i><b>2.3</b> Exercises Week 3</a></li>
<li class="chapter" data-level="2.4" data-path="exercises-week-4.html"><a href="exercises-week-4.html"><i class="fa fa-check"></i><b>2.4</b> Exercises week 4</a></li>
<li class="chapter" data-level="2.5" data-path="exercises-week-5.html"><a href="exercises-week-5.html"><i class="fa fa-check"></i><b>2.5</b> Exercises Week 5</a></li>
<li class="chapter" data-level="2.6" data-path="exercises-week-6.html"><a href="exercises-week-6.html"><i class="fa fa-check"></i><b>2.6</b> Exercises Week 6</a></li>
<li class="chapter" data-level="2.7" data-path="exercises-week-7.html"><a href="exercises-week-7.html"><i class="fa fa-check"></i><b>2.7</b> Exercises Week 7</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html"><i class="fa fa-check"></i><b>3</b> Probabilistic Machine Learning</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://joakim-bilyk.github.io/index.html">Back to main site</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Exercises</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="exercises-week-2" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Exercises Week 2<a href="exercises-week-2.html#exercises-week-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Exercise 1</strong> <em>(Bjork 4.1)</em> Compute the stochastic differential <span class="math inline">\(dZ_t\)</span> when</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(Z_t=e^{\alpha t}\)</span>.</li>
<li><span class="math inline">\(Z_t=\int_0^t g_s\ dW_s\)</span>, where <span class="math inline">\(g\)</span> is an adapted stochastic process.</li>
<li><span class="math inline">\(Z_t=e^{\alpha W_t}\)</span>.</li>
<li><span class="math inline">\(Z_t=e^{\alpha X_t}\)</span>, where <span class="math inline">\(X\)</span> has stochastic differential <span class="math inline">\(dX_t=\mu\ dt + \sigma\ dW_t\)</span> and <span class="math inline">\(\mu,\sigma\)</span> is constants.</li>
<li><span class="math inline">\(Z_t=X_t^2\)</span>, where <span class="math inline">\(X\)</span> has stochastic differential <span class="math inline">\(dX_t=\alpha X_t\ dt+\sigma X_t\ dW_t\)</span>.</li>
</ol>
<details>
<summary>
<strong>Solution (a).</strong>
</summary>
<p>Let <span class="math inline">\(Z_t=e^{\alpha t}\)</span>, then we see that <span class="math inline">\(f(t,x)=e^{\alpha t}\)</span> and the the following relevant derivatives is</p>
<p><span class="math display">\[
\frac{\partial f}{\partial t}(t,x)=\alpha e^{\alpha t},\hspace{10pt}\frac{\partial f}{\partial x}(t,x) =0,\hspace{10pt}\frac{\partial f}{\partial x^2}(t,x) =0.
\]</span></p>
<p>Since <span class="math inline">\(Z\)</span> does not depend on any stochastic process, we will content with <span class="math inline">\(X_t=0\)</span>, that is <span class="math inline">\(\mu_t=\sigma_t=0\)</span>. Then by theorem 4.11 (Ito’s formula) we have</p>
<p><span class="math display">\[
dZ_t=\left(\alpha e^{\alpha t} +0+0\right)\ dt + 0=\alpha e^{\alpha t}\ dt,
\]</span></p>
<p>as expected. <span class="math inline">\(\square\)</span></p>
</details>
<details>
<summary>
<strong>Solution (b).</strong>
</summary>
<p>Let <span class="math inline">\(Z_t=\int_0^t g_s\ dW_s\)</span>, where <span class="math inline">\(g\)</span> is an adapted stochastic process. We see that if we set <span class="math inline">\(X_t=\int_0^t g_s\ dW_s\)</span> then</p>
<p><span class="math display">\[
dX_t=0\ dt+g_t\ dW_t.
\]</span></p>
<p>Then we have the function <span class="math inline">\(f(t,x)=x\)</span> and the relevant derivatives are:</p>
<p><span class="math display">\[
\frac{\partial f}{\partial t}(t,x)=0,\hspace{10pt}\frac{\partial f}{\partial x}(t,x) =1,\hspace{10pt}\frac{\partial f}{\partial x^2}(t,x) =0.
\]</span></p>
<p>This then gives</p>
<p><span class="math display">\[
dZ_t=\left(0+0+\frac{1}{2}g_t\cdot 0\right)\ dt + g_t\cdot 1\ dW_t=g_t\ dW_t,
\]</span></p>
<p>as expected. <span class="math inline">\(\square\)</span></p>
</details>
<details>
<summary>
<strong>Solution (c).</strong>
</summary>
<p>Let <span class="math inline">\(Z_t=e^{\alpha W_t}\)</span>. Then we may set <span class="math inline">\(X_t=W_t\)</span> and we then have <span class="math inline">\(\mu_t=0\)</span> and <span class="math inline">\(\sigma_t=1\)</span>. The function <span class="math inline">\(f(t,x)=e^{\alpha x}\)</span> and the relevant derivatives are:</p>
<p><span class="math display">\[
\frac{\partial f}{\partial t}(t,x)=0,\hspace{10pt}\frac{\partial f}{\partial x}(t,x) =\alpha e^{\alpha x},\hspace{10pt}\frac{\partial f}{\partial x^2}(t,x) =\alpha^2 e^{\alpha x}.
\]</span></p>
<p>Then the dynamics of <span class="math inline">\(Z_t\)</span> is as follows</p>
<p><span class="math display">\[\begin{align*}
dZ_t&amp;=\left(0+0+\frac{1}{2}1^2\alpha^2e^{\alpha X_t}\right)\ dt + 1\alpha e^{\alpha X_t}\ dW_t\\
&amp;=\frac{\alpha^2}{2}e^{\alpha X_t}\ dt +\alpha e^{\alpha X_t}\ dW_t\\
&amp;=\frac{\alpha^2}{2}Z_t\ dt +\alpha Z_t\ dW_t.
\end{align*}\]</span></p>
<p>As desired. <span class="math inline">\(\square\)</span>.</p>
</details>
<details>
<summary>
<strong>Solution (d).</strong>
</summary>
<p>Let <span class="math inline">\(Z_t=e^{\alpha X_t}\)</span>, where <span class="math inline">\(X\)</span> has stochastic differential <span class="math inline">\(dX_t=\mu\ dt + \sigma\ dW_t\)</span> and <span class="math inline">\(\mu,\sigma\)</span> is constants. Then we have been given the definition of <span class="math inline">\(X_t\)</span> and we set <span class="math inline">\(f(t,x)=e^{\alpha x}\)</span>. The relevant derivatives are then:</p>
<p><span class="math display">\[
\frac{\partial f}{\partial t}(t,x)=0,\hspace{10pt}\frac{\partial f}{\partial x}(t,x) =\alpha e^{\alpha x},\hspace{10pt}\frac{\partial f}{\partial x^2}(t,x) =\alpha^2 e^{\alpha x}.
\]</span></p>
<p>We may now derive the dynamics of <span class="math inline">\(Z_t\)</span>:</p>
<p><span class="math display">\[\begin{align*}
dZ_t&amp;=\left(0+\mu \alpha e^{\alpha X_t}+\frac{1}{2} \sigma^2\alpha^2 e^{\alpha X_t}\right)\ dt+\sigma \alpha e^{\alpha X_t}\ dW_t\\
&amp;=\left(\mu+\frac{1}{2}\sigma^2\alpha\right)\alpha e^{\alpha X_t}\ dt+\sigma \alpha e^{\alpha X_t}\ dW_t\\
&amp;=\left(\mu+\frac{1}{2}\sigma^2\alpha\right)\alpha Z_t\ dt+\sigma \alpha Z_t\ dW_t.
\end{align*}\]</span></p>
<p>As desired. <span class="math inline">\(\square\)</span>.</p>
</details>
<details>
<summary>
<strong>Solution (e).</strong>
</summary>
<p>Let <span class="math inline">\(Z_t=X_t^2\)</span>, where <span class="math inline">\(X\)</span> has stochastic differential <span class="math inline">\(dX_t=\alpha X_t\ dt+\sigma X_t\ dW_t\)</span>. Then we set <span class="math inline">\(f(t,x)=x^2\)</span> and the relevant derivatives are:</p>
<p><span class="math display">\[
\frac{\partial f}{\partial t}(t,x)=0,\hspace{10pt}\frac{\partial f}{\partial x}(t,x) =2x,\hspace{10pt}\frac{\partial f}{\partial x^2}(t,x) =2.
\]</span></p>
<p>Given this we have the dynamics of <span class="math inline">\(Z_t\)</span> as follows</p>
<p><span class="math display">\[\begin{align*}
dZ_t&amp;=\left(0 + \alpha X_t2X_t+\frac{1}{2}(\sigma X_t)^22\right)\ dt+\sigma X_t 2 X_t\ dW_t\\
&amp;=\left(2\alpha +\sigma^2\right) X_t^2\ dt + 2\sigma X_t^2\ dW_t\\
&amp;=\left(2\alpha +\sigma^2\right) Z_t\ dt + 2\sigma Z_t\ dW_t.
\end{align*}\]</span></p>
<p>As desired. <span class="math inline">\(\square\)</span>.</p>
</details>
<p><strong>Exercise 2</strong> <em>(Bjork 4.2)</em> Compute the stochastic differential for <span class="math inline">\(Z\)</span> when <span class="math inline">\(Z_t=(X_t)^{-1}\)</span> and <span class="math inline">\(X\)</span> has the stochastic differential</p>
<p><span class="math display">\[
dX_t=\alpha X_t\ dt + \sigma X_t\ dW_t.
\]</span></p>
<p>Furthermore, by using the definition <span class="math inline">\(Z=X^{-1}\)</span> you can in fact express the right-hand side of <span class="math inline">\(dZ\)</span> entirely in terms of <span class="math inline">\(Z\)</span> itself (rather then in terms of <span class="math inline">\(X\)</span>). Thus <span class="math inline">\(Z\)</span> satisfies a stochastic differential equation. Which one?</p>
<details>
<summary>
<strong>Solution.</strong>
</summary>
<p>We see that <span class="math inline">\(f(t,x)=1/x\)</span> and so the relevant derivatives is</p>
<p><span class="math display">\[
\frac{\partial f}{\partial t}(t,x)=0,\hspace{10pt}\frac{\partial f}{\partial x}(t,x) =-\frac{1}{x^2},\hspace{10pt}\frac{\partial f}{\partial x^2}(t,x) =\frac{2}{x^3}.
\]</span></p>
<p>Then we by Ito’s formula we have</p>
<p><span class="math display">\[\begin{align*}
dZ_t&amp;=\left(0-\alpha X_t\frac{1}{X_t^2}+\frac{1}{2} \sigma^2 X_t^2\frac{2}{X_t^3}\right)\ dt-\sigma X_t\frac{1}{X_t^2}\ dW_t\\
&amp;=\left(-\alpha \frac{1}{X_t}+ \sigma^2 \frac{1}{X_t}\right)\ dt-\sigma \frac{1}{X_t}\ dW_t\\
&amp;=(\sigma^2-\alpha)Z_t\ dt-\sigma Z_t\ dW_t.
\end{align*}\]</span></p>
<p>We also notice that</p>
<p><span class="math display">\[
Z_t=\frac{1}{X_t}\Rightarrow dZ_t=d\left(\frac{1}{X_t}\right)=-\left(\frac{1}{X_t}\right)^2\ dX_t=-Z_t^2(\alpha X_t\ dt+\sigma X_t\ dW_t)
\]</span></p>
<p>Hence we may insert <span class="math inline">\(X_t=Z_t^{-1}\)</span> and optain</p>
<p><span class="math display">\[
dZ_t=-Z_t^2\left(\alpha\frac{1}{Z_t}\ dt + \sigma \frac{1}{Z_t}\ dW_t\right)=-\alpha Z_t\ dt-\sigma Z_t\ dW_t.
\]</span></p>
<p>Which clearly is faulty.. <span class="math inline">\(\square\)</span></p>
</details>
<p><strong>Exercise 3.</strong> <em>(Bjork 4.3)</em> Let <span class="math inline">\(\sigma(t)\)</span> be a given deterministic function of time and define the process <span class="math inline">\(X\)</span> by</p>
<p><span class="math display">\[
X_t=\int_0^t\sigma(s)\ dW_s.
\]</span></p>
<p>Use the technique discribed in example 4.17 in order to show that the characteristic function of <span class="math inline">\(X_t\)</span> (for a fixed <span class="math inline">\(t\)</span>) is given by</p>
<p><span class="math display">\[
E[e^{iuX_t}]=\exp\left\{-\frac{u^2}{2}\int_0^t\sigma^2(s)\ ds\right\},\ \ u\in\mathbb{R},
\]</span></p>
<p>thus showing that <span class="math inline">\(X_t\)</span> is normally distributed with zero mean and a variance given by</p>
<p><span class="math display">\[
Var[X_t]=\int_0^t\sigma^2(s)\ ds.
\]</span></p>
<details>
<summary>
<strong>Solution.</strong>
</summary>
<p>We follow along the lines of</p>
<ol style="list-style-type: decimal">
<li>Determine the dynamics of <span class="math inline">\(Z_t=e^{iuX_t}\)</span> (for fixed <span class="math inline">\(u\)</span>).</li>
<li>Write the integral form of <span class="math inline">\(Z_t\)</span>.</li>
<li>Take expectation.</li>
<li>Solve ODE.</li>
</ol>
<p>“1)” Set <span class="math inline">\(f(t,x)=e^{iuX_t}\)</span> then the relevant derivatives are</p>
<p><span class="math display">\[
\frac{\partial f}{\partial t}(t,x)=0,\hspace{10pt}\frac{\partial f}{\partial x}(t,x) =iue^{iuX_t}=iuZ_t,\hspace{10pt}\frac{\partial f}{\partial x^2}(t,x) =i^2u^2e^{iuX_t}=-u^2Z_t.
\]</span></p>
<p>Recall that <span class="math inline">\(dX_t=\sigma(t)\ dW_t\)</span>, then by Ito’s formula we have</p>
<p><span class="math display">\[
dZ_t=\left(-\sigma(t)^2\frac{1}{2}u^2Z_t\right)\ dt+\sigma(t)iuZ_t\ dW_t.\tag{*}
\]</span></p>
<p>“2)” We can now write (*) on integral form as below</p>
<p><span class="math display">\[
Z_t=Z_0-\frac{u^2}{2}\int_0^t\sigma^2(s)Z_s\ ds+iu\int_0^t\sigma (s)Z_s\ dW_s,
\]</span></p>
<p>where <span class="math inline">\(Z_0=e^{iuX_0}=1\)</span>.</p>
<p>“3)” Taking expectation now yields</p>
<p><span class="math display">\[
E[Z_t]=1-\frac{u^2}{2}\int_0^t\sigma^2(s)E[Z_s]\ ds+iuE\left[\int_0^t \sigma(s)Z_s\ dW_s\right]=1-\frac{u^2}{2}\int_0^t\sigma^2(s)E[Z_s]\ ds,
\]</span></p>
<p>since any expectaion of an integral wrt. a Brownian motion is 0 (proposition 4.5).</p>
<p>“4)” Now we see that the <span class="math inline">\(t\)</span>-derivative gives</p>
<p><span class="math display">\[
dE[Z_t]=-\frac{u^2}{2}\sigma^2(t)E[Z_t]\ dt,\ \ E[Z_0]=1.
\]</span></p>
<p>This is a ordinary differential equation with solution <span class="math inline">\(y(t)=\exp\{-u^2/2\int_0^t\sigma^2(s)\ ds\}\)</span> (check by differentiating) hence</p>
<p><span class="math display">\[
E[e^{iuX_t}]=E[Z_t]=\exp\left\{-\frac{u^2}{2}\int_0^t\sigma^2(s)\ ds\right\}.
\]</span></p>
<p>We recognize this as the characteristic function of a normally distributed random variable with variance <span class="math inline">\(\int_0^t\sigma^2(s)\ ds\)</span> as desired. (<span class="math inline">\(X_t\)</span> follows this distributions since characteristic functions determine the distribution) <span class="math inline">\(\square\)</span></p>
</details>
<p><strong>Exercise 4</strong> <em>(Bjork 4.4)</em> Suppose that <span class="math inline">\(X\)</span> has the stochastic differential</p>
<p><span class="math display">\[
dX_t=\alpha X_t\ dt+\sigma_t\ dW_t,
\]</span></p>
<p>where <span class="math inline">\(\alpha\)</span> is a real number and <span class="math inline">\(\sigma_t\)</span> is a integrable adapted stochastic process. Use the technique in example 4.17 in order to determine the function <span class="math inline">\(m(t)=E[X_t]\)</span>.</p>
<details>
<summary>
<strong>Solution.</strong>
</summary>
<p>We follow the same steps as the previous exercise. We have been given the dynamics of <span class="math inline">\(X\)</span> hence we may write it on integral form.</p>
<p><span class="math display">\[
X_t=X_0+\alpha\int_0^tX_s\ ds+\int_0^t\sigma(s)\ dW_s.
\]</span></p>
<p>Then taking expectation now gives</p>
<p><span class="math display">\[
E[X_t]=X_0+\alpha\int_0^tE[X_s]\ ds.
\]</span></p>
<p>Hence <span class="math inline">\(E[X_t]\)</span> follows from the solution to the ODE below</p>
<p><span class="math display">\[
dE[X_t]=\alpha E[X_t]\Rightarrow E[X_t]=C\cdot\exp\{\alpha t\}.
\]</span></p>
<p>Then obviously <span class="math inline">\(C=X_0\)</span> and we arrive at the solution <span class="math inline">\(E[X_t]=X_0e^{\alpha t}\)</span>, where <span class="math inline">\(X_0\)</span> is some deterministic value. <span class="math inline">\(\square\)</span></p>
</details>
<p><strong>Exercise 5</strong> <em>(Bjork 4.5)</em> Suppose that the process <span class="math inline">\(X\)</span> has a stochastic differential</p>
<p><span class="math display">\[
dX_t=\mu_t\ dt+\sigma_t\ dW_t,
\]</span></p>
<p>and that <span class="math inline">\(\mu_t\ge 0\)</span> with probability one for all <span class="math inline">\(t\ge 0\)</span>. Show that this implies that <span class="math inline">\(X\)</span> is a sub-martingale.</p>
<details>
<summary>
<strong>Solution.</strong>
</summary>
<p>Note that we are (strictly speaking) supposed to show adaptation and integrability, we will however only fokus on the submartingale property.</p>
<p>“<span class="math inline">\(E[X_t\vert \mathcal{F}_s]\ge X_s\)</span>” Intuitively speaking, the statement is obvious since we have with probability one a positive upwards drift with Brownian distortion (i.e. martingale). Formally, we will show the statement by first writing <span class="math inline">\(X_t\)</span> on integral form</p>
<p><span class="math display">\[
X_t=x_0+\int_0^t\mu_s\ ds+\int_0^t\sigma_s\ dW_s.
\]</span></p>
<p>And so</p>
<p><span class="math display">\[
X_t-X_s=\int_s^t\mu_u\ du+\int_s^t\sigma_u\ dW_u.
\]</span></p>
<p>We then have</p>
<p><span class="math display">\[\begin{align*}
E[X_t\ \vert\ \mathcal{F}_s]-X_s&amp;=E[X_t-X_s\ \vert\ \mathcal{F}_s]\\
&amp;=E\left[\left.\int_s^t\mu_u\ du+\int_s^t\sigma_u\ dW_u\ \right\vert\ \mathcal{F}_s\right]\\
&amp;=E\left[\left.\int_s^t\mu_u\ du\ \right\vert\ \mathcal{F}_s\right]+E\left[\left.\int_s^t\sigma_u\ dW_u\ \right\vert\ \mathcal{F}_s\right]\\
&amp;=E\left[\left.\int_s^t\mu_u\ du\ \right\vert\ \mathcal{F}_s\right]\ge 0.
\end{align*}\]</span></p>
<p>Then adding <span class="math inline">\(X_s\)</span> to the above inequality yields the result. <span class="math inline">\(\square\)</span></p>
</details>
<p><strong>Exercise 6</strong> <em>(Bjork 4.7)</em> The objective of this exercise is to give an argument for the formal identity</p>
<p><span class="math display">\[
dW_1(t)\cdot dW_2(t)=0,
\]</span></p>
<p>when <span class="math inline">\(W_1\)</span> and <span class="math inline">\(W_2\)</span> are independent Brownian motions. Let us therefore fix a time <span class="math inline">\(t\)</span>, and divide the inerval <span class="math inline">\([0,t]\)</span> into equidistant points <span class="math inline">\(0=t_0&lt;t_1&lt;\cdots &lt; t_n=t\)</span>, where <span class="math inline">\(t_i=\frac{i}{n}\cdot t\)</span>. We use the notation</p>
<p><span class="math display">\[
\Delta W_i(t_k)=W_i(t_k)-W_i(t_{k-1}),\ i=1,2.
\]</span></p>
<p>Now define <span class="math inline">\(Q_n\)</span> by</p>
<p><span class="math display">\[
Q_n=\sum_{k=1}^n \Delta W_1(t_k)\cdot \Delta W_2(t_k).
\]</span></p>
<p>Show that <span class="math inline">\(Q_n\to 0\)</span> in <span class="math inline">\(L^2\)</span>, i.e. show that</p>
<p><span class="math display">\[
E[Q_n]=0,\\
Var[Q_n]\to 0.
\]</span></p>
<details>
<summary>
<strong>Solution.</strong>
</summary>
<p>We wish to show the statement</p>
<p><span class="math display">\[
E[(Q_n-0)^2]=E[Q_n^2]\to 0,
\]</span></p>
<p>as <span class="math inline">\(n\to \infty\)</span>. Recall that</p>
<p><span class="math display">\[
Var[Q_n]=E[Q_n^2]-E[Q_n]^2,
\]</span></p>
<p>hence if <span class="math inline">\(Q_n\)</span> has mean 0, then showing convergence in <span class="math inline">\(L^2\)</span> is equivalent to showing variance going to 0. Let us start by showing the mean is 0.</p>
<p>We have that</p>
<p><span class="math display">\[\begin{align*}
Q_n&amp;=\sum_{k=1}^n \Delta W_1(t_k)\cdot \Delta W_2(t_k)\\
&amp;=\sum_{k=1}^n(W_1(t_k)-W_1(t_{k-1}))\cdot (W_2(t_k)-W_2(t_{k-1}))\\
&amp;\stackrel{\mathcal{D}}{=}\sum_{k=1}^nXY,
\end{align*}\]</span></p>
<p>where <span class="math inline">\(X,Y\sim\mathcal{N}(0,t_k-t_{k-1})=\mathcal{N}(0,1/n)\)</span> and independent random variable. This is justified since the increments of the Brownian motion has mean 0 and variance equal to the increment size. Now this implies, that we need to show that <span class="math inline">\(E[XY]=0\)</span> and that <span class="math inline">\(Var[XY]\)</span> is sufficiently small in terms of <span class="math inline">\(n\)</span> such that it is summable. We see that</p>
<p><span class="math display">\[
E[XY]=E[X]E[Y]=0^2=0.
\]</span></p>
<p>Here we use independence. We now know that the mean is</p>
<p><span class="math display">\[
E[Q_n]=\sum_{k=1}^nE[XY]=0.
\]</span></p>
<p>We know from basic properties of variance that</p>
<p><span class="math display">\[\begin{align*}
Var(Q_n)&amp;=\sum_{k=1}^n Var(XY)=\sum_{k=1}^n E[(XY)^2]\\
&amp;=\sum_{k=1}^n\frac{1}{n^2}=\frac{1}{n^2}n\\
&amp;=\frac{1}{n}\to0,\ n\to\infty.
\end{align*}\]</span></p>
<p>And so the result follows. <span class="math inline">\(\square\)</span></p>
</details>
<p><strong>Exercise 7</strong> <em>(Bjork 4.8)</em> Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be given as the solutions to the following system of stochastic differential equations.</p>
<p><span class="math display">\[\begin{align*}
&amp;dX_t=\alpha X_t\ dt-Y_t\ dW_t,\ &amp;X_0=x_0,\\
&amp;dY_t=\alpha Y_t\ dt + X_t\ dW_t,\ &amp;Y_0=y_0.
\end{align*}\]</span></p>
<p>Note that the initial values <span class="math inline">\(x_0\)</span> and <span class="math inline">\(y_0\)</span> are deterministic constants.</p>
<ol style="list-style-type: lower-alpha">
<li>Prove that the process <span class="math inline">\(R\)</span> defined by <span class="math inline">\(R_t=X_t^2+Y_t^2\)</span> is deterministic.</li>
<li>Compute <span class="math inline">\(E[X_t]\)</span>.</li>
</ol>
<details>
<summary>
<strong>Solution (a).</strong>
</summary>
<p>We see that</p>
<p><span class="math display">\[
dR_t=d(X_t^2+Y_t^2)=d(X_t^2)+d(Y_t^2)
\]</span></p>
<p>Hence we may start by considering de dynamics of the processes <span class="math inline">\(X_t^2\)</span> and <span class="math inline">\(Y_t^2\)</span>. We see that for the process <span class="math inline">\(Z_t=X_t^2\)</span> we may set <span class="math inline">\(f(t,x)=x^2\)</span> and the relevant derivatives are</p>
<p><span class="math display">\[
\frac{\partial f}{\partial t}(t,x)=0,\ \frac{\partial f}{\partial x}(t,x)=2x,\ \frac{\partial^2 f}{\partial x^2}(t,x)=2.
\]</span></p>
<p>By Ito’s formula we have</p>
<p><span class="math display">\[
d(X_t^2)=\left(\alpha X_t2X_t+Y_t^22\right)\ dt-Y_t2X_t\ dW_t=2(\alpha X_t^2+Y_t^2)\ dt-2X_tY_t\ dW_t.
\]</span></p>
<p>By the same concept we have</p>
<p><span class="math display">\[
d(Y_t^2)=\left(\alpha Y_t2Y_t+X_t^22\right)\ dt+X_t2Y_t\ dW_t=2(\alpha Y_t^2+X_t^2)\ dt+2X_tY_t\ dW_t.
\]</span></p>
<p>Combining we get the dynamics</p>
<p><span class="math display">\[\begin{align*}
dR_t&amp;=2(\alpha X_t^2+Y_t^2)\ dt-2X_tY_t\ dW_t\\
&amp;+2(\alpha Y_t^2+X_t^2)\ dt+2X_tY_t\ dW_t\\
&amp;=(2\alpha +1)(X_t^2 + Y_t^2)\ dt\\
&amp;=(2\alpha +1)R_t\ dt
\end{align*}\]</span></p>
<p>Hence <span class="math inline">\(R_t\)</span> has deterministic derivative and therefore a deterministic process. In fact, the solution to above is</p>
<p><span class="math display">\[
R_t=R_0\exp\left\{(2\alpha + 1)t\right\}=(x_0^2+y_0^2)e^{(2\alpha + 1)t},
\]</span></p>
<p>which is clearly deterministic. <span class="math inline">\(\square\)</span></p>
</details>
<details>
<summary>
<strong>Solution (b).</strong>
</summary>
<p>We start by acknowledging that the differential form of <span class="math inline">\(X\)</span> may be written on integral form:</p>
<p><span class="math display">\[
X_t=x_0+\alpha\int_0^tX_s\ ds-\int_0^tY_s\ dW_s.
\]</span></p>
<p>Taking expectation we see that</p>
<p><span class="math display">\[
E[X_t]=x_0+\int_0^tE[X_s]\ ds
\]</span></p>
<p>as the last term has mean 0 according to proposition 4.5. Then the above may be written on the differential form</p>
<p><span class="math display">\[
dE[X_t]=E[X_t]\ dt
\]</span></p>
<p>Hence we have that</p>
<p><span class="math display">\[
E[X_t]=x_0e^{t}.
\]</span></p>
<p>Hence <span class="math inline">\(X_t\)</span> has mean not depending on the tragetory of the sister-process <span class="math inline">\(Y_t\)</span>. <span class="math inline">\(\square\)</span></p>
</details>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="exercises-week-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="exercises-week-3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
