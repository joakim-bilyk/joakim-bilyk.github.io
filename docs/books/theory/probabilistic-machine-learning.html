<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Probabilistic Machine Learning | Complete Theory</title>
  <meta name="description" content="Chapter 9 Probabilistic Machine Learning | Complete Theory" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Probabilistic Machine Learning | Complete Theory" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Probabilistic Machine Learning | Complete Theory" />
  
  
  

<meta name="author" content="Joakim Bilyk" />


<meta name="date" content="2023-02-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="topics-in-non-life-insurance-mathematics.html"/>
<link rel="next" href="quantative-risk-management.html"/>
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="https://code.jquery.com/jquery-1.9.1.js"></script>

<script>
    $(function() {
        var element = document.body;
        if (localStorage.chkbx && localStorage.chkbx != '') {
            $('#remember_me').attr('checked', 'checked');
            element.classList.toggle("dark-mode");
            document.querySelector('.book-header.fixed').click();
        } else {
            $('#remember_me').removeAttr('checked');
            document.querySelector('.book-header.fixed').click();
        }

        $('#remember_me').click(function() {

            if ($('#remember_me').is(':checked')) {
                // save username and password
                localStorage.chkbx = $('#remember_me').val();
                element.classList.toggle("dark-mode");
                document.querySelector('.book-header.fixed').click();
            } else {
                localStorage.chkbx = '';
                element.classList.toggle("dark-mode");
                document.querySelector('.book-header.fixed').click();
            }
        });
    });

</script>

<div class = "sticky-darkmode-toggle">
  <label class="switch">
  <input type="checkbox" value="remember-me" id="remember_me">
  <span class="slider round">
  </span>
  </label>
</div>

<script>
$(function() {
  $('body').after($('.sticky-darkmode-toggle'));
})
</script>

<style>

.sticky-darkmode-toggle {
  position: fixed;
  right: 20px;
  bottom: 20px;
}
</style>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Comlete theory</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#abbreviations"><i class="fa fa-check"></i><b>1.1</b> Abbreviations</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#to-do-reading"><i class="fa fa-check"></i><b>1.2</b> To-do reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="basic-life-insurance-mathematics.html"><a href="basic-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>2</b> Basic Life Insurance Mathematics</a></li>
<li class="chapter" data-level="3" data-path="stochastic-processes-in-life-insurance-mathematics.html"><a href="stochastic-processes-in-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>3</b> Stochastic Processes in Life Insurance Mathematics</a></li>
<li class="chapter" data-level="4" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>4</b> Topics in Life Insurance Mathematics</a>
<ul>
<li class="chapter" data-level="4.1" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html#markov-jump-processes"><i class="fa fa-check"></i><b>4.1</b> Markov Jump Processes</a></li>
<li class="chapter" data-level="4.2" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html#phase-type-distributions"><i class="fa fa-check"></i><b>4.2</b> Phase-type distributions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html"><i class="fa fa-check"></i><b>5</b> Continuous Time Finance</a>
<ul>
<li class="chapter" data-level="5.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#discrete-time-models"><i class="fa fa-check"></i><b>5.1</b> Discrete time models</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#one-period-time-models"><i class="fa fa-check"></i><b>5.1.1</b> One-period time models</a></li>
<li class="chapter" data-level="5.1.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#multi-period-model"><i class="fa fa-check"></i><b>5.1.2</b> Multi-period model</a></li>
<li class="chapter" data-level="5.1.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#generelised-one-period-model"><i class="fa fa-check"></i><b>5.1.3</b> Generelised one-period model</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#self-financing-portfolios"><i class="fa fa-check"></i><b>5.2</b> Self-financing portfolios</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#discrete-time-sf-portfolio"><i class="fa fa-check"></i><b>5.2.1</b> Discrete time SF portfolio</a></li>
<li class="chapter" data-level="5.2.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#continuous-time-sf-portfolio"><i class="fa fa-check"></i><b>5.2.2</b> Continuous time SF portfolio</a></li>
<li class="chapter" data-level="5.2.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#portfolio-weights"><i class="fa fa-check"></i><b>5.2.3</b> Portfolio weights</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#black-scholes-pde"><i class="fa fa-check"></i><b>5.3</b> Black-Scholes PDE</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#contingent-claims-and-arbitrage"><i class="fa fa-check"></i><b>5.3.1</b> Contingent Claims and Arbitrage</a></li>
<li class="chapter" data-level="5.3.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#risk-neutral-valuation-1"><i class="fa fa-check"></i><b>5.3.2</b> Risk Neutral Valuation</a></li>
<li class="chapter" data-level="5.3.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#black-scholes-formula"><i class="fa fa-check"></i><b>5.3.3</b> Black-Scholes formula</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#completeness-and-hedging"><i class="fa fa-check"></i><b>5.4</b> Completeness and Hedging</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#completeness-in-black-scholes"><i class="fa fa-check"></i><b>5.4.1</b> Completeness in Black-Scholes</a></li>
<li class="chapter" data-level="5.4.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#absence-of-arbitrage-1"><i class="fa fa-check"></i><b>5.4.2</b> Absence of Arbitrage</a></li>
<li class="chapter" data-level="5.4.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#incomplete-markets"><i class="fa fa-check"></i><b>5.4.3</b> Incomplete Markets</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#parity-relations"><i class="fa fa-check"></i><b>5.5</b> Parity relations</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#put-call-parity"><i class="fa fa-check"></i><b>5.5.1</b> Put-call Parity</a></li>
<li class="chapter" data-level="5.5.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#the-greeks"><i class="fa fa-check"></i><b>5.5.2</b> The Greeks</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#fundamental-pricing-theorem-i-and-ii"><i class="fa fa-check"></i><b>5.6</b> Fundamental pricing theorem I and II</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#completeness-1"><i class="fa fa-check"></i><b>5.6.1</b> Completeness</a></li>
<li class="chapter" data-level="5.6.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#risk-neutral-valuation-formula"><i class="fa fa-check"></i><b>5.6.2</b> Risk Neutral Valuation Formula</a></li>
<li class="chapter" data-level="5.6.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#stochastic-discount-factors-1"><i class="fa fa-check"></i><b>5.6.3</b> Stochastic Discount Factors</a></li>
<li class="chapter" data-level="5.6.4" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#summary"><i class="fa fa-check"></i><b>5.6.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#mathematics-of-the-martingale-approach"><i class="fa fa-check"></i><b>5.7</b> Mathematics of the martingale approach</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#martingale-representation-theorem"><i class="fa fa-check"></i><b>5.7.1</b> Martingale representation theorem</a></li>
<li class="chapter" data-level="5.7.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#girsanov-theorem"><i class="fa fa-check"></i><b>5.7.2</b> Girsanov theorem</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#black-scholes-model---martingale-approach"><i class="fa fa-check"></i><b>5.8</b> Black-Scholes model - martingale approach</a></li>
<li class="chapter" data-level="5.9" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#multidimensional-models"><i class="fa fa-check"></i><b>5.9</b> Multidimensional models</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="basic-non-life-insurance-mathematics.html"><a href="basic-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>6</b> Basic Non-Life Insurance Mathematics</a></li>
<li class="chapter" data-level="7" data-path="stochastic-processes-in-non-life-insurance-mathematics.html"><a href="stochastic-processes-in-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>7</b> Stochastic Processes in Non-Life Insurance Mathematics</a></li>
<li class="chapter" data-level="8" data-path="topics-in-non-life-insurance-mathematics.html"><a href="topics-in-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>8</b> Topics in Non-Life Insurance Mathematics</a></li>
<li class="chapter" data-level="9" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html"><i class="fa fa-check"></i><b>9</b> Probabilistic Machine Learning</a>
<ul>
<li class="chapter" data-level="9.1" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#supervised-learning"><i class="fa fa-check"></i><b>9.1</b> Supervised Learning</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#what-is-a-good-estimator"><i class="fa fa-check"></i><b>9.1.1</b> What is a good estimator?</a></li>
<li class="chapter" data-level="9.1.2" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#excess-risk"><i class="fa fa-check"></i><b>9.1.2</b> Excess risk</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#training-validating-and-testing"><i class="fa fa-check"></i><b>9.2</b> Training, Validating and Testing</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#estimating-risk"><i class="fa fa-check"></i><b>9.2.1</b> Estimating risk</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#linear-models"><i class="fa fa-check"></i><b>9.3</b> Linear Models</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="quantative-risk-management.html"><a href="quantative-risk-management.html"><i class="fa fa-check"></i><b>10</b> Quantative Risk Management</a>
<ul>
<li class="chapter" data-level="10.1" data-path="quantative-risk-management.html"><a href="quantative-risk-management.html#the-loss-variable"><i class="fa fa-check"></i><b>10.1</b> The Loss Variable</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="quantative-risk-management.html"><a href="quantative-risk-management.html#risk-measures"><i class="fa fa-check"></i><b>10.1.1</b> Risk measures</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="measure-theory.html"><a href="measure-theory.html"><i class="fa fa-check"></i><b>11</b> Measure theory</a>
<ul>
<li class="chapter" data-level="11.1" data-path="measure-theory.html"><a href="measure-theory.html#axioms-of-probability"><i class="fa fa-check"></i><b>11.1</b> Axioms of Probability</a></li>
<li class="chapter" data-level="11.2" data-path="measure-theory.html"><a href="measure-theory.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>11.2</b> Conditional Probability and Independence</a></li>
<li class="chapter" data-level="11.3" data-path="measure-theory.html"><a href="measure-theory.html#equivalent-probability-measures"><i class="fa fa-check"></i><b>11.3</b> Equivalent Probability Measures</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="measure-theory.html"><a href="measure-theory.html#the-radon-nikodym-theorem"><i class="fa fa-check"></i><b>11.3.1</b> The Radon-Nikodym Theorem</a></li>
<li class="chapter" data-level="11.3.2" data-path="measure-theory.html"><a href="measure-theory.html#equivalent-probability-measures-1"><i class="fa fa-check"></i><b>11.3.2</b> Equivalent Probability Measures</a></li>
<li class="chapter" data-level="11.3.3" data-path="measure-theory.html"><a href="measure-theory.html#likelihood-processes"><i class="fa fa-check"></i><b>11.3.3</b> Likelihood processes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>12</b> Random Variables</a>
<ul>
<li class="chapter" data-level="12.1" data-path="random-variables.html"><a href="random-variables.html#introduction-1"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="random-variables.html"><a href="random-variables.html#conditional-expectation"><i class="fa fa-check"></i><b>12.2</b> Conditional expectation</a></li>
<li class="chapter" data-level="12.3" data-path="random-variables.html"><a href="random-variables.html#independence"><i class="fa fa-check"></i><b>12.3</b> Independence</a></li>
<li class="chapter" data-level="12.4" data-path="random-variables.html"><a href="random-variables.html#moment-generating-function"><i class="fa fa-check"></i><b>12.4</b> Moment generating function</a></li>
<li class="chapter" data-level="12.5" data-path="random-variables.html"><a href="random-variables.html#standard-distributions"><i class="fa fa-check"></i><b>12.5</b> Standard distributions</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="random-variables.html"><a href="random-variables.html#normal-disribution"><i class="fa fa-check"></i><b>12.5.1</b> Normal disribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html"><i class="fa fa-check"></i><b>13</b> Discrete Time Stochastic Processes</a>
<ul>
<li class="chapter" data-level="13.1" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#convergence-concepts"><i class="fa fa-check"></i><b>13.1</b> Convergence concepts</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#sums-and-average-processes"><i class="fa fa-check"></i><b>13.1.1</b> Sums and average processes</a></li>
<li class="chapter" data-level="13.1.2" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#ergodic-theory"><i class="fa fa-check"></i><b>13.1.2</b> Ergodic Theory</a></li>
<li class="chapter" data-level="13.1.3" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#weak-convergence"><i class="fa fa-check"></i><b>13.1.3</b> Weak Convergence</a></li>
<li class="chapter" data-level="13.1.4" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#central-limit-theorems"><i class="fa fa-check"></i><b>13.1.4</b> Central Limit Theorems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="continuous-time-stochastic-processes.html"><a href="continuous-time-stochastic-processes.html"><i class="fa fa-check"></i><b>14</b> Continuous Time Stochastic Processes</a>
<ul>
<li class="chapter" data-level="14.1" data-path="continuous-time-stochastic-processes.html"><a href="continuous-time-stochastic-processes.html#brownian-motion"><i class="fa fa-check"></i><b>14.1</b> Brownian Motion</a></li>
<li class="chapter" data-level="14.2" data-path="continuous-time-stochastic-processes.html"><a href="continuous-time-stochastic-processes.html#filtration"><i class="fa fa-check"></i><b>14.2</b> Filtration</a></li>
<li class="chapter" data-level="14.3" data-path="continuous-time-stochastic-processes.html"><a href="continuous-time-stochastic-processes.html#martingale"><i class="fa fa-check"></i><b>14.3</b> Martingale</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html"><i class="fa fa-check"></i><b>15</b> Stochastic calculus</a>
<ul>
<li class="chapter" data-level="15.1" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#stochastic-integrals"><i class="fa fa-check"></i><b>15.1</b> Stochastic Integrals</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#information"><i class="fa fa-check"></i><b>15.1.1</b> Information</a></li>
<li class="chapter" data-level="15.1.2" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#stochastic-integrals-1"><i class="fa fa-check"></i><b>15.1.2</b> Stochastic Integrals</a></li>
<li class="chapter" data-level="15.1.3" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#martingales"><i class="fa fa-check"></i><b>15.1.3</b> Martingales</a></li>
<li class="chapter" data-level="15.1.4" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#stochastic-calculus-and-the-ito-formula"><i class="fa fa-check"></i><b>15.1.4</b> Stochastic Calculus and the Ito Formula</a></li>
<li class="chapter" data-level="15.1.5" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#the-multidimensional-ito-formula"><i class="fa fa-check"></i><b>15.1.5</b> The multidimensional Ito Formula</a></li>
<li class="chapter" data-level="15.1.6" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#correlated-brownian-motions"><i class="fa fa-check"></i><b>15.1.6</b> Correlated Brownian motions</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#discrete-stochastic-integrals"><i class="fa fa-check"></i><b>15.2</b> Discrete Stochastic Integrals</a></li>
<li class="chapter" data-level="15.3" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#stochastic-differential-equations"><i class="fa fa-check"></i><b>15.3</b> Stochastic Differential Equations</a></li>
<li class="chapter" data-level="15.4" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#partial-differential-equations"><i class="fa fa-check"></i><b>15.4</b> Partial differential equations</a></li>
<li class="chapter" data-level="15.5" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#the-product-integral"><i class="fa fa-check"></i><b>15.5</b> The Product Integral</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#properties-of-the-product-integral"><i class="fa fa-check"></i><b>15.5.1</b> Properties of the Product Integral</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="linear-algebra.html"><a href="linear-algebra.html"><i class="fa fa-check"></i><b>16</b> Linear Algebra</a>
<ul>
<li class="chapter" data-level="16.1" data-path="linear-algebra.html"><a href="linear-algebra.html#invertible-matrices"><i class="fa fa-check"></i><b>16.1</b> Invertible matrices</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="coding.html"><a href="coding.html"><i class="fa fa-check"></i><b>17</b> Coding</a>
<ul>
<li class="chapter" data-level="17.1" data-path="coding.html"><a href="coding.html#r-packages"><i class="fa fa-check"></i><b>17.1</b> R-Packages</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="coding.html"><a href="coding.html#mlr3"><i class="fa fa-check"></i><b>17.1.1</b> mlr3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://joakim-bilyk.github.io/index.html">Back to main site</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Complete Theory</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probabilistic-machine-learning" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Chapter 9</span> Probabilistic Machine Learning<a href="probabilistic-machine-learning.html#probabilistic-machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="supervised-learning" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Supervised Learning<a href="probabilistic-machine-learning.html#supervised-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter we restrict our selves to the area of <em>Supervised Learning</em> as we use numerical methods and machine learning algorithms to estimate models in a restricted framework. Take for instance the random forest, this algorithm’s estimation method is perfectly capable of being written recursively and so no “leaning” is done in the sense, that the calculations are predetermined from the algorithm. We therefore call the area of study supervised learning instead of the wider area of study <em>machine learning</em>. Let us define what we mean by supervised learning.</p>
<blockquote class="def">
<p><strong>Definition. (Supervised Learning)</strong> <em>Supervised learning is a field in machine learning that works with labeled data, i.e. data consisting of a set of features <span class="math inline">\(X\)</span>, and a response <span class="math inline">\(Y\)</span>. The goal is to learn a function <span class="math inline">\(m^*\)</span> that maps a given input <span class="math inline">\(x\)</span> to an output <span class="math inline">\(y\)</span>.</em></p>
</blockquote>
<p>We will in this chapter only use data in the form of a spread sheet e.g.</p>
<p><span class="math display">\[
\mathcal{D}_n=
\left(X_i, Y_i \right)_{i=1,...,n}=
\left[
\begin{array}{cccc|c}
X_{11} &amp; X_{12} &amp; \cdots &amp; X_{1p} &amp; Y_1\\
X_{21} &amp; X_{22} &amp; \cdots &amp; X_{2p} &amp; Y_2\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots\\
X_{n1} &amp; X_{n2} &amp; \cdots &amp; X_{np} &amp; Y_n
\end{array}
\right],
\]</span></p>
<p>we could however consider any data that may be interpreted by computer software.</p>
<p>The setting is then; assume that we have <span class="math inline">\(n\)</span> independent copies of the random variable <span class="math inline">\(D=(X,Y)\in \mathcal{X}\times \mathcal{Y}\)</span>, where <span class="math inline">\(X\)</span> is <span class="math inline">\(p\)</span>-dimensional and <span class="math inline">\(Y\)</span> is one-dimensional. We make no assumption on whether <span class="math inline">\(X_j\)</span>, <span class="math inline">\(j=1,..,p\)</span> and <span class="math inline">\(Y\)</span> are discrete or continuous, however in concrete cases this will be specified. We combine the sample of the <span class="math inline">\(n\)</span> observations in the matrix <span class="math inline">\(\mathcal{D}_n=(X_i,Y_i)_{i=1,...,n}\)</span> being a <span class="math inline">\(n\times p+1\)</span> matrix as in the above. We call <span class="math inline">\(\mathcal{D}_n\)</span> the <strong>training data</strong>.</p>
<p>This specification does indeed imply that <span class="math inline">\(D_i=(X_i,Y_i)\)</span> are iid. This is actually a bit controversial as we would expect that the distribution of <span class="math inline">\(D\)</span> will shift over time. For instance, the distribution of ages in a population changes over time and have been more right skewed as humanity advances. This may be accounted for by transforming the data such that the distribution becomes the same. This may be done in a variety of ways some example include: 1) transforming to uniform variable with the time dependent distribution <span class="math inline">\(F_t\)</span>, 2) normalizing using a price index and so forth. One should therefore start any analysis by ensuring that the data a given algorithm is trained on is iid.</p>
<p>The job becomes finding a good estimator such that we may predict <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span> i.e. <span class="math inline">\(Y\ \vert\ X\)</span>. Let us define what an estimator is.</p>
<blockquote class="def">
<p><strong>Definition. (Estimator)</strong> <em>Consider a training dataset <span class="math inline">\(\mathcal{D}_n\)</span>. A estimator <span class="math inline">\(m\)</span> is a function-valued mapping that takes <span class="math inline">\(\mathcal{D}_n\)</span> as input and associates a function <span class="math inline">\(m_n : \mathcal{X}\to \mathcal{Y}\)</span> i.e. <span class="math inline">\(m\)</span> takes the form</em></p>
<p><span class="math display">\[
m(\mathcal{D}_n)=m_n:\mathcal{X}\to \mathcal{Y}
\]</span></p>
<p><em>the class of estimators is called <span class="math inline">\(\mathcal{G}\)</span>.</em></p>
</blockquote>
<div id="what-is-a-good-estimator" class="section level3 hasAnchor" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> What is a good estimator?<a href="probabilistic-machine-learning.html#what-is-a-good-estimator" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>It is easy to construct an estimator <span class="math inline">\(\hat{m}\)</span> for instance by maximum likelihood esitmation, bayes optimization or simply by taking conditional expectations. We are however interested in two problems:</p>
<ol style="list-style-type: decimal">
<li>What is the best class of estimators <span class="math inline">\(\mathcal{G}_0\subset\mathcal{G}\)</span>,</li>
<li>In the subset of estimators <span class="math inline">\(m \in \mathcal{G}_0\)</span>, what is then the best estimator.</li>
</ol>
<p>We will now discuss the meaning of being the <em>“best”</em> estimator. Obviously, the first type of consideration is regarding the inherent restrictions of some algorithm, where the second is the problem of error comming from the restriction that we do not have infinite observations. We therefore have two problems namely the <strong>inductive bias</strong> from the class <span class="math inline">\(\mathcal{G}_0\)</span> and the <strong>estimation error</strong> from the available data. A typical problem is that the larger a class <span class="math inline">\(\mathcal{G}_0\)</span> gives low inductive bias we then may not be able to estimate anything and so the estimation error will be large. The converse also applies.</p>
<blockquote class="def">
<p><strong>Definition.</strong> <em>Let <span class="math inline">\(D=(X,Y)\)</span> be a random variable on the background space <span class="math inline">\((\Omega, \mathcal{F},P)\)</span>. Then we define the following:</em></p>
<ul>
<li><em>A <strong>decision rule</strong> is a deterministic function <span class="math inline">\(m:\mathcal{X}\to \mathcal{Y}\)</span>,</em></li>
<li><em>A <strong>loss function</strong> is a deterministic function <span class="math inline">\(L: \mathcal{Y}\times \mathcal{Y}\to \mathbb{R}_+\)</span>,</em></li>
<li><em>The <strong>risk</strong> of a decision rule <span class="math inline">\(m\)</span> is given a loss function <span class="math inline">\(L\)</span> is <span class="math inline">\(r(m)=E[L(Y,m(X))]\)</span>.</em></li>
</ul>
</blockquote>
<p>Notice that in the definition of risk we see that <span class="math inline">\(m\)</span> is included inside the expectation. This means in particular that the training data <span class="math inline">\(\mathcal{D}_n\)</span> is also accounted for i.e. by the tower rule we have</p>
<p><span class="math display">\[
r(m)=\mathbb{E}[L(Y,m(X))]=\mathbb{E}\left[\mathbb{E}\Big[L(Y,m_n(X))\ \Big\vert\ \mathcal{D}_n\Big]\right]:=\mathbb{E}\left[R(m)\right].
\]</span></p>
<p>Some widely used loss function include</p>
<ul>
<li>Quadratic loss function: <span class="math inline">\(L(y_1,y_2)=(y_1-y_2)^2\)</span>,</li>
<li>Poisson Deviance: <span class="math inline">\(L(y_1,y_2)=2\left(y_1\log\frac{y_1}{y_2}-y_1+y_2\right)\)</span>,</li>
<li>Binary loss function: <span class="math inline">\(L(y_1,y_2)=1_{y_1\ne y_2}\)</span>.</li>
</ul>
<p>Given a loss function <span class="math inline">\(L\)</span> we may find a (possibly non-unique) solution <span class="math inline">\(m^*\)</span> that minimizes <span class="math inline">\(R(m)\)</span>. We call this the <strong>Bayes estimator</strong>. The quantity <span class="math inline">\(R(m^*)\)</span> is called the <strong>Bayes risk</strong>. On some special case loss functions we may determine the unique solution.</p>
<blockquote class="lem">
<p><strong>Lemma.</strong> <em>Assume <span class="math inline">\(Y\)</span> is <span class="math inline">\(L_2\)</span> (square integrable), then the decision function that minimized the risk for the quadratic loss function is</em></p>
<p><span class="math display">\[
m^*=\underset{m}{\text{argmin}}\ \mathbb{E}[(Y-m(X))^2]=E[Y\ \vert\ X=x]
\]</span>
i.e. the conditional expectation.</p>
</blockquote>
<blockquote class="lem">
<p><strong>Lemma.</strong> <em>Assume <span class="math inline">\(\mathcal{Y}=\{1,...,K\}\)</span>, the decision function that minimizes the risk for the binary loss function satisfies</em></p>
<p><span class="math display">\[
m^*=\underset{m}{\text{argmin}}\ \mathbb{E}[1_{Y\ne m(X)}]=\underset{m}{\text{argmin}}\  \mathbb{P}(Y\ne m(X))=\underset{k=1,..,K}{\text{argmax}}\ \mathbb{P}(Y=k\ \vert\ X=x).
\]</span></p>
</blockquote>
<p>We can now define the prediction risk and the generalization error which relates to the balance of a sufficiently large class <span class="math inline">\(\mathcal{G}_0\)</span> and how effective the optimal estimator is conditional on the class <span class="math inline">\(\mathcal{G}_0\)</span>.</p>
<blockquote class="def">
<p><strong>Definition. (Conditional risk)</strong> <em>Let <span class="math inline">\(\mathcal{D}_n\)</span> be some training data. Given an estimator <span class="math inline">\(\hat{m}_n\)</span> we call</em></p>
<p><span class="math display">\[
R(\hat{m}_n)=\mathbb{E}[L(Y,\hat{m}_n(X))\ \vert\ \mathcal{D}_n]
\]</span></p>
<p><em>the prediction risk or conditional generalized error.</em></p>
</blockquote>
<blockquote class="def">
<p><strong>Definition. (Risk)</strong> <em>We call</em></p>
<p><span class="math display">\[
r(\hat{m}_n)=\mathbb{E}[R(\hat{m}_n)],
\]</span></p>
<p><em>the prediction risk or generalized error.</em></p>
</blockquote>
</div>
<div id="excess-risk" class="section level3 hasAnchor" number="9.1.2">
<h3><span class="header-section-number">9.1.2</span> Excess risk<a href="probabilistic-machine-learning.html#excess-risk" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote class="def">
<p><strong>Definition. (Excess Risk)</strong> <em>Consider the set <span class="math inline">\(\mathcal{G}\)</span> be the set of all measurable estimators. Fix a subset <span class="math inline">\(\mathcal{G}_0\subset\mathcal{G}\)</span>. Given some training data <span class="math inline">\(\mathcal{D}_n\)</span> consider the Bayes estimator restricted to <span class="math inline">\(\mathcal{G}_0\)</span> denoted by <span class="math inline">\(\hat{m}_n\)</span> and the unconditional Bayes estimator restricted to <span class="math inline">\(\mathcal{G}\)</span> we define the quantity</em></p>
<p><span class="math display">\[
R(\hat{m}_n)-r(m^*)
\]</span></p>
<p><em>or</em></p>
<p><span class="math display">\[
\mathbb{E}[R(\hat{m}_n)\ \vert\ X_1,...,X_n]-r(m^*),
\]</span></p>
<p><em>as the excess risk. This is the difference between the generalization error and the risk obtained by an optimal decision function.</em></p>
</blockquote>
<p>In the context of the above definition we can decompose the risk associated with the optimal estimator <span class="math inline">\(\hat{m}_n\in\mathcal{G}_0\)</span> into the estimation error and the inductive bias.</p>
<p><span class="math display">\[
R(\hat{m}_n)-r(m^*)=\underbrace{\left[R(\hat{m}_n)-\inf_{m\in\mathcal{G}_0}R(m)\right]}_{\text{estimation error}}+\underbrace{\left[\inf_{m\in\mathcal{G}_0}R(m)-R(m^*)\right].}_{\text{inductions bias/approximation error}}
\]</span></p>
<p>where we have to balance the trade-off with a larger <span class="math inline">\(\mathcal{G}_0\)</span> infer a lower induction bias but larger estimation error and a smaller class <span class="math inline">\(\mathcal{G}_0\)</span> infer a lower estimation error but larger induction bias.</p>
<blockquote class="def">
<p><strong>Definition. (Empirical risk and empirical risk minimizer)</strong> <em>Given training data <span class="math inline">\(\mathcal{D}_n\)</span> and a loss function <span class="math inline">\(L\)</span>, we call</em></p>
<p><span class="math display">\[
\hat{R}_n(m):=\sum_{i=1}^nL(Y_i,m(X_i))
\]</span></p>
<p><em>the <strong>empirical risk</strong>. Given an additional function class <span class="math inline">\(\mathcal{G}_0\)</span>,</em></p>
<p><span class="math display">\[
\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \hat{R}_n(m)=\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \sum_{i=1}^nL(Y_i,m(X_i))
\]</span></p>
<p><em>is called <strong>empirical risk minimizer</strong> or (standard leaner).</em></p>
</blockquote>
<p>For larger function classes <span class="math inline">\(\mathcal{G}_0\)</span> the empirical risk minimizer might not be unique and possibly too noisy. In this case one sometimes adds a penalty term <span class="math inline">\(J_\lambda : \mathcal{G}\to \mathbb{R}_+\)</span> that penalizes the complexity of <span class="math inline">\(m\)</span> and minimizes the penalized empirical risk:</p>
<p><span class="math display">\[
\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \hat{R}_{n,\lambda}:=\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \sum_{i=1}^nL(Y_i,m(X_i)) + J_\lambda(m).
\]</span></p>
<p>If <span class="math inline">\(J_\lambda\)</span> and <span class="math inline">\(\hat{R}_n\)</span> is convex one can show that</p>
<p><span class="math display">\[
\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \hat{R}_{n,\lambda}=\underset{m\in\mathcal{G}_\eta}{\text{argmin}}\ \hat{R}_{n}
\]</span></p>
<p>for the class <span class="math inline">\(\mathcal{G}_\eta=\{m\in \mathcal{G}_0\ \vert\ J_\lambda(m)\le \eta\}\)</span>. Some penalty terms could be</p>
<ul>
<li><span class="math inline">\(J_\lambda(m)=\lambda\int m&#39;&#39;(x)\ dx\)</span>,</li>
<li><span class="math inline">\(J_\lambda(m)=\lambda \int\vert m&#39;(x)\vert\ dx\)</span>,</li>
<li><span class="math inline">\(J_\lambda(m)=\lambda \int(m(x))^2\ dx\)</span>.</li>
</ul>
<blockquote class="prop">
<p><strong>Proposition. (Probability bounds)</strong> <em>Let <span class="math inline">\(\tilde{m}=\underset{m}{\text{argmin}}\ r(m)\)</span>. We have</em></p>
<p><span class="math display">\[
r(\hat{m}_n)-r(\tilde{m})\le 2\sup_{m\in\mathcal{G}_0}\Big\vert\hat{R}_n(m) - r(m) \Big\vert,
\]</span></p>
<p><em>and for all <span class="math inline">\(\lambda \in \Lambda\)</span>,</em></p>
<p><span class="math display">\[
r(\hat{m}_{n,\lambda})-r(\tilde{m})\le 2\sup_{m\in\mathcal{G}_0}\Big\vert\hat{R}_{n,\lambda}(m) - r(m) \Big\vert + J_\lambda(\tilde{m})-J_\lambda(\hat{m}_n).
\]</span></p>
</blockquote>
<blockquote class="def">
<p><strong>Definition.</strong> <em>We say <span class="math inline">\(\hat{m}_n\)</span> is <span class="math inline">\(\varepsilon\)</span>-accurate with probabiltiy <span class="math inline">\(1-\delta\)</span>, if</em></p>
<p><span class="math display">\[
P\Big(R(\hat{m}_n)-\inf_{m\in\mathcal{G}}r(m)&gt;\varepsilon\Big)&lt;\delta.
\]</span></p>
</blockquote>
</div>
</div>
<div id="training-validating-and-testing" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Training, Validating and Testing<a href="probabilistic-machine-learning.html#training-validating-and-testing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When deciding which method too choose for a given task, one may like to pick the method with the smallest generalization error. However, most machine learning methods depend on hyper parameters and one may first need to decide which hyper parameters are best for the given task. In short: We would like to compare the generalization error of optimally tuned machine learning methods given our data.</p>
<blockquote class="def">
<p><strong>Definition. (Training and test set)</strong> <em>One often randomly divides the given data into training data and test data:</em></p>
<ul>
<li><span class="math inline">\(\mathcal{D}_n=(X_i,Y_i)_{i=1,...,n}\)</span> <em>(traning data)</em></li>
<li><span class="math inline">\(\mathcal{T}_m=(\tilde{X}_j,\tilde{Y}_j)_{j=1,...,m}\)</span> <em>(test data)</em></li>
</ul>
<p><em>with <span class="math inline">\(n\in[0.8m,0.95m]\)</span>.</em></p>
</blockquote>
<blockquote class="def">
<p><strong>Definition. (Training and test error)</strong> <em>The empirical risk on the training data is called training error and on the test data test error.</em></p>
</blockquote>
<blockquote class="def">
<p><strong>Definition. (Validation set)</strong> <em>To tune the hyper parameters for an algorithm, one often randomly divides the given training data into training data (yes: also called training data.) and validation data:</em></p>
<ul>
<li><span class="math inline">\(\mathcal{D}_{n_1}=(X_i,Y_i)_{i=\tau(1),...,\tau(n_1)}\)</span> <em>(traning data)</em></li>
<li><span class="math inline">\(\mathcal{V}_{n_2}=(\tilde{X}_j,\tilde{Y}_j)_{j=\tau(n_1+1),...,\tau(n)}\)</span> <em>(validation data)</em></li>
</ul>
<p><em>where <span class="math inline">\(\tau\)</span> is a randomly picked permutation of <span class="math inline">\(\{1,...,n\}\)</span> and <span class="math inline">\(n_1+n_2=n\)</span> is respectively the size of the training set and the validation set.</em></p>
</blockquote>
<p>One can now compare different methods via the following simple algorithm:</p>
<ol style="list-style-type: decimal">
<li>Split your data into train, validation and test set.</li>
<li>For a given method and a rich set of hyper parameter configurations train the method on the training set and compare performance via empirical risk on the validation set.</li>
<li>For every method, pick the hyper parameter with the smallest empirical risk.</li>
<li>Compare different methods with the chosen hyper parameters on the test set (trained on training+validation set) and pick the method with smallest empirical risk.</li>
</ol>
<p>Notice that the procedure above is stochastic and has bias and variance both for selecting the optimal hyper parameters and for selecting the optimal method.</p>
<ul>
<li>Bias: Bias occurs because the sample sizes used for learning the hyper parameters <span class="math inline">\(n_1\)</span> are smaller than the actual training size <span class="math inline">\(n\)</span> and also the full data size <span class="math inline">\(n+m\)</span>.</li>
<li>Variance: The results are stochastic because the validation and test set are not of infinite size.</li>
</ul>
<p>Variance can be reduced by repeating steps 1-4 several times. The most popular method for doing so is (nested) cross validation.</p>
<div id="estimating-risk" class="section level3 hasAnchor" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Estimating risk<a href="probabilistic-machine-learning.html#estimating-risk" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We want to estimate the generalization error of a method <span class="math inline">\(\hat{m}_{n,\lambda}\)</span> that depends on a fixed hyper parameter <span class="math inline">\(\lambda\)</span>.</p>
<blockquote class="def">
<p><strong>Definition. (M-fold Cross validation)</strong> <em>Given the indices of a data set <span class="math inline">\(S=\{1,...,n\}\)</span>, M-fold cross validation follows the following steps:</em></p>
<ol style="list-style-type: decimal">
<li><em>Divide the data into <span class="math inline">\(M\)</span> disjoint sets <span class="math inline">\(S_1,...,S_M\)</span> of same size. Define <span class="math inline">\(S_{-l}=\cup_{k\ne l}S_k\)</span> being the complement to <span class="math inline">\(S_l\)</span>. (<span class="math inline">\(\#S_l=n/M\)</span> and <span class="math inline">\(\#S_{-l}=(M-1)n/M\)</span>)</em></li>
<li><em>For each subdivision <span class="math inline">\(l=1,...,M\)</span> train the algorithm on <span class="math inline">\(S_{-l}\)</span> and denote the estimator <span class="math inline">\(\hat{m}_\lambda(S_{-l})\)</span>.</em></li>
<li><em>Calculate the cross validated empirical risk</em>
<span class="math display">\[
  CV(\hat{m}_{n,\lambda})=\frac{1}{M}\sum_{l=1}^M\frac{1}{\vert S_{-l}\vert}\sum_{i\in S_{-l}}L\big(Y_i,\hat{m}_\lambda(S_{-l})(X_i)\big)
  \]</span></li>
</ol>
</blockquote>
<p>It is a non-trivial discussion what <span class="math inline">\(CV(\hat{m}_{n,\lambda})\)</span> is estimating. Consider the heuristic
<span class="math display">\[\begin{align*}
CV(\hat{m}_{n,\lambda})&amp;=\frac{1}{M}\sum_{l=1}^M\frac{1}{\vert S_{-l}\vert}\sum_{i\in S_{-l}}L\big(Y_i,\hat{m}_\lambda(S_{-l})(X_i)\big)\\
&amp;\approx \frac{1}{M}\sum_{l=1}^MR\big(Y,\hat{m}_\lambda(S_{-l})(X)\big)\\
&amp;\approx \mathbb{E}\left[R\big(Y,\hat{m}_\lambda(S_{-l})(X)\big)\right].
\end{align*}\]</span>
Where we used the law of large numbers in the first approximation. The last approximation is not so clear because the summands are dependent for <span class="math inline">\(M&gt;2\)</span>.</p>
<p>The bias is minimal for large <span class="math inline">\(M\)</span> since estimation is based on training the algorithm on <span class="math inline">\((M-1)n/M\)</span> data points. In the case that <span class="math inline">\(M=n\)</span>, M-fold cross validation is also known as leave-one-our cross validation. It is however often not practical because of the computational cost. In practice, setting <span class="math inline">\(M=5\)</span> or <span class="math inline">\(M=10\)</span> is common choices.</p>
<p>When deciding on an optimal hyper parameter we would like to pick</p>
<p><span class="math display">\[
\underset{\lambda \in \Lambda}{\text{argmin}}\ CV(\hat{m}_{n,\lambda}).
\]</span></p>
<p>But the hyper parameter space <span class="math inline">\(\Lambda\)</span> is often multi-dimensional and partly continuous. Hence it is infeasible to try out all parameters. Common practice are</p>
<ul>
<li>Grid search</li>
<li>Random search (e.g. pick 200 parameters uniformly random from the parameter space)</li>
<li>Advanced optimization techniques (i.e. techniques that aim to find the minimzer of a function (here: cross validated empirical risk) without the requirement of knowing the analytical form of the function to optimize.</li>
</ul>
<p>Above we have discussed how we can use cross validation to pick an optimal parameter for a given method and data set. But how to choose between different methods? One popular way is nested cross validation comprising an inner loop for hyper parameter selection (tuning) and an outer loop for method comparison. Assume that we want to compare <span class="math inline">\(J\)</span> methods <span class="math inline">\(\hat{m}_{n,j}\)</span>, <span class="math inline">\(j=1,...,J\)</span>. then we may use nested cross validation.</p>
<blockquote class="def">
<p><strong>Definition. (Nested <span class="math inline">\(M_1-M_2\)</span> Cross-validation)</strong> <em>Given the indices of a data set <span class="math inline">\(S=\{1,...,n\}\)</span>, nested <span class="math inline">\(M_1-M_2\)</span> cross validation follows the following steps:</em></p>
<ol style="list-style-type: decimal">
<li><em>Divide the data into <span class="math inline">\(M_1\)</span> disjoint sets <span class="math inline">\(S_1,...,S_{M_1}\)</span> of same size. Define <span class="math inline">\(S_{-l}=\cup_{k\ne l}S_k\)</span> being the complement to <span class="math inline">\(S_l\)</span>. (<span class="math inline">\(\#S_l=n/M_1\)</span> and <span class="math inline">\(\#S_{-l}=(M_1-1)n/M_1\)</span>)</em></li>
<li><em>For each <span class="math inline">\(l=1,...,M_1\)</span>, run <span class="math inline">\(M_2\)</span>-fold cross validation on <span class="math inline">\(S_{-l}\)</span> for all <span class="math inline">\(J\)</span> methods, returning optimal hyper parameters <span class="math inline">\(\hat{\lambda}(j,l)\)</span>, <span class="math inline">\(j=1,...,J\)</span> and <span class="math inline">\(l=1,...,M_1\)</span>. (the one with lowest <span class="math inline">\(CV\)</span> is choosen for each <span class="math inline">\((j,l)\)</span>)</em></li>
<li><em>Calculate the cross validated empirical risk</em>
<span class="math display">\[
  CV(\hat{m}_{n,j})=\frac{1}{M_1}\sum_{l=1}^{M_1}\frac{1}{\vert S_{-l}\vert}\sum_{i\in S_l}L\big(Y_i,\hat{m}_{\lambda(j,l)}(S_{-l})(X_i)\big)
  \]</span></li>
<li><em>Pick the method with the smallest risk (and possibly tune again for fitting)</em></li>
</ol>
</blockquote>
</div>
</div>
<div id="linear-models" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Linear Models<a href="probabilistic-machine-learning.html#linear-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We may take the linear model as a case study of the methods introduced in the above chapter. As such we consider the squaed loss <span class="math inline">\(L(y_1,y_2)=(y_1-y_2)^2\)</span> for which we already know the Bayes rule:</p>
<p><span class="math display">\[
m^*(x)=\underset{m}{\text{argmin}}\ R(m)=\mathbb{E}[Y\ \vert\ X=x].
\]</span></p>
<p>The linear model has the following assumptions. There exists paramaters <span class="math inline">\(\beta_0^*,\beta_1^*,...,\beta_p^*\)</span>, with</p>
<p><span class="math display">\[
m^*(x)=\beta_0^*+\sum_{j=1}^{p}\beta_j^*x_j.
\]</span></p>
<p>In other words, we assume that <span class="math inline">\(m^*\)</span> is a linear function, i.e.,</p>
<p><span class="math display">\[
m^*\in\mathcal{G}=\{f : \mathbb{R}^p\to \mathbb{R}\ \vert\ f(x)=\beta^\top x\}.
\]</span></p>
<p>Given iid training data <span class="math inline">\((X_i,Y_i)_{i=1,...,n}\)</span> we have an additive noise model</p>
<p><span class="math display">\[
Y_i=\beta_0^*+\sum_{j=1}^{p}\beta_j^*X_{ij}+\varepsilon_i,
\]</span></p>
<p>with <span class="math inline">\(\varepsilon_i=Y_i-m^*(X_i)\)</span> and hence iid with <span class="math inline">\(\mathbb{E}[\varepsilon_i\ \vert\ X_i]=0\)</span>.</p>
<p>Notice, that since we are assuming <span class="math inline">\(m^*\in\mathcal{G}\)</span> we have by assumption no inductive bias and we therefore only consider estimation error i.e.</p>
<p><span class="math display">\[
R(\hat{m}_n)-r(m^*).
\]</span></p>
<p>Given the training data we may approximate the coefficients using the following.</p>
<blockquote class="lem">
<p><strong>Lemma. (Coefficients in the linear model)</strong> <em>Under the Linear model assumption we have for <span class="math inline">\(j=1,...,p\)</span></em></p>
<p><span class="math display">\[
\beta^*_j=\frac{\text{Cov}\Big(X_{1j},Y_1-\sum_{k\in \{1,...,p\}\setminus \{j\}} \beta_k^*X_{1k}\Big)}{\text{Var}(X_{1j})}
\]</span></p>
<p><em>In particular, if the components of <span class="math inline">\(X\)</span> are uncorrelated, we have</em></p>
<p><span class="math display">\[
\beta_j^*=\frac{\text{Cov}(X_{1j},Y_1)}{\text{Var}(X_{1j})}.
\]</span></p>
</blockquote>
<blockquote class="lem">
<p><strong>Lemma. (Bayes risk in the linear model)</strong> <em>Under the Linear model assumption we have</em></p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(r(m^*)=\text{Var}(\varepsilon_i)\)</span></li>
<li>For <span class="math inline">\(m(x)=\beta_0+\sum_{j=1}^p \beta_jx_j\)</span>,
<span class="math display">\[
  r(m)-r(m^*)=\Vert\Sigma^{1/2}(\beta -\beta^*) \Vert^2_2.
  \]</span></li>
</ol>
</blockquote>
<p>Moving forward we will assume <span class="math inline">\(\beta_0^*=0\)</span> since we can always translate the data and make the centered around 0. We will furthermore use the notation:</p>
<p><span class="math display">\[
\mathbf{X}=
\begin{bmatrix}
X_{11} &amp; \cdots &amp; X_{1p}\\
\vdots &amp; \ddots &amp; \vdots\\
X_{n1} &amp; \cdots &amp; X_{np}
\end{bmatrix},\hspace{10pt} \mathbf{Y}=
\begin{pmatrix}
Y_1\\
\vdots\\
Y_n
\end{pmatrix},\hspace{10pt} \varepsilon=
\begin{pmatrix}
\varepsilon_1\\
\vdots\\
\varepsilon_n
\end{pmatrix}.
\]</span></p>
<p>In this cases the empirical risk takes the form</p>
<p><span class="math display">\[
\hat{R}_n(m)=\frac{1}{n}\Vert\mathbf{Y}-\mathbf{X}\beta \Vert^2_2.
\]</span></p>
<blockquote class="lem">
<p><strong>Lemma. (Least squares estimator)</strong></p>
<ul>
<li><em>It holds that <span class="math inline">\((\mathbf{X}^\top\mathbf{X})\hat{\beta}=\mathbf{X}^\top \mathbf{Y}\)</span>,</em></li>
<li><em>If <span class="math inline">\(\mathbf{X}\)</span> has full rank, then</em>
<span class="math display">\[
  \hat{\beta}_n^{LS}=(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top \mathbf{Y}.
  \]</span></li>
</ul>
</blockquote>
<blockquote class="thm">
<p><strong>Theorem. (Excess risk Least squares estimator)</strong> If <span class="math inline">\(\mathbf{X}^\top\mathbf{X}\)</span> is invertible, then</p>
<p><span class="math display">\[
\mathbb{E}[R(\hat{m}_n^{LS})\ \vert\ \mathbf{X}]-r(m^*)=\frac{\sigma^2}{n}\cdot \text{tr}\left(\Sigma\hat{\Sigma}^{-1}\right)
\]</span></p>
<p>with <span class="math inline">\(\Sigma=\mathbb{E}[\mathbf{X}^\top\mathbf{X}]\)</span> and <span class="math inline">\(\hat{\Sigma}=\frac{1}{n}\mathbf{X}^\top\mathbf{X}\)</span>.</p>
</blockquote>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="topics-in-non-life-insurance-mathematics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="quantative-risk-management.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
