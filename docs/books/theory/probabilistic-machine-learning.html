<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Probabilistic Machine Learning | Complete Theory</title>
  <meta name="description" content="Chapter 9 Probabilistic Machine Learning | Complete Theory" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Probabilistic Machine Learning | Complete Theory" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Probabilistic Machine Learning | Complete Theory" />
  
  
  

<meta name="author" content="Joakim Bilyk" />


<meta name="date" content="2023-02-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="topics-in-non-life-insurance-mathematics.html"/>
<link rel="next" href="quantative-risk-management.html"/>
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="https://code.jquery.com/jquery-1.9.1.js"></script>

<script>
    $(function() {
        var element = document.body;
        if (localStorage.chkbx && localStorage.chkbx != '') {
            $('#remember_me').attr('checked', 'checked');
            element.classList.toggle("dark-mode");
            document.querySelector('.book-header.fixed').click();
        } else {
            $('#remember_me').removeAttr('checked');
            document.querySelector('.book-header.fixed').click();
        }

        $('#remember_me').click(function() {

            if ($('#remember_me').is(':checked')) {
                // save username and password
                localStorage.chkbx = $('#remember_me').val();
                element.classList.toggle("dark-mode");
                document.querySelector('.book-header.fixed').click();
            } else {
                localStorage.chkbx = '';
                element.classList.toggle("dark-mode");
                document.querySelector('.book-header.fixed').click();
            }
        });
    });

</script>

<div class = "sticky-darkmode-toggle">
  <label class="switch">
  <input type="checkbox" value="remember-me" id="remember_me">
  <span class="slider round">
  </span>
  </label>
</div>

<script>
$(function() {
  $('body').after($('.sticky-darkmode-toggle'));
})
</script>

<style>

.sticky-darkmode-toggle {
  position: fixed;
  right: 20px;
  bottom: 20px;
}
</style>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Comlete theory</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#abbreviations"><i class="fa fa-check"></i><b>1.1</b> Abbreviations</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#to-do-reading"><i class="fa fa-check"></i><b>1.2</b> To-do reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="basic-life-insurance-mathematics.html"><a href="basic-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>2</b> Basic Life Insurance Mathematics</a></li>
<li class="chapter" data-level="3" data-path="stochastic-processes-in-life-insurance-mathematics.html"><a href="stochastic-processes-in-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>3</b> Stochastic Processes in Life Insurance Mathematics</a></li>
<li class="chapter" data-level="4" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>4</b> Topics in Life Insurance Mathematics</a>
<ul>
<li class="chapter" data-level="4.1" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html#markov-jump-processes"><i class="fa fa-check"></i><b>4.1</b> Markov Jump Processes</a></li>
<li class="chapter" data-level="4.2" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html#phase-type-distributions"><i class="fa fa-check"></i><b>4.2</b> Phase-type distributions</a></li>
<li class="chapter" data-level="4.3" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html#interest-rates"><i class="fa fa-check"></i><b>4.3</b> Interest rates</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html#basic-definitions-and-properties"><i class="fa fa-check"></i><b>4.3.1</b> Basic definitions and properties</a></li>
<li class="chapter" data-level="4.3.2" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html#phase-type-representation-of-bond-prices"><i class="fa fa-check"></i><b>4.3.2</b> Phase-type representation of bond prices</a></li>
<li class="chapter" data-level="4.3.3" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html#term-structure-models"><i class="fa fa-check"></i><b>4.3.3</b> Term structure models</a></li>
<li class="chapter" data-level="4.3.4" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html#estimation-of-ph-bond-models"><i class="fa fa-check"></i><b>4.3.4</b> Estimation of PH bond models</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html#survival-and-mortality-rates"><i class="fa fa-check"></i><b>4.4</b> Survival and mortality rates</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html"><i class="fa fa-check"></i><b>5</b> Continuous Time Finance</a>
<ul>
<li class="chapter" data-level="5.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#discrete-time-models"><i class="fa fa-check"></i><b>5.1</b> Discrete time models</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#one-period-time-models"><i class="fa fa-check"></i><b>5.1.1</b> One-period time models</a></li>
<li class="chapter" data-level="5.1.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#multi-period-model"><i class="fa fa-check"></i><b>5.1.2</b> Multi-period model</a></li>
<li class="chapter" data-level="5.1.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#generelised-one-period-model"><i class="fa fa-check"></i><b>5.1.3</b> Generelised one-period model</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#self-financing-portfolios"><i class="fa fa-check"></i><b>5.2</b> Self-financing portfolios</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#discrete-time-sf-portfolio"><i class="fa fa-check"></i><b>5.2.1</b> Discrete time SF portfolio</a></li>
<li class="chapter" data-level="5.2.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#continuous-time-sf-portfolio"><i class="fa fa-check"></i><b>5.2.2</b> Continuous time SF portfolio</a></li>
<li class="chapter" data-level="5.2.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#portfolio-weights"><i class="fa fa-check"></i><b>5.2.3</b> Portfolio weights</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#black-scholes-pde"><i class="fa fa-check"></i><b>5.3</b> Black-Scholes PDE</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#contingent-claims-and-arbitrage"><i class="fa fa-check"></i><b>5.3.1</b> Contingent Claims and Arbitrage</a></li>
<li class="chapter" data-level="5.3.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#risk-neutral-valuation-1"><i class="fa fa-check"></i><b>5.3.2</b> Risk Neutral Valuation</a></li>
<li class="chapter" data-level="5.3.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#black-scholes-formula"><i class="fa fa-check"></i><b>5.3.3</b> Black-Scholes formula</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#completeness-and-hedging"><i class="fa fa-check"></i><b>5.4</b> Completeness and Hedging</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#completeness-in-black-scholes"><i class="fa fa-check"></i><b>5.4.1</b> Completeness in Black-Scholes</a></li>
<li class="chapter" data-level="5.4.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#absence-of-arbitrage-1"><i class="fa fa-check"></i><b>5.4.2</b> Absence of Arbitrage</a></li>
<li class="chapter" data-level="5.4.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#incomplete-markets"><i class="fa fa-check"></i><b>5.4.3</b> Incomplete Markets</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#parity-relations"><i class="fa fa-check"></i><b>5.5</b> Parity relations</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#put-call-parity"><i class="fa fa-check"></i><b>5.5.1</b> Put-call Parity</a></li>
<li class="chapter" data-level="5.5.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#the-greeks"><i class="fa fa-check"></i><b>5.5.2</b> The Greeks</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#fundamental-pricing-theorem-i-and-ii"><i class="fa fa-check"></i><b>5.6</b> Fundamental pricing theorem I and II</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#completeness-1"><i class="fa fa-check"></i><b>5.6.1</b> Completeness</a></li>
<li class="chapter" data-level="5.6.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#risk-neutral-valuation-formula"><i class="fa fa-check"></i><b>5.6.2</b> Risk Neutral Valuation Formula</a></li>
<li class="chapter" data-level="5.6.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#stochastic-discount-factors-1"><i class="fa fa-check"></i><b>5.6.3</b> Stochastic Discount Factors</a></li>
<li class="chapter" data-level="5.6.4" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#summary"><i class="fa fa-check"></i><b>5.6.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#mathematics-of-the-martingale-approach"><i class="fa fa-check"></i><b>5.7</b> Mathematics of the martingale approach</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#martingale-representation-theorem"><i class="fa fa-check"></i><b>5.7.1</b> Martingale representation theorem</a></li>
<li class="chapter" data-level="5.7.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#girsanov-theorem"><i class="fa fa-check"></i><b>5.7.2</b> Girsanov theorem</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#black-scholes-model---martingale-approach"><i class="fa fa-check"></i><b>5.8</b> Black-Scholes model - martingale approach</a></li>
<li class="chapter" data-level="5.9" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#multidimensional-models"><i class="fa fa-check"></i><b>5.9</b> Multidimensional models</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="basic-non-life-insurance-mathematics.html"><a href="basic-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>6</b> Basic Non-Life Insurance Mathematics</a></li>
<li class="chapter" data-level="7" data-path="stochastic-processes-in-non-life-insurance-mathematics.html"><a href="stochastic-processes-in-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>7</b> Stochastic Processes in Non-Life Insurance Mathematics</a></li>
<li class="chapter" data-level="8" data-path="topics-in-non-life-insurance-mathematics.html"><a href="topics-in-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>8</b> Topics in Non-Life Insurance Mathematics</a></li>
<li class="chapter" data-level="9" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html"><i class="fa fa-check"></i><b>9</b> Probabilistic Machine Learning</a>
<ul>
<li class="chapter" data-level="9.1" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#supervised-learning"><i class="fa fa-check"></i><b>9.1</b> Supervised Learning</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#what-is-a-good-estimator"><i class="fa fa-check"></i><b>9.1.1</b> What is a good estimator?</a></li>
<li class="chapter" data-level="9.1.2" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#excess-risk"><i class="fa fa-check"></i><b>9.1.2</b> Excess risk</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#training-validating-and-testing"><i class="fa fa-check"></i><b>9.2</b> Training, Validating and Testing</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#estimating-risk"><i class="fa fa-check"></i><b>9.2.1</b> Estimating risk</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#linear-models"><i class="fa fa-check"></i><b>9.3</b> Linear Models</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#least-squares-estimator"><i class="fa fa-check"></i><b>9.3.1</b> Least Squares Estimator</a></li>
<li class="chapter" data-level="9.3.2" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#ridge-regression"><i class="fa fa-check"></i><b>9.3.2</b> Ridge Regression</a></li>
<li class="chapter" data-level="9.3.3" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#lasso-regression"><i class="fa fa-check"></i><b>9.3.3</b> Lasso Regression</a></li>
<li class="chapter" data-level="9.3.4" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#conclusion"><i class="fa fa-check"></i><b>9.3.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#nonparametric-regression"><i class="fa fa-check"></i><b>9.4</b> Nonparametric Regression</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#curse-of-dimensionality"><i class="fa fa-check"></i><b>9.4.1</b> Curse of dimensionality</a></li>
<li class="chapter" data-level="9.4.2" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#splines"><i class="fa fa-check"></i><b>9.4.2</b> Splines</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="quantative-risk-management.html"><a href="quantative-risk-management.html"><i class="fa fa-check"></i><b>10</b> Quantative Risk Management</a>
<ul>
<li class="chapter" data-level="10.1" data-path="quantative-risk-management.html"><a href="quantative-risk-management.html#the-loss-variable"><i class="fa fa-check"></i><b>10.1</b> The Loss Variable</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="quantative-risk-management.html"><a href="quantative-risk-management.html#risk-measures"><i class="fa fa-check"></i><b>10.1.1</b> Risk measures</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="measure-theory.html"><a href="measure-theory.html"><i class="fa fa-check"></i><b>11</b> Measure theory</a>
<ul>
<li class="chapter" data-level="11.1" data-path="measure-theory.html"><a href="measure-theory.html#axioms-of-probability"><i class="fa fa-check"></i><b>11.1</b> Axioms of Probability</a></li>
<li class="chapter" data-level="11.2" data-path="measure-theory.html"><a href="measure-theory.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>11.2</b> Conditional Probability and Independence</a></li>
<li class="chapter" data-level="11.3" data-path="measure-theory.html"><a href="measure-theory.html#probabilities-on-a-finite-or-countable-space"><i class="fa fa-check"></i><b>11.3</b> Probabilities on a Finite or Countable Space</a></li>
<li class="chapter" data-level="11.4" data-path="measure-theory.html"><a href="measure-theory.html#construction-of-a-probability-measure-on-mathbb-r"><i class="fa fa-check"></i><b>11.4</b> Construction of a Probability Measure on <span class="math inline">\(\mathbb R\)</span></a></li>
<li class="chapter" data-level="11.5" data-path="measure-theory.html"><a href="measure-theory.html#random-variables"><i class="fa fa-check"></i><b>11.5</b> Random Variables</a></li>
<li class="chapter" data-level="11.6" data-path="measure-theory.html"><a href="measure-theory.html#integration-with-respect-to-a-probability-measure"><i class="fa fa-check"></i><b>11.6</b> Integration with Respect to a Probability Measure</a></li>
<li class="chapter" data-level="11.7" data-path="measure-theory.html"><a href="measure-theory.html#independent-random-variables"><i class="fa fa-check"></i><b>11.7</b> Independent Random Variables</a></li>
<li class="chapter" data-level="11.8" data-path="measure-theory.html"><a href="measure-theory.html#probability-distributions-on-mathbb-r"><i class="fa fa-check"></i><b>11.8</b> Probability Distributions on <span class="math inline">\(\mathbb R\)</span></a></li>
<li class="chapter" data-level="11.9" data-path="measure-theory.html"><a href="measure-theory.html#probability-distributions-on-mathbb-rn"><i class="fa fa-check"></i><b>11.9</b> Probability Distributions on <span class="math inline">\(\mathbb R^n\)</span></a></li>
<li class="chapter" data-level="11.10" data-path="measure-theory.html"><a href="measure-theory.html#equivalent-probability-measures"><i class="fa fa-check"></i><b>11.10</b> Equivalent Probability Measures</a>
<ul>
<li class="chapter" data-level="11.10.1" data-path="measure-theory.html"><a href="measure-theory.html#the-radon-nikodym-theorem"><i class="fa fa-check"></i><b>11.10.1</b> The Radon-Nikodym Theorem</a></li>
<li class="chapter" data-level="11.10.2" data-path="measure-theory.html"><a href="measure-theory.html#equivalent-probability-measures-1"><i class="fa fa-check"></i><b>11.10.2</b> Equivalent Probability Measures</a></li>
<li class="chapter" data-level="11.10.3" data-path="measure-theory.html"><a href="measure-theory.html#likelihood-processes"><i class="fa fa-check"></i><b>11.10.3</b> Likelihood processes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="random-variables-1.html"><a href="random-variables-1.html"><i class="fa fa-check"></i><b>12</b> Random Variables</a>
<ul>
<li class="chapter" data-level="12.1" data-path="random-variables-1.html"><a href="random-variables-1.html#introduction-1"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="random-variables-1.html"><a href="random-variables-1.html#conditional-expectation"><i class="fa fa-check"></i><b>12.2</b> Conditional expectation</a></li>
<li class="chapter" data-level="12.3" data-path="random-variables-1.html"><a href="random-variables-1.html#independence"><i class="fa fa-check"></i><b>12.3</b> Independence</a></li>
<li class="chapter" data-level="12.4" data-path="random-variables-1.html"><a href="random-variables-1.html#moment-generating-function"><i class="fa fa-check"></i><b>12.4</b> Moment generating function</a></li>
<li class="chapter" data-level="12.5" data-path="random-variables-1.html"><a href="random-variables-1.html#standard-distributions"><i class="fa fa-check"></i><b>12.5</b> Standard distributions</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="random-variables-1.html"><a href="random-variables-1.html#normal-disribution"><i class="fa fa-check"></i><b>12.5.1</b> Normal disribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html"><i class="fa fa-check"></i><b>13</b> Discrete Time Stochastic Processes</a>
<ul>
<li class="chapter" data-level="13.1" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#convergence-concepts"><i class="fa fa-check"></i><b>13.1</b> Convergence concepts</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#sums-and-average-processes"><i class="fa fa-check"></i><b>13.1.1</b> Sums and average processes</a></li>
<li class="chapter" data-level="13.1.2" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#ergodic-theory"><i class="fa fa-check"></i><b>13.1.2</b> Ergodic Theory</a></li>
<li class="chapter" data-level="13.1.3" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#weak-convergence"><i class="fa fa-check"></i><b>13.1.3</b> Weak Convergence</a></li>
<li class="chapter" data-level="13.1.4" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#central-limit-theorems"><i class="fa fa-check"></i><b>13.1.4</b> Central Limit Theorems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="markov-chains.html"><a href="markov-chains.html"><i class="fa fa-check"></i><b>14</b> Markov Chains</a>
<ul>
<li class="chapter" data-level="14.1" data-path="markov-chains.html"><a href="markov-chains.html#definition-of-a-markov-chain"><i class="fa fa-check"></i><b>14.1</b> Definition of a Markov Chain</a></li>
<li class="chapter" data-level="14.2" data-path="markov-chains.html"><a href="markov-chains.html#classification-of-states"><i class="fa fa-check"></i><b>14.2</b> Classification of states</a></li>
<li class="chapter" data-level="14.3" data-path="markov-chains.html"><a href="markov-chains.html#limit-results-and-invariant-probabilities"><i class="fa fa-check"></i><b>14.3</b> Limit results and invariant probabilities</a></li>
<li class="chapter" data-level="14.4" data-path="markov-chains.html"><a href="markov-chains.html#absorbing-probabilities"><i class="fa fa-check"></i><b>14.4</b> Absorbing probabilities</a></li>
<li class="chapter" data-level="14.5" data-path="markov-chains.html"><a href="markov-chains.html#markov-chains-in-continuous-times"><i class="fa fa-check"></i><b>14.5</b> Markov Chains in Continuous Times</a></li>
<li class="chapter" data-level="14.6" data-path="markov-chains.html"><a href="markov-chains.html#properties-of-transitionsprobabilities"><i class="fa fa-check"></i><b>14.6</b> Properties of transitionsprobabilities</a></li>
<li class="chapter" data-level="14.7" data-path="markov-chains.html"><a href="markov-chains.html#invariant-probabilies-and-absorption"><i class="fa fa-check"></i><b>14.7</b> Invariant probabilies and absorption</a></li>
<li class="chapter" data-level="14.8" data-path="markov-chains.html"><a href="markov-chains.html#birth-death-processes"><i class="fa fa-check"></i><b>14.8</b> Birth-death processes</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="continuous-time-stochastic-processes.html"><a href="continuous-time-stochastic-processes.html"><i class="fa fa-check"></i><b>15</b> Continuous Time Stochastic Processes</a>
<ul>
<li class="chapter" data-level="15.1" data-path="continuous-time-stochastic-processes.html"><a href="continuous-time-stochastic-processes.html#brownian-motion"><i class="fa fa-check"></i><b>15.1</b> Brownian Motion</a></li>
<li class="chapter" data-level="15.2" data-path="continuous-time-stochastic-processes.html"><a href="continuous-time-stochastic-processes.html#filtration"><i class="fa fa-check"></i><b>15.2</b> Filtration</a></li>
<li class="chapter" data-level="15.3" data-path="continuous-time-stochastic-processes.html"><a href="continuous-time-stochastic-processes.html#martingale"><i class="fa fa-check"></i><b>15.3</b> Martingale</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html"><i class="fa fa-check"></i><b>16</b> Stochastic calculus</a>
<ul>
<li class="chapter" data-level="16.1" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#stochastic-integrals"><i class="fa fa-check"></i><b>16.1</b> Stochastic Integrals</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#information"><i class="fa fa-check"></i><b>16.1.1</b> Information</a></li>
<li class="chapter" data-level="16.1.2" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#stochastic-integrals-1"><i class="fa fa-check"></i><b>16.1.2</b> Stochastic Integrals</a></li>
<li class="chapter" data-level="16.1.3" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#martingales"><i class="fa fa-check"></i><b>16.1.3</b> Martingales</a></li>
<li class="chapter" data-level="16.1.4" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#stochastic-calculus-and-the-ito-formula"><i class="fa fa-check"></i><b>16.1.4</b> Stochastic Calculus and the Ito Formula</a></li>
<li class="chapter" data-level="16.1.5" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#the-multidimensional-ito-formula"><i class="fa fa-check"></i><b>16.1.5</b> The multidimensional Ito Formula</a></li>
<li class="chapter" data-level="16.1.6" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#correlated-brownian-motions"><i class="fa fa-check"></i><b>16.1.6</b> Correlated Brownian motions</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#discrete-stochastic-integrals"><i class="fa fa-check"></i><b>16.2</b> Discrete Stochastic Integrals</a></li>
<li class="chapter" data-level="16.3" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#stochastic-differential-equations"><i class="fa fa-check"></i><b>16.3</b> Stochastic Differential Equations</a></li>
<li class="chapter" data-level="16.4" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#partial-differential-equations"><i class="fa fa-check"></i><b>16.4</b> Partial differential equations</a></li>
<li class="chapter" data-level="16.5" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#the-product-integral"><i class="fa fa-check"></i><b>16.5</b> The Product Integral</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#properties-of-the-product-integral"><i class="fa fa-check"></i><b>16.5.1</b> Properties of the Product Integral</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="linear-algebra.html"><a href="linear-algebra.html"><i class="fa fa-check"></i><b>17</b> Linear Algebra</a>
<ul>
<li class="chapter" data-level="17.1" data-path="linear-algebra.html"><a href="linear-algebra.html#invertible-matrices"><i class="fa fa-check"></i><b>17.1</b> Invertible matrices</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="coding.html"><a href="coding.html"><i class="fa fa-check"></i><b>18</b> Coding</a>
<ul>
<li class="chapter" data-level="18.1" data-path="coding.html"><a href="coding.html#r-packages"><i class="fa fa-check"></i><b>18.1</b> R-Packages</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="coding.html"><a href="coding.html#mlr3"><i class="fa fa-check"></i><b>18.1.1</b> mlr3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://joakim-bilyk.github.io/index.html">Back to main site</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Complete Theory</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probabilistic-machine-learning" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Chapter 9</span> Probabilistic Machine Learning<a href="probabilistic-machine-learning.html#probabilistic-machine-learning" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="supervised-learning" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Supervised Learning<a href="probabilistic-machine-learning.html#supervised-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter we restrict our selves to the area of <em>Supervised Learning</em> as we use numerical methods and machine learning algorithms to estimate models in a restricted framework. Take for instance the random forest, this algorithm’s estimation method is perfectly capable of being written recursively and so no “leaning” is done in the sense, that the calculations are predetermined from the algorithm. We therefore call the area of study supervised learning instead of the wider area of study <em>machine learning</em>. Let us define what we mean by supervised learning.</p>
<blockquote class="def">
<p><strong>Definition. (Supervised Learning)</strong> <em>Supervised learning is a field in machine learning that works with labeled data, i.e. data consisting of a set of features <span class="math inline">\(X\)</span>, and a response <span class="math inline">\(Y\)</span>. The goal is to learn a function <span class="math inline">\(m^*\)</span> that maps a given input <span class="math inline">\(x\)</span> to an output <span class="math inline">\(y\)</span>.</em></p>
</blockquote>
<p>We will in this chapter only use data in the form of a spread sheet e.g.</p>
<p><span class="math display">\[
\mathcal{D}_n=
\left(X_i, Y_i \right)_{i=1,...,n}=
\left[
\begin{array}{cccc|c}
X_{11} &amp; X_{12} &amp; \cdots &amp; X_{1p} &amp; Y_1\\
X_{21} &amp; X_{22} &amp; \cdots &amp; X_{2p} &amp; Y_2\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots\\
X_{n1} &amp; X_{n2} &amp; \cdots &amp; X_{np} &amp; Y_n
\end{array}
\right],
\]</span></p>
<p>we could however consider any data that may be interpreted by computer software.</p>
<p>The setting is then; assume that we have <span class="math inline">\(n\)</span> independent copies of the random variable <span class="math inline">\(D=(X,Y)\in \mathcal{X}\times \mathcal{Y}\)</span>, where <span class="math inline">\(X\)</span> is <span class="math inline">\(p\)</span>-dimensional and <span class="math inline">\(Y\)</span> is one-dimensional. We make no assumption on whether <span class="math inline">\(X_j\)</span>, <span class="math inline">\(j=1,..,p\)</span> and <span class="math inline">\(Y\)</span> are discrete or continuous, however in concrete cases this will be specified. We combine the sample of the <span class="math inline">\(n\)</span> observations in the matrix <span class="math inline">\(\mathcal{D}_n=(X_i,Y_i)_{i=1,...,n}\)</span> being a <span class="math inline">\(n\times p+1\)</span> matrix as in the above. We call <span class="math inline">\(\mathcal{D}_n\)</span> the <strong>training data</strong>.</p>
<p>This specification does indeed imply that <span class="math inline">\(D_i=(X_i,Y_i)\)</span> are iid. This is actually a bit controversial as we would expect that the distribution of <span class="math inline">\(D\)</span> will shift over time. For instance, the distribution of ages in a population changes over time and have been more right skewed as humanity advances. This may be accounted for by transforming the data such that the distribution becomes the same. This may be done in a variety of ways some example include: 1) transforming to uniform variable with the time dependent distribution <span class="math inline">\(F_t\)</span>, 2) normalizing using a price index and so forth. One should therefore start any analysis by ensuring that the data a given algorithm is trained on is iid.</p>
<p>The job becomes finding a good estimator such that we may predict <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span> i.e. <span class="math inline">\(Y\ \vert\ X\)</span>. Let us define what an estimator is.</p>
<blockquote class="def">
<p><strong>Definition. (Estimator)</strong> <em>Consider a training dataset <span class="math inline">\(\mathcal{D}_n\)</span>. A estimator <span class="math inline">\(m\)</span> is a function-valued mapping that takes <span class="math inline">\(\mathcal{D}_n\)</span> as input and associates a function <span class="math inline">\(m_n : \mathcal{X}\to \mathcal{Y}\)</span> i.e. <span class="math inline">\(m\)</span> takes the form</em></p>
<p><span class="math display">\[
m(\mathcal{D}_n)=m_n:\mathcal{X}\to \mathcal{Y}
\]</span></p>
<p><em>the class of estimators is called <span class="math inline">\(\mathcal{G}\)</span>.</em></p>
</blockquote>
<div id="what-is-a-good-estimator" class="section level3 hasAnchor" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> What is a good estimator?<a href="probabilistic-machine-learning.html#what-is-a-good-estimator" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>It is easy to construct an estimator <span class="math inline">\(\hat{m}\)</span> for instance by maximum likelihood esitmation, bayes optimization or simply by taking conditional expectations. We are however interested in two problems:</p>
<ol style="list-style-type: decimal">
<li>What is the best class of estimators <span class="math inline">\(\mathcal{G}_0\subset\mathcal{G}\)</span>,</li>
<li>In the subset of estimators <span class="math inline">\(m \in \mathcal{G}_0\)</span>, what is then the best estimator.</li>
</ol>
<p>We will now discuss the meaning of being the <em>“best”</em> estimator. Obviously, the first type of consideration is regarding the inherent restrictions of some algorithm, where the second is the problem of error comming from the restriction that we do not have infinite observations. We therefore have two problems namely the <strong>inductive bias</strong> from the class <span class="math inline">\(\mathcal{G}_0\)</span> and the <strong>estimation error</strong> from the available data. A typical problem is that the larger a class <span class="math inline">\(\mathcal{G}_0\)</span> gives low inductive bias we then may not be able to estimate anything and so the estimation error will be large. The converse also applies.</p>
<blockquote class="def">
<p><strong>Definition.</strong> <em>Let <span class="math inline">\(D=(X,Y)\)</span> be a random variable on the background space <span class="math inline">\((\Omega, \mathcal{F},P)\)</span>. Then we define the following:</em></p>
<ul>
<li><em>A <strong>decision rule</strong> is a deterministic function <span class="math inline">\(m:\mathcal{X}\to \mathcal{Y}\)</span>,</em></li>
<li><em>A <strong>loss function</strong> is a deterministic function <span class="math inline">\(L: \mathcal{Y}\times \mathcal{Y}\to \mathbb{R}_+\)</span>,</em></li>
<li><em>The <strong>risk</strong> of a decision rule <span class="math inline">\(m\)</span> is given a loss function <span class="math inline">\(L\)</span> is <span class="math inline">\(r(m)=E[L(Y,m(X))]\)</span>.</em></li>
</ul>
</blockquote>
<p>Notice that in the definition of risk we see that <span class="math inline">\(m\)</span> is included inside the expectation. This means in particular that the training data <span class="math inline">\(\mathcal{D}_n\)</span> is also accounted for i.e. by the tower rule we have</p>
<p><span class="math display">\[
r(m)=\mathbb{E}[L(Y,m(X))]=\mathbb{E}\left[\mathbb{E}\Big[L(Y,m_n(X))\ \Big\vert\ \mathcal{D}_n\Big]\right]:=\mathbb{E}\left[R(m)\right].
\]</span></p>
<p>Some widely used loss function include</p>
<ul>
<li>Quadratic loss function: <span class="math inline">\(L(y_1,y_2)=(y_1-y_2)^2\)</span>,</li>
<li>Poisson Deviance: <span class="math inline">\(L(y_1,y_2)=2\left(y_1\log\frac{y_1}{y_2}-y_1+y_2\right)\)</span>,</li>
<li>Binary loss function: <span class="math inline">\(L(y_1,y_2)=1_{y_1\ne y_2}\)</span>.</li>
</ul>
<p>Given a loss function <span class="math inline">\(L\)</span> we may find a (possibly non-unique) solution <span class="math inline">\(m^*\)</span> that minimizes <span class="math inline">\(R(m)\)</span>. We call this the <strong>Bayes estimator</strong>. The quantity <span class="math inline">\(R(m^*)\)</span> is called the <strong>Bayes risk</strong>. On some special case loss functions we may determine the unique solution.</p>
<blockquote class="lem">
<p><strong>Lemma.</strong> <em>Assume <span class="math inline">\(Y\)</span> is <span class="math inline">\(L_2\)</span> (square integrable), then the decision function that minimized the risk for the quadratic loss function is</em></p>
<p><span class="math display">\[
m^*=\underset{m}{\text{argmin}}\ \mathbb{E}[(Y-m(X))^2]=E[Y\ \vert\ X=x]
\]</span>
i.e. the conditional expectation.</p>
</blockquote>
<blockquote class="lem">
<p><strong>Lemma.</strong> <em>Assume <span class="math inline">\(\mathcal{Y}=\{1,...,K\}\)</span>, the decision function that minimizes the risk for the binary loss function satisfies</em></p>
<p><span class="math display">\[
m^*=\underset{m}{\text{argmin}}\ \mathbb{E}[1_{Y\ne m(X)}]=\underset{m}{\text{argmin}}\  \mathbb{P}(Y\ne m(X))=\underset{k=1,..,K}{\text{argmax}}\ \mathbb{P}(Y=k\ \vert\ X=x).
\]</span></p>
</blockquote>
<p>We can now define the prediction risk and the generalization error which relates to the balance of a sufficiently large class <span class="math inline">\(\mathcal{G}_0\)</span> and how effective the optimal estimator is conditional on the class <span class="math inline">\(\mathcal{G}_0\)</span>.</p>
<blockquote class="def">
<p><strong>Definition. (Conditional risk)</strong> <em>Let <span class="math inline">\(\mathcal{D}_n\)</span> be some training data. Given an estimator <span class="math inline">\(\hat{m}_n\)</span> we call</em></p>
<p><span class="math display">\[
R(\hat{m}_n)=\mathbb{E}[L(Y,\hat{m}_n(X))\ \vert\ \mathcal{D}_n]
\]</span></p>
<p><em>the prediction risk or conditional generalized error.</em></p>
</blockquote>
<blockquote class="def">
<p><strong>Definition. (Risk)</strong> <em>We call</em></p>
<p><span class="math display">\[
r(\hat{m}_n)=\mathbb{E}[R(\hat{m}_n)],
\]</span></p>
<p><em>the prediction risk or generalized error.</em></p>
</blockquote>
</div>
<div id="excess-risk" class="section level3 hasAnchor" number="9.1.2">
<h3><span class="header-section-number">9.1.2</span> Excess risk<a href="probabilistic-machine-learning.html#excess-risk" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote class="def">
<p><strong>Definition. (Excess Risk)</strong> <em>Consider the set <span class="math inline">\(\mathcal{G}\)</span> be the set of all measurable estimators. Fix a subset <span class="math inline">\(\mathcal{G}_0\subset\mathcal{G}\)</span>. Given some training data <span class="math inline">\(\mathcal{D}_n\)</span> consider the Bayes estimator restricted to <span class="math inline">\(\mathcal{G}_0\)</span> denoted by <span class="math inline">\(\hat{m}_n\)</span> and the unconditional Bayes estimator restricted to <span class="math inline">\(\mathcal{G}\)</span> we define the quantity</em></p>
<p><span class="math display">\[
R(\hat{m}_n)-r(m^*)
\]</span></p>
<p><em>or</em></p>
<p><span class="math display">\[
\mathbb{E}[R(\hat{m}_n)\ \vert\ X_1,...,X_n]-r(m^*),
\]</span></p>
<p><em>as the excess risk. This is the difference between the generalization error and the risk obtained by an optimal decision function.</em></p>
</blockquote>
<p>In the context of the above definition we can decompose the risk associated with the optimal estimator <span class="math inline">\(\hat{m}_n\in\mathcal{G}_0\)</span> into the estimation error and the inductive bias.</p>
<p><span class="math display">\[
R(\hat{m}_n)-r(m^*)=\underbrace{\left[R(\hat{m}_n)-\inf_{m\in\mathcal{G}_0}R(m)\right]}_{\text{estimation error}}+\underbrace{\left[\inf_{m\in\mathcal{G}_0}R(m)-R(m^*)\right].}_{\text{inductions bias/approximation error}}
\]</span>
where we have to balance the trade-off with a larger <span class="math inline">\(\mathcal{G}_0\)</span> infer a lower induction bias but larger estimation error and a smaller class <span class="math inline">\(\mathcal{G}_0\)</span> infer a lower estimation error but larger induction bias.</p>
<blockquote class="def">
<p><strong>Definition. (Empirical risk and empirical risk minimizer)</strong> <em>Given training data <span class="math inline">\(\mathcal{D}_n\)</span> and a loss function <span class="math inline">\(L\)</span>, we call</em></p>
<p><span class="math display">\[
\hat{R}_n(m):=\sum_{i=1}^nL(Y_i,m(X_i))
\]</span></p>
<p><em>the <strong>empirical risk</strong>. Given an additional function class <span class="math inline">\(\mathcal{G}_0\)</span>,</em></p>
<p><span class="math display">\[
\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \hat{R}_n(m)=\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \sum_{i=1}^nL(Y_i,m(X_i))
\]</span></p>
<p><em>is called <strong>empirical risk minimizer</strong> or (standard leaner).</em></p>
</blockquote>
<p>For larger function classes <span class="math inline">\(\mathcal{G}_0\)</span> the empirical risk minimizer might not be unique and possibly too noisy. In this case one sometimes adds a penalty term <span class="math inline">\(J_\lambda : \mathcal{G}\to \mathbb{R}_+\)</span> that penalizes the complexity of <span class="math inline">\(m\)</span> and minimizes the penalized empirical risk:</p>
<p><span class="math display">\[
\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \hat{R}_{n,\lambda}:=\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \sum_{i=1}^nL(Y_i,m(X_i)) + J_\lambda(m).
\]</span></p>
<p>If <span class="math inline">\(J_\lambda\)</span> and <span class="math inline">\(\hat{R}_n\)</span> is convex one can show that</p>
<p><span class="math display">\[
\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \hat{R}_{n,\lambda}=\underset{m\in\mathcal{G}_\eta}{\text{argmin}}\ \hat{R}_{n}
\]</span></p>
<p>for the class <span class="math inline">\(\mathcal{G}_\eta=\{m\in \mathcal{G}_0\ \vert\ J_\lambda(m)\le \eta\}\)</span>. Some penalty terms could be</p>
<ul>
<li><span class="math inline">\(J_\lambda(m)=\lambda\int m&#39;&#39;(x)\ dx\)</span>,</li>
<li><span class="math inline">\(J_\lambda(m)=\lambda \int\vert m&#39;(x)\vert\ dx\)</span>,</li>
<li><span class="math inline">\(J_\lambda(m)=\lambda \int(m(x))^2\ dx\)</span>.</li>
</ul>
<blockquote class="prop">
<p><strong>Proposition. (Probability bounds)</strong> <em>Let <span class="math inline">\(\tilde{m}=\underset{m}{\text{argmin}}\ r(m)\)</span>. We have</em></p>
<p><span class="math display">\[
r(\hat{m}_n)-r(\tilde{m})\le 2\sup_{m\in\mathcal{G}_0}\Big\vert\hat{R}_n(m) - r(m) \Big\vert,
\]</span></p>
<p><em>and for all <span class="math inline">\(\lambda \in \Lambda\)</span>,</em></p>
<p><span class="math display">\[
r(\hat{m}_{n,\lambda})-r(\tilde{m})\le 2\sup_{m\in\mathcal{G}_0}\Big\vert\hat{R}_{n,\lambda}(m) - r(m) \Big\vert + J_\lambda(\tilde{m})-J_\lambda(\hat{m}_n).
\]</span></p>
</blockquote>
<blockquote class="def">
<p><strong>Definition.</strong> <em>We say <span class="math inline">\(\hat{m}_n\)</span> is <span class="math inline">\(\varepsilon\)</span>-accurate with probabiltiy <span class="math inline">\(1-\delta\)</span>, if</em></p>
<p><span class="math display">\[
P\Big(R(\hat{m}_n)-\inf_{m\in\mathcal{G}}r(m)&gt;\varepsilon\Big)&lt;\delta.
\]</span></p>
</blockquote>
</div>
</div>
<div id="training-validating-and-testing" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Training, Validating and Testing<a href="probabilistic-machine-learning.html#training-validating-and-testing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When deciding which method too choose for a given task, one may like to pick the method with the smallest generalization error. However, most machine learning methods depend on hyper parameters and one may first need to decide which hyper parameters are best for the given task. In short: We would like to compare the generalization error of optimally tuned machine learning methods given our data.</p>
<blockquote class="def">
<p><strong>Definition. (Training and test set)</strong> <em>One often randomly divides the given data into training data and test data:</em></p>
<ul>
<li><span class="math inline">\(\mathcal{D}_n=(X_i,Y_i)_{i=1,...,n}\)</span> <em>(training data)</em></li>
<li><span class="math inline">\(\mathcal{T}_m=(\tilde{X}_j,\tilde{Y}_j)_{j=1,...,m}\)</span> <em>(test data)</em></li>
</ul>
<p><em>with <span class="math inline">\(n\in[0.8m,0.95m]\)</span>.</em></p>
</blockquote>
<blockquote class="def">
<p><strong>Definition. (Training and test error)</strong> <em>The empirical risk on the training data is called training error and on the test data test error.</em></p>
</blockquote>
<blockquote class="def">
<p><strong>Definition. (Validation set)</strong> <em>To tune the hyper parameters for an algorithm, one often randomly divides the given training data into training data (yes: also called training data.) and validation data:</em></p>
<ul>
<li><span class="math inline">\(\mathcal{D}_{n_1}=(X_i,Y_i)_{i=\tau(1),...,\tau(n_1)}\)</span> <em>(traning data)</em></li>
<li><span class="math inline">\(\mathcal{V}_{n_2}=(\tilde{X}_j,\tilde{Y}_j)_{j=\tau(n_1+1),...,\tau(n)}\)</span> <em>(validation data)</em></li>
</ul>
<p><em>where <span class="math inline">\(\tau\)</span> is a randomly picked permutation of <span class="math inline">\(\{1,...,n\}\)</span> and <span class="math inline">\(n_1+n_2=n\)</span> is respectively the size of the training set and the validation set.</em></p>
</blockquote>
<p>One can now compare different methods via the following simple algorithm:</p>
<ol style="list-style-type: decimal">
<li>Split your data into train, validation and test set.</li>
<li>For a given method and a rich set of hyper parameter configurations train the method on the training set and compare performance via empirical risk on the validation set.</li>
<li>For every method, pick the hyper parameter with the smallest empirical risk.</li>
<li>Compare different methods with the chosen hyper parameters on the test set (trained on training+validation set) and pick the method with smallest empirical risk.</li>
</ol>
<p>Notice that the procedure above is stochastic and has bias and variance both for selecting the optimal hyper parameters and for selecting the optimal method.</p>
<ul>
<li>Bias: Bias occurs because the sample sizes used for learning the hyper parameters <span class="math inline">\(n_1\)</span> are smaller than the actual training size <span class="math inline">\(n\)</span> and also the full data size <span class="math inline">\(n+m\)</span>.</li>
<li>Variance: The results are stochastic because the validation and test set are not of infinite size.</li>
</ul>
<p>Variance can be reduced by repeating steps 1-4 several times. The most popular method for doing so is (nested) cross validation.</p>
<div id="estimating-risk" class="section level3 hasAnchor" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Estimating risk<a href="probabilistic-machine-learning.html#estimating-risk" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We want to estimate the generalization error of a method <span class="math inline">\(\hat{m}_{n,\lambda}\)</span> that depends on a fixed hyper parameter <span class="math inline">\(\lambda\)</span>.</p>
<blockquote class="def">
<p><strong>Definition. (M-fold Cross validation)</strong> <em>Given the indices of a data set <span class="math inline">\(S=\{1,...,n\}\)</span>, M-fold cross validation follows the following steps:</em></p>
<ol style="list-style-type: decimal">
<li><em>Divide the data into <span class="math inline">\(M\)</span> disjoint sets <span class="math inline">\(S_1,...,S_M\)</span> of same size. Define <span class="math inline">\(S_{-l}=\cup_{k\ne l}S_k\)</span> being the complement to <span class="math inline">\(S_l\)</span>. (<span class="math inline">\(\#S_l=n/M\)</span> and <span class="math inline">\(\#S_{-l}=(M-1)n/M\)</span>)</em></li>
<li><em>For each subdivision <span class="math inline">\(l=1,...,M\)</span> train the algorithm on <span class="math inline">\(S_{-l}\)</span> and denote the estimator <span class="math inline">\(\hat{m}_\lambda(S_{-l})\)</span>.</em></li>
<li><em>Calculate the cross validated empirical risk</em>
<span class="math display">\[
  CV(\hat{m}_{n,\lambda})=\frac{1}{M}\sum_{l=1}^M\frac{1}{\vert S_{-l}\vert}\sum_{i\in S_{-l}}L\big(Y_i,\hat{m}_\lambda(S_{-l})(X_i)\big)
  \]</span></li>
</ol>
</blockquote>
<p>It is a non-trivial discussion what <span class="math inline">\(CV(\hat{m}_{n,\lambda})\)</span> is estimating. Consider the heuristic
<span class="math display">\[\begin{align*}
CV(\hat{m}_{n,\lambda})&amp;=\frac{1}{M}\sum_{l=1}^M\frac{1}{\vert S_{-l}\vert}\sum_{i\in S_{-l}}L\big(Y_i,\hat{m}_\lambda(S_{-l})(X_i)\big)\\
&amp;\approx \frac{1}{M}\sum_{l=1}^MR\big(Y,\hat{m}_\lambda(S_{-l})(X)\big)\\
&amp;\approx \mathbb{E}\left[R\big(Y,\hat{m}_\lambda(S_{-l})(X)\big)\right].
\end{align*}\]</span>
Where we used the law of large numbers in the first approximation. The last approximation is not so clear because the summands are dependent for <span class="math inline">\(M&gt;2\)</span>.</p>
<p>The bias is minimal for large <span class="math inline">\(M\)</span> since estimation is based on training the algorithm on <span class="math inline">\((M-1)n/M\)</span> data points. In the case that <span class="math inline">\(M=n\)</span>, M-fold cross validation is also known as leave-one-our cross validation. It is however often not practical because of the computational cost. In practice, setting <span class="math inline">\(M=5\)</span> or <span class="math inline">\(M=10\)</span> is common choices.</p>
<p>When deciding on an optimal hyper parameter we would like to pick</p>
<p><span class="math display">\[
\underset{\lambda \in \Lambda}{\text{argmin}}\ CV(\hat{m}_{n,\lambda}).
\]</span></p>
<p>But the hyper parameter space <span class="math inline">\(\Lambda\)</span> is often multi-dimensional and partly continuous. Hence it is infeasible to try out all parameters. Common practice are</p>
<ul>
<li>Grid search</li>
<li>Random search (e.g. pick 200 parameters uniformly random from the parameter space)</li>
<li>Advanced optimization techniques (i.e. techniques that aim to find the minimzer of a function (here: cross validated empirical risk) without the requirement of knowing the analytical form of the function to optimize.</li>
</ul>
<p>Above we have discussed how we can use cross validation to pick an optimal parameter for a given method and data set. But how to choose between different methods? One popular way is nested cross validation comprising an inner loop for hyper parameter selection (tuning) and an outer loop for method comparison. Assume that we want to compare <span class="math inline">\(J\)</span> methods <span class="math inline">\(\hat{m}_{n,j}\)</span>, <span class="math inline">\(j=1,...,J\)</span>. then we may use nested cross validation.</p>
<blockquote class="def">
<p><strong>Definition. (Nested <span class="math inline">\(M_1-M_2\)</span> Cross-validation)</strong> <em>Given the indices of a data set <span class="math inline">\(S=\{1,...,n\}\)</span>, nested <span class="math inline">\(M_1-M_2\)</span> cross validation follows the following steps:</em></p>
<ol style="list-style-type: decimal">
<li><em>Divide the data into <span class="math inline">\(M_1\)</span> disjoint sets <span class="math inline">\(S_1,...,S_{M_1}\)</span> of same size. Define <span class="math inline">\(S_{-l}=\cup_{k\ne l}S_k\)</span> being the complement to <span class="math inline">\(S_l\)</span>. (<span class="math inline">\(\#S_l=n/M_1\)</span> and <span class="math inline">\(\#S_{-l}=(M_1-1)n/M_1\)</span>)</em></li>
<li><em>For each <span class="math inline">\(l=1,...,M_1\)</span>, run <span class="math inline">\(M_2\)</span>-fold cross validation on <span class="math inline">\(S_{-l}\)</span> for all <span class="math inline">\(J\)</span> methods, returning optimal hyper parameters <span class="math inline">\(\hat{\lambda}(j,l)\)</span>, <span class="math inline">\(j=1,...,J\)</span> and <span class="math inline">\(l=1,...,M_1\)</span>. (the one with lowest <span class="math inline">\(CV\)</span> is choosen for each <span class="math inline">\((j,l)\)</span>)</em></li>
<li><em>Calculate the cross validated empirical risk</em>
<span class="math display">\[
  CV(\hat{m}_{n,j})=\frac{1}{M_1}\sum_{l=1}^{M_1}\frac{1}{\vert S_{-l}\vert}\sum_{i\in S_l}L\big(Y_i,\hat{m}_{\lambda(j,l)}(S_{-l})(X_i)\big)
  \]</span></li>
<li><em>Pick the method with the smallest risk (and possibly tune again for fitting)</em></li>
</ol>
</blockquote>
</div>
</div>
<div id="linear-models" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Linear Models<a href="probabilistic-machine-learning.html#linear-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We may take the linear model as a case study of the methods introduced in the above chapter. As such we consider the squaed loss <span class="math inline">\(L(y_1,y_2)=(y_1-y_2)^2\)</span> for which we already know the Bayes rule:</p>
<p><span class="math display">\[
m^*(x)=\underset{m}{\text{argmin}}\ R(m)=\mathbb{E}[Y\ \vert\ X=x].
\]</span></p>
<p>The linear model has the following assumptions. There exists paramaters <span class="math inline">\(\beta_0^*,\beta_1^*,...,\beta_p^*\)</span>, with</p>
<p><span class="math display">\[
m^*(x)=\beta_0^*+\sum_{j=1}^{p}\beta_j^*x_j.
\]</span></p>
<p>In other words, we assume that <span class="math inline">\(m^*\)</span> is a linear function, i.e.,</p>
<p><span class="math display">\[
m^*\in\mathcal{G}=\{f : \mathbb{R}^p\to \mathbb{R}\ \vert\ f(x)=\beta^\top x\}.
\]</span></p>
<p>Given iid training data <span class="math inline">\((X_i,Y_i)_{i=1,...,n}\)</span> we have an additive noise model</p>
<p><span class="math display">\[
Y_i=\beta_0^*+\sum_{j=1}^{p}\beta_j^*X_{ij}+\varepsilon_i,
\]</span></p>
<p>with <span class="math inline">\(\varepsilon_i=Y_i-m^*(X_i)\)</span> and hence iid with <span class="math inline">\(\mathbb{E}[\varepsilon_i\ \vert\ X_i]=0\)</span>.</p>
<p>Notice, that since we are assuming <span class="math inline">\(m^*\in\mathcal{G}\)</span> we have by assumption no inductive bias and we therefore only consider estimation error i.e.</p>
<p><span class="math display">\[
R(\hat{m}_n)-r(m^*).
\]</span></p>
<p>Given the training data we may approximate the coefficients using the following.</p>
<blockquote class="lem">
<p><strong>Lemma. (Coefficients in the linear model)</strong> <em>Under the Linear model assumption we have for <span class="math inline">\(j=1,...,p\)</span></em></p>
<p><span class="math display">\[
\beta^*_j=\frac{\text{Cov}\Big(X_{1j},Y_1-\sum_{k\in \{1,...,p\}\setminus \{j\}} \beta_k^*X_{1k}\Big)}{\text{Var}(X_{1j})}
\]</span></p>
<p><em>In particular, if the components of <span class="math inline">\(X\)</span> are uncorrelated, we have</em></p>
<p><span class="math display">\[
\beta_j^*=\frac{\text{Cov}(X_{1j},Y_1)}{\text{Var}(X_{1j})}.
\]</span></p>
</blockquote>
<blockquote class="lem">
<p><strong>Lemma. (Bayes risk in the linear model)</strong> <em>Under the Linear model assumption we have</em></p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(r(m^*)=\text{Var}(\varepsilon_i)\)</span></li>
<li>For <span class="math inline">\(m(x)=\beta_0+\sum_{j=1}^p \beta_jx_j\)</span>,
<span class="math display">\[
  r(m)-r(m^*)=\Vert\Sigma^{1/2}(\beta -\beta^*) \Vert^2_2.
  \]</span></li>
</ol>
</blockquote>
<div id="least-squares-estimator" class="section level3 hasAnchor" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> Least Squares Estimator<a href="probabilistic-machine-learning.html#least-squares-estimator" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Moving forward we will assume <span class="math inline">\(\beta_0^*=0\)</span> since we can always translate the data and make the centered around 0. We will furthermore use the notation:</p>
<p><span class="math display">\[
\mathbf{X}=
\begin{bmatrix}
X_{11} &amp; \cdots &amp; X_{1p}\\
\vdots &amp; \ddots &amp; \vdots\\
X_{n1} &amp; \cdots &amp; X_{np}
\end{bmatrix},\hspace{10pt} \mathbf{Y}=
\begin{pmatrix}
Y_1\\
\vdots\\
Y_n
\end{pmatrix},\hspace{10pt} \varepsilon=
\begin{pmatrix}
\varepsilon_1\\
\vdots\\
\varepsilon_n
\end{pmatrix}.
\]</span></p>
<p>In this cases the empirical risk takes the form</p>
<p><span class="math display">\[
\hat{R}_n(m)=\frac{1}{n}\Vert\mathbf{Y}-\mathbf{X}\beta \Vert^2_2.
\]</span></p>
<blockquote class="lem">
<p><strong>Lemma. (Least squares estimator)</strong></p>
<ul>
<li><em>It holds that <span class="math inline">\((\mathbf{X}^\top\mathbf{X})\hat{\beta}=\mathbf{X}^\top \mathbf{Y}\)</span>,</em></li>
<li><em>If <span class="math inline">\(\mathbf{X}\)</span> has full rank, then</em>
<span class="math display">\[
  \hat{\beta}_n^{LS}=(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top \mathbf{Y}.
  \]</span></li>
</ul>
</blockquote>
<blockquote class="thm">
<p><strong>Theorem. (Excess risk Least squares estimator)</strong> <em>If <span class="math inline">\(\mathbf{X}^\top\mathbf{X}\)</span> is invertible, then</em></p>
<p><span class="math display">\[
\mathbb{E}[R(\hat{m}_n^{LS})\ \vert\ \mathbf{X}]-r(m^*)=\frac{\sigma^2}{n}\cdot \text{tr}\left(\Sigma\hat{\Sigma}^{-1}\right)
\]</span></p>
<p><em>with <span class="math inline">\(\Sigma=\mathbb{E}[\mathbf{X}^\top\mathbf{X}]\)</span> and <span class="math inline">\(\hat{\Sigma}=\frac{1}{n}\mathbf{X}^\top\mathbf{X}\)</span>.</em></p>
</blockquote>
<details>
<summary>
<strong>Proof.</strong>
</summary>
<p><span class="math display">\[
\hat{\beta}^{LS}=\left(\mathbf{X}^T \mathbf{X}\right)^{-1} \mathbf{X}^T \mathbf{Y}=\left(\mathbf{X}^T \mathbf{X}\right)^{-1} \mathbf{X}^T \mathbf{X} \beta^*+\left(\mathbf{X}^T \mathbf{X}\right)^{-1} \mathbf{X}^T \mathbf{\varepsilon}=\beta^*+\left(\mathbf{X}^T \mathbf{X}\right)^{-1} \mathbf{X}^T \mathbf{\mathbf { \varepsilon }}.
\]</span></p>
<p>Thus
<span class="math display">\[\begin{align*}
R\left(\hat{m}^{LS}\right)-r\left(m^*\right) &amp; =\left\|\Sigma^{1 / 2}\left(\hat{\beta}^{L S}-\beta^*\right)\right\|_2^2=\left\|\Sigma^{1 / 2}\left(\mathbf{X}^T \mathbf{X}\right)^{-1} \mathbf{X}^T \mathbf{\varepsilon}\right\|_2^2=n^{-1}\left\|n^{-1/2}\Sigma^{1 / 2} \hat{\Sigma}^{-1} {\mathbf{X}^T \mathbf{\varepsilon}}\right\|_2^2 \\
&amp; =n^{-1}\|A \mathbf{\varepsilon}\|_2^2,
\end{align*}\]</span>
where <span class="math inline">\(\hat \Sigma=n^{-1} \mathbf{{X^T}X}, A:=n^{-1/2}\Sigma^{1 / 2} \hat{\Sigma}^{-1} {\mathbf{X}^T}\)</span>. We calculate the excess risk conditional on <span class="math inline">\(\mathbf{X}\)</span>. Note that <span class="math inline">\(\operatorname{tr}(\cdot)\)</span> is linear and invariant under cyclic permutations. We have
<span class="math display">\[\begin{align*}
\mathbb{E}\left[R\left(\hat{m}^{LS}\right) \mid \mathbf{X}\right]-r\left(m^*\right) &amp; =n^{-1} \mathbb{E}\left[\|A \mathbf{\varepsilon}\|_2^2 \mid \mathbf{X}\right] \\
&amp; =n^{-1} \mathbb{E}\left[\operatorname{tr}\left(A \mathbf{\varepsilon \varepsilon}^T A^T\right) \mid \mathbf{X}\right]=n^{-1} \operatorname{tr}(A \underbrace{\mathbb{E}\left[\mathbf{\varepsilon \varepsilon}^T\right]}_{=\sigma^2 I_{p \times p}} A^T)=\frac{\sigma^2}{n}\|A\|_F^2 \\
&amp; =\frac{\sigma^2}{n} \cdot \operatorname{tr}\left(\Sigma^{1 / 2} \hat{\Sigma}^{-1} \hat{\Sigma} \hat{\Sigma}^{-1} \Sigma^{1 / 2}\right) \\
&amp; =\frac{\sigma^2}{n} \cdot \operatorname{tr}\left(\Sigma \hat{\Sigma}^{-1}\right) .
\end{align*}\]</span>
as desired. <span class="math inline">\(\blacksquare\)</span></p>
</details>
<p>From the above it follos that if <span class="math inline">\(\hat{\Sigma}\approx \Sigma\)</span> then</p>
<p><span class="math display">\[
\mathbb{E}[R(\hat{m}_n^{LS})\ \vert\ \mathbf{X}]-r(m^*)\approx\frac{\sigma^2p}{n}.
\]</span></p>
<p>This approximation does not take into account the variation of <span class="math inline">\(X\)</span>. Due to the inverse, it is not easily possible to derive an upper bound for the expectation of <span class="math inline">\(\hat{\Sigma}^{-1}\)</span>. Therefore, we only obtain a result for the excess Bayes risk which holds with high probability and under additional assumptions (which could be relaxed but would lead to much more complicated proofs).</p>
<blockquote class="thm">
<p><strong>Theorem. (PAC Least squares estimator)</strong> <em>We do not assume a linear model. Let <span class="math inline">\(m(x)=E[Y\ \vert\ X=x]\)</span> and assume <span class="math inline">\(m^*(x)=x\Sigma^{-1}E[YX]\)</span> is the best linear approximation. Assume that <span class="math inline">\(X\)</span> has bounded support and sub-Gaussian noise, i.e., there exists a <span class="math inline">\(\sigma\)</span> such that for all <span class="math inline">\(t\)</span>:</em></p>
<p><span class="math display">\[
E[e^{tx}\ \vert\ X=x]\le e^{t^2\sigma^2/2},
\]</span></p>
<p><em>then for <span class="math inline">\(n\)</span> big enough, and <span class="math inline">\(t&gt;\max\{0,2.6-\log p\}\)</span></em></p>
<p><span class="math display">\[
P\left(r(\hat{m}^{LS})-r(m^*)\ge \frac{2 A}{n}(1+\sqrt{8t})^2+\frac{\sigma^2(p+2\sqrt{pt}+2t)}{n} + o(1/n)\right)\le 3e^{-t}
\]</span></p>
<p><em>where <span class="math inline">\(A=\mathbb{E}\left[\Vert\Sigma^{1/2}X(m(X)-\beta^\top X) \Vert^2\right]\)</span> is an approximation error.</em></p>
</blockquote>
<p>Up until now we have assumed that <span class="math inline">\(\mathbf{X}\)</span> has full rank. This is not very realistic for very large <span class="math inline">\(p\)</span> (<span class="math inline">\(p&gt; &gt; n\)</span>). Even if <span class="math inline">\(\mathbf{X}^\top\mathbf{X}\)</span> is invertible, the variance of the estimation error might be too large. This leads us to penalized models that reduce variance by adding some bias. Other alternatives (not discussed here) are dimension reduction, say via PCA, or feature selection, say forward stepwise regression.</p>
</div>
<div id="ridge-regression" class="section level3 hasAnchor" number="9.3.2">
<h3><span class="header-section-number">9.3.2</span> Ridge Regression<a href="probabilistic-machine-learning.html#ridge-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote class="def">
<p><strong>Definition. (Ridge regression)</strong> <em>Let <span class="math inline">\(\lambda \geq 0\)</span> and</em></p>
<p><span class="math display">\[
J_\lambda(\beta)=\lambda\|\beta\|_2^2=\lambda \sum_{j=1}^p \beta_j^2.
\]</span></p>
<p><em>The Ridge estimator is defined as </em>
<span class="math display">\[\begin{align*}
\hat{\beta}_\lambda^{\text {ridge }} &amp; =\underset{\beta \in \mathbb{R}^p}{\arg \min }\left\{\hat{R}_n(\beta)+J_\lambda(\beta)\right\} \\
&amp; =\underset{\beta \in \mathbb{R}^p}{\arg \min }\left\{\|\mathbf{Y}-\mathbf{X} \beta\|_2^2+\lambda\|\beta\|_2^2\right\} .
\end{align*}\]</span>
<em>The corresponding algorithm is</em></p>
<p><span class="math display">\[
\hat{m}_{n, \lambda}^{\text {ridge }}(x)=\sum_{j=1}^p \hat{\beta}^\text{ridge}_{\lambda, j} x_j.
\]</span></p>
</blockquote>
<blockquote class="lem">
<p><strong>Lemma. (Ridge regression solution)</strong> <em>Let <span class="math inline">\(\lambda&gt;0\)</span>. Then </em></p>
<span class="math display">\[
\hat{\beta}^\text{ridge}_\lambda=\left(\mathbf{X}^T \mathbf{X}+\lambda n I_{p \times p}\right)^{-1} \mathbf{X}^T \mathbf{Y}
\]</span>
</blockquote>
<p>In ridge regression, the matrix <span class="math inline">\(\mathbf{X}^T \mathbf{X}\)</span> is ‘made invertible’ by adding a positive multiple of the identity matrix. Therefore, the ridge estimator also can be used in the case <span class="math inline">\(p&gt;n\)</span>. The name ‘ridge’ stems from the fact that the optimization problem is equivalent to</p>
<p><span class="math display">\[
\min _{ \beta \in \mathbb{R}^p} \hat{R}_n(X\beta) \quad \text { s.t. } \quad\|\beta\|_2 \leq t
\]</span></p>
<p>for some suitable <span class="math inline">\(t&gt;0\)</span>.</p>
<blockquote class="thm">
<p><strong>Theorem. (Excess risk for ridge regression estimator)</strong> <em>Under the linear model, </em></p>
<p><span class="math display">\[
\mathbb E[ R\left(\hat{m}^{n,\text{ridge}}_\lambda \right)|X]-r\left(m^*\right)=\frac{\sigma^2}{n} \cdot \operatorname{tr}\left(\Sigma\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \hat{\Sigma}\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1}\right)+\lambda^2\left\|\Sigma^{1 / 2}\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \beta^*\right\|_2^2.
\]</span></p>
<p><em>Let <span class="math inline">\(\Sigma=U D U^T\)</span> be the spectral decomposition of <span class="math inline">\(\Sigma\)</span> with orthogonal matrix <span class="math inline">\(U\)</span> and diagonal matrix <span class="math inline">\(D=\operatorname{diag}\left(s_1, \ldots, s_p\right.\)</span> ) (entries are the eigenvalues of <span class="math inline">\(\Sigma\)</span> ). By assuming <span class="math inline">\(\hat \Sigma= \Sigma\)</span>, the excess risk simplifies to </em></p>
<span class="math display">\[
\frac{\sigma^2}{n} \sum_{j=1}^p \frac{s_j^2}{\left(s_j+\lambda\right)^2}+\lambda^2 \cdot \sum_{j=1}^p \frac{s_j\left(U^T \beta^*\right)_j^2}{\left(s_j+\lambda\right)^2}.
\]</span>
</blockquote>
<details>
<summary>
<strong>Proof.</strong>
</summary>
<p><span class="math display">\[\begin{align*}
\hat{\beta}_\lambda-\beta^* &amp; =-\lambda n\left(\mathbf{X}^T \mathbf{X}+\lambda n I_{p \times p}\right)^{-1} \beta^*+\left(\mathbf{X}^T \mathbf{X}+\lambda n I_{p\times p}\right)^{-1} \mathbf{X}^T \mathbf{\varepsilon} \\
&amp; =-\lambda\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \beta^*+\frac{1}{n}\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \mathbf{X}^T \mathbf{\varepsilon}
\end{align*}\]</span>.
thus</p>
<p><span class="math display">\[
R\left(\hat{\beta}_\lambda\right)-R\left(\beta^*\right)=\left\|B-\frac{1}{\sqrt{n}} A \mathbf{\varepsilon}\right\|_2^2=\|B\|_2^2-\frac{2}{\sqrt{n}}\langle B, A\varepsilon \rangle+\frac{1}{n}\|A \mathbb{\mathbf { \varepsilon }}\|_2^2
\]</span></p>
<p>where <span class="math inline">\(A=\Sigma^{1 / 2}\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \frac{\mathbf{X}^T}{\sqrt{n}}\)</span> and <span class="math inline">\(B:=\lambda \Sigma^{1 / 2}\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \beta^*\)</span>. Since <span class="math inline">\(\mathbb{E} \mathbf{\varepsilon}=0\)</span>, we have
<span class="math display">\[\begin{align*}
\mathbb{E}\left[R\left(\hat{\beta}_\lambda\right) \mid \mathbf{X}\right]-R\left(\beta^*\right) &amp; =\frac{\sigma^2}{n}\|A\|_F^2+\|B\|_2^2 \\
&amp; =\frac{\sigma^2}{n} \cdot \operatorname{tr}\left(\Sigma\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \hat{\Sigma}\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1}\right)\\
&amp;+\lambda^2\left\|\Sigma^{1 / 2}\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \beta^*\right\|_2^2
\end{align*}\]</span>
Furthermore, assuming <span class="math inline">\(\hat \Sigma= \Sigma\)</span> the above expression simplifies to
<span class="math display">\[\begin{align*}
&amp;\frac{\sigma^2}{n} \cdot \operatorname{tr}\left(\Sigma\left(\Sigma+\lambda I_{p \times p}\right)^{-1} \Sigma\left(\Sigma+\lambda I_{p \times p}\right)^{-1}\right)+\lambda^2\left\|\Sigma^{1 / 2}\left(\Sigma+\lambda I_{p \times p}\right)^{-1} \beta^*\right\|_2^2 \\
=&amp;\frac{\sigma^2}{n} \cdot \operatorname{tr}\left(D\left(D+\lambda I_{p \times p}\right)^{-1} D\left(D+\lambda I_{p \times p}\right)^{-1}\right)+\lambda^2\left\|D^{1 / 2}\left(D+\lambda I_{p \times p}\right)^{-1} U^T \beta^*\right\|_2^2 \\
=&amp;\frac{\sigma^2}{n} \sum_{j=1}^p \frac{s_j^2}{\left(s_j+\lambda\right)^2}+\lambda^2 \cdot \sum_{j=1}^p \frac{s_j\left(U^T \beta^*\right)_j^2}{\left(s_j+\lambda\right)^2}
\end{align*}\]</span></p>
<p>and the result follows. <span class="math inline">\(\blacksquare\)</span></p>
</details>
<p>If all eigenvalues are equal, that is, <span class="math inline">\(s_j=s\)</span> and if additionally <span class="math inline">\(\left(U^T \beta^*\right)_j=b(j=1, \ldots, p)\)</span>, then the expression of the theorem simplifies to</p>
<p><span class="math display">\[
\frac{\sigma^2 p}{n} \cdot \frac{s^2}{(s+\lambda)^2}+\lambda^2 \frac{s b^2 p}{(s+\lambda)^2} \underset{\lambda=\frac{\sigma^2/n}{b^2}}{\stackrel{\min }{\rightarrow}} \frac{\sigma^2 p}{n} \cdot \frac{b^2 s}{\frac{\sigma^2}{n}+b^2 s} \leq \frac{\sigma^2 p}{n} .
\]</span></p>
<p>We see that for a suitable choice of the penalization parameter <span class="math inline">\(\lambda\)</span>, the excess Bayes risk of the ridge estimator can be smaller than the corresponding upper bound of the LS estimator.</p>
</div>
<div id="lasso-regression" class="section level3 hasAnchor" number="9.3.3">
<h3><span class="header-section-number">9.3.3</span> Lasso Regression<a href="probabilistic-machine-learning.html#lasso-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we believe that some covariates are pure noise, i.e., unrelated to <span class="math inline">\(Y\)</span>, the most obvious choice to penalize <span class="math inline">\(\beta\)</span> would be of the form <span class="math inline">\(\|\beta\|_0=\#\{j=\)</span> <span class="math inline">\(\left.{1, \ldots, p: \beta_j} \neq 0\right\}\)</span>. Then, one would simply penalize the number of non-zero entries of <span class="math inline">\(\beta\)</span>. However, this leads to an NP-hard optimization problems whose solutions are not accessible in practice. One therefore uses a different norm which has similar properties but leads to a convex optimization problem.</p>
<blockquote class="def">
<p><strong>Definition. (Lasso - Least absolute shrinkage and selection operator regression)</strong> <em>Let <span class="math inline">\(\lambda \geq 0\)</span> and </em></p>
<p><span class="math display">\[
J_\lambda(\beta)=\lambda \cdot\|\beta\|_1=\lambda \sum_{j=1}^p\left|\beta_j\right| .
\]</span></p>
<p><em>The LASSO estimator is given by </em>
<span class="math display">\[\begin{align*}
\hat{\beta}_\lambda^{\text {lasso }} &amp; \in \underset{\beta \in \mathbb{R}^p}{\arg \min }\left\{\hat{R}_n(X\beta)+J_\lambda(X\beta)\right\} \\
&amp; =\underset{\beta \in \mathbb{R}^p}{\arg \min }\left\{\frac{1}{n}\|\mathbf{Y}-\mathbf{X} \beta\|_2^2+\lambda \cdot\|\beta\|_1\right\}
\end{align*}\]</span>
<em>The corresponding algorithm reads </em></p>
<p><span class="math display">\[
\hat{m}_{n, \lambda}^{l a s s o}(x)=\sum_{j=1}^p \hat{\beta}^{\text{lasso}}_{\lambda, j} x_j.
\]</span></p>
</blockquote>
<p>There exists no easy closed-form solution for <span class="math inline">\(\hat \beta^{\text{lasso}}_{\lambda}\)</span> besides some special cases.</p>
<p>For <span class="math inline">\(\beta \in \mathbb{R}^p\)</span>, define</p>
<p><span class="math display">\[
S(\beta):=\left\{j \in\{1, \ldots, p\}: \beta_j \neq 0\right\}.
\]</span></p>
<p>For <span class="math inline">\(S \subset\{1, \ldots, p\}\)</span> and <span class="math inline">\(v \in \mathbb{R}^p\)</span>, put <span class="math inline">\(v_S:=\left(v_j \mathbb{1}_{\{j \in S\}}\right)_{j=1, \ldots, p}\)</span></p>
<p>If <span class="math inline">\(p \ll n\)</span>, then <span class="math inline">\(\hat{\Sigma}\)</span> would usually be invertible and the smallest eigenvalue (Rayleigh quotient) would satisfy</p>
<p><span class="math display">\[
\lambda_{\min }(\hat{\Sigma}):=\inf _{v \in \mathbb{R}^p} \frac{v^T \hat{\Sigma} v}{\|v\|_2^2}&gt;0.
\]</span></p>
<p>Then <span class="math inline">\(\hat{\Sigma}\)</span> would be one-to-one (injective) and the linear equation system <span class="math inline">\(\hat{\Sigma} \beta=\frac{1}{n} \mathbf{X}^T \mathbf{Y}\)</span> would lead to the (unique) least squares estimator.</p>
<p>For <span class="math inline">\(p \gg n\)</span>, one has <span class="math inline">\(\lambda_{\min }(\hat{\Sigma})=0\)</span>.</p>
<p>When employing LASSO, we are usually only interested in estimators <span class="math inline">\(\hat{\beta}\)</span> whith non-zero entries at the components <span class="math inline">\(S\left(\beta^*\right)\)</span>. This means that in principle we only need injectivity of <span class="math inline">\(\hat{\Sigma}\)</span> on the set</p>
<p><span class="math display">\[
\tilde{C}=\left\{\beta \in \mathbb{R}^p: S(\beta)=S\left(\beta^*\right)\right\}=\left\{\beta \in \mathbb{R}^p:\left\|\beta_{S\left(\beta^*\right)^ c}\right\|_1=0\right\},
\]</span></p>
<p>or equivalently, <span class="math inline">\(\inf _{v \in \tilde{C}} \frac{v^T \hat{\Sigma} v}{\|v\|_2^2}=\inf _{v \in \tilde{C}} \frac{v^T \hat{\Sigma} v}{\left\|v_{S\left(\beta^*\right)}\right\|_2^2}&gt;0 .\)</span></p>
<blockquote class="def">
<p><strong>Definition. (Restricted eigenvalue property (REP))</strong> <em>We say that the restricted eigenvalue property (REP) is satisfied with <span class="math inline">\(\alpha&gt;0\)</span> if for</em></p>
<p><span class="math display">\[
C:=\left\{\beta \in \mathbb{R}^p:\left\|\beta_{S\left(\beta^*\right)^c}\right\|_1 \leq \alpha \left\|\beta_{S\left(\beta^*\right)}\right\|_1\right\}
\]</span></p>
<p><em>it holds that</em></p>
<p><span class="math display">\[
\Lambda_{\min }(\Sigma):=\inf _{v \in C} \frac{v^T \Sigma v}{\left\|v_{S\left(\beta^*\right)}\right\|_2^2}&gt;0,
\]</span></p>
</blockquote>
<blockquote class="thm">
<p><strong>Theorem.</strong> <em>Let <span class="math inline">\(\varepsilon \sim N\left(0, \sigma^2\right), X \sim N(0, \Sigma)\)</span> and <span class="math inline">\(\Sigma_{j j}=1(j=1, \ldots, p)\)</span>. Define <span class="math inline">\(s:=\# S\left(\beta^*\right)\)</span>. Then there exist universal constants <span class="math inline">\(c_1, c_2&gt;0\)</span> such that the condition</em></p>
<p><span class="math display">\[
n \geq c_1 \frac{\|\Sigma\|_2}{\Lambda_{\min }(\Sigma)^2} s \log (e p / s)
\]</span></p>
<p><em>implies: For each <span class="math inline">\(t \geq 0\)</span> and </em></p>
<p><span class="math display">\[
\lambda \geq \frac{6 \sqrt{2} \sigma}{\sqrt{n}} \sqrt{\log (p)+t},
\]</span></p>
<p><em>it holds that</em></p>
<p><span class="math display">\[
\mathbb{P}\left(R\left(\hat{m}_{n,\lambda}\right)-r\left(\beta^*\right)&gt;16 \lambda^2 \frac{s}{\Lambda_{\min }(\Sigma)}\right) \leq e^{-t}+2 p e^{-c_2 n} .
\]</span></p>
</blockquote>
<p>The upper bound for the convergence rate of the excess risk of the LASSO estimator is minimized for <span class="math inline">\(\lambda=6 \sqrt{2} \cdot \frac{\sigma}{\sqrt{n}} \sqrt{\log (p)}\)</span>. With that choice,</p>
<p><span class="math display">\[
16 \lambda^2 \frac{s}{\Lambda_{\min }(\Sigma)}=\frac{\text {c }}{\Lambda_{\min }(\Sigma)} \cdot \frac{\sigma^2 s}{n} \cdot \log (p)
\]</span></p>
<p>Interpretation: <span class="math inline">\(\hat{\beta}_\lambda\)</span> behaves like the LS estimator in a model with <span class="math inline">\(s\)</span> instead of <span class="math inline">\(p\)</span> dimensions.</p>
<p>The LASSO estimator <span class="math inline">\(\hat{\beta}_\lambda\)</span> has to ‘pay’ with a factor <span class="math inline">\(\log (p)\)</span> for the missing insight which components are non-zero. This is a rather small price to pay even if <span class="math inline">\(p\)</span> is large.</p>
<p>One can prove similar theoretical statements without the conditions <span class="math inline">\(\varepsilon \sim N\left(0, \sigma^2\right)\)</span> and <span class="math inline">\(X \sim N(0, \Sigma)\)</span> and still can preserve the small <span class="math inline">\(\log (p)\)</span> term.</p>
<p>Regarding the REP: The smallest eigenvalue <span class="math inline">\(\lambda_{\min }(\Sigma)\)</span> measures how strongly the components of <span class="math inline">\(X\)</span> are correlated. Note that a strong correlation of <span class="math inline">\(X\)</span> is a problem for estimation of <span class="math inline">\(\beta^*\)</span>, but not for the excess risk itself: In the extreme case <span class="math inline">\(X_1=X_2\)</span>, it is clear that <span class="math inline">\(\hat{\beta}\)</span> cannot distinguish the values of <span class="math inline">\(\beta_1^*\)</span> and <span class="math inline">\(\beta_2^*\)</span>, but it can still provide good predictions through <span class="math inline">\(X \hat{\beta}\)</span>. Unfortunately, the proof technique underlying the theorem transfers the estimation quality of <span class="math inline">\(\beta^*\)</span> to an upper bound of the excess risk, therefore this fact is not adequately represented in the result.</p>
<p>The assumption <span class="math inline">\(\Sigma_{j j}=1\)</span> is only to provide an easier result. In practice, this normalization can be obtained by standardizing <span class="math inline">\(X_1, \ldots, X_n\)</span> before computing the LASSO estimator (that is, center <span class="math inline">\(X_i\)</span> and divide by the empirical standard deviation).</p>
<blockquote class="thm">
<p><strong>Theorem.</strong> <em>We do not assume that the linear model holds. Assume that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have bounded support (bounded by <span class="math inline">\(B&gt;0\)</span>). Let </em></p>
<p><span class="math display">\[
\beta_*=\underset{\|\beta\|_1 \leq \eta}{\operatorname{argmin}} r(X\beta)
\]</span></p>
<p><em>Then for any <span class="math inline">\(\xi&gt;0\)</span>,</em></p>
<p><span class="math display">\[
\mathbb P\left (r(\widehat{\beta})- r\left(\beta_*\right)\geq\sqrt{\frac{2(\eta+1)^4 B^2}{n} \log \left(\frac{2p^2}{\xi}\right)}\right) \leq \xi  .
\]</span></p>
</blockquote>
<details>
<summary>
<strong>Proof.</strong>
</summary>
<p>Set <span class="math inline">\(Z=(Y, X)\)</span> and <span class="math inline">\(Z_i=\left(Y_i, X_i\right)\)</span>, <span class="math inline">\(\gamma = \gamma(\beta)=(-1, \beta)\)</span>. Then</p>
<p><span class="math display">\[
r(X\beta)=\mathbb{E}\left(Y-\beta^T X\right)^2=\gamma^T \Lambda \gamma
\]</span></p>
<p>where <span class="math inline">\(\Lambda=\mathbb{E}\left[Z Z^T\right]\)</span>. Note that <span class="math inline">\(\|\gamma\|_1=\|\beta\|_1+1\)</span>. Let <span class="math inline">\(\mathcal{B}=\left\{\beta:\|\beta\|_1 \leq \gamma\right\}\)</span>.</p>
<p><span class="math display">\[
\hat{R}_n( X\beta)=\frac{1}{n} \sum_{i=1}^n\left(Y_i-X_i^T \beta\right)^2=\gamma^T \widehat{\Lambda} \gamma
\]</span></p>
<p>where <span class="math inline">\(\widehat{\Lambda}=\frac{1}{n} \sum_{i=1}^n Z_i Z_i^T\)</span>. For any <span class="math inline">\(\beta \in \mathcal{B}\)</span>
<span class="math display">\[\begin{align*}
|\hat{R}_n(\mathbf X\beta)-r(X\beta)| &amp; =\left|\gamma^T(\widehat{\Lambda}-\Lambda) \gamma\right| \\
&amp; \leq \sum_{j, k}|\gamma_j||\gamma_k||\widehat{\Lambda}_{j k}-\Lambda_{jk}| \\
&amp; \leq(\eta+1)^2 \max_{jk} |\widehat{\Lambda}_{j k}-\Lambda_{jk}|
\end{align*}\]</span>
Note that <span class="math inline">\(|\Lambda_{jk}| \leq B^2\)</span>. By Hoeffding’s inequality,</p>
<p><span class="math display">\[
\mathbb{P}\left( |\widehat{\Lambda}_{j k}-\Lambda_{jk}|\geq \epsilon\right) \leq 2 e^{-2n \epsilon^2 / B^2}
\]</span></p>
<p>and so, by the union bound,</p>
<p><span class="math display">\[
\mathbb{P}\left(\max _{j, k}|\widehat{\Lambda}_{j k}-\Lambda_{j k}| \geq \epsilon\right) \leq 2 p^2 e^{-2n \epsilon^2 / B^2}=\xi,
\]</span></p>
<p>if we choose <span class="math inline">\(\epsilon=\sqrt{\frac{B^2} {2 n} \log \left(\frac{{2} p^2}{{ \xi}}\right)}\)</span>.
Hence, with probability <span class="math inline">\(1-\xi\)</span> (see slide 14, lecture 1),</p>
<p><span class="math display">\[
r({X \hat\beta}) - r\left(X\beta^*\right)\leq 2(\eta+1)^2 \varepsilon.
\]</span></p>
<p>as desired. <span class="math inline">\(\blacksquare\)</span></p>
</details>
<blockquote class="def">
<p><strong>Definition.</strong> <em>If <span class="math inline">\(P(S(\widehat{\beta})=S(\beta)) \rightarrow 1\)</span> we call <span class="math inline">\(\hat \beta\)</span> <strong>sparsistent</strong>.</em></p>
<p><em>We call <span class="math inline">\(\hat{\beta}\)</span> weakly <strong>sparsistent</strong> if, for every <span class="math inline">\(\beta\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span> </em></p>
<p><span class="math display">\[
P_\beta\left(I\left(\widehat{\beta}_j=1\right) \leq I\left(\beta_j=1\right) \text { for all } j\right) \rightarrow 1
\]</span></p>
</blockquote>
<p>Suppose that <span class="math inline">\(p\)</span> is fixed. Then the least squares estimator <span class="math inline">\(\widehat{\beta}_n\)</span> is minimax and satisfies</p>
<p><span class="math display">\[
\sup _\beta E_\beta\left(n\left\|\widehat{\beta}_n-\beta\right\|^2\right)=O(1) .
\]</span></p>
<p>But sparsistent estimators have larger risk:</p>
<blockquote class="thm">
<p><strong>Theorem.</strong> <em>We don’t assume the linear model. Suppose that the following condiitons hold:</em></p>
<ul>
<li><em><span class="math inline">\(p\)</span> is fixed.</em></li>
<li><em>The covariariates are nonstochastic and <span class="math inline">\(n^{-1} \mathbf{X}^T \mathbf{X} \rightarrow \Sigma\)</span> for some positive definite matrix <span class="math inline">\(\Sigma\)</span>.</em></li>
<li><em>The errors <span class="math inline">\(\epsilon_i\)</span> are independent with mean 0, finite variance <span class="math inline">\(\sigma^2\)</span> and have a density <span class="math inline">\(f\)</span> satisfying </em>
<span class="math display">\[
  0&lt;\int\left(\frac{f^{\prime}(x)}{f(x)}\right)^2 f(x) d x&lt;\infty
  \]</span></li>
</ul>
<p><em>If <span class="math inline">\(\widehat{\beta}\)</span> is weakly sparsistent, then</em></p>
<p><span class="math display">\[
\sup _\beta \mathbb E_\beta\left(n\left\|\widehat{\beta}_n-\beta\right\|^2\right) \rightarrow \infty .
\]</span></p>
<p><em>More generally, if <span class="math inline">\(\ell\)</span> is any loss function <span class="math inline">\(\ell: \mathbb R \mapsto \mathbb R_{\geq 0}\)</span>.then </em></p>
<p><span class="math display">\[
\sup _\beta  \mathbb E_\beta\left(\ell\left(n^{1 / 2}\left(\widehat{\beta}_n-\beta\right)\right)\right) \rightarrow \sup _s \ell(s) .
\]</span></p>
</blockquote>
<details>
<summary>
<strong>Proof.</strong>
</summary>
<p>Choose any <span class="math inline">\(s \in \mathbb{R}^d\)</span> and let <span class="math inline">\(\beta_n=-s / \sqrt{n}\)</span>. Then,
<span class="math display">\[\begin{align*}
\sup _\beta \mathbb E_\beta\left(\ell\left(n^{1 / 2}(\widehat{\beta}-\beta)\right)\right. &amp; \geq \mathbb E_{\beta_n}\left(\ell\left(n^{1 / 2}(\widehat{\beta}-\beta)\right) \geq \mathbb E_{\beta_n}\left(\ell\left(n^{1 / 2}(\widehat{\beta}-\beta)\right) I(\widehat{\beta}=0)\right)\right. \\
&amp; =\ell\left(-\sqrt{n} \beta_n\right) \mathbb P_{\beta_n}(\widehat{\beta}=0)=\ell(s) P_{\beta_n}(\widehat{\beta}=0) .
\end{align*}\]</span>
Now, <span class="math inline">\(\mathbb P_0(\widehat{\beta}=0) \rightarrow 1\)</span> by assumption. It can be shown (via contiguity) that we also have <span class="math inline">\(\mathbb P_{\beta_n}(\widehat{\beta}=0) \rightarrow 1 .\)</span> Hence, with probability tending to 1,</p>
<p><span class="math display">\[
\sup _\beta E_\beta\left(\ell\left(n^{1 / 2}(\widehat{\beta}-\beta)\right) \geq \ell(s) .\right.
\]</span></p>
<p>Since <span class="math inline">\(s\)</span> was arbitrary the result follows. <span class="math inline">\(\blacksquare\)</span></p>
</details>
</div>
<div id="conclusion" class="section level3 hasAnchor" number="9.3.4">
<h3><span class="header-section-number">9.3.4</span> Conclusion<a href="probabilistic-machine-learning.html#conclusion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Lasso and Ridge regression aim for different things. Ridge regression reduces variance of the estimator by restricting the function space. Heuristically, the smaller <span class="math inline">\(||\beta^\ast||_2\)</span> the more helpful is ridge regression. Lasso is useful in sparse setting, i.e, if one wishes to eliminate components/features.</p>
<p><strong>Example.</strong> Assume that <span class="math inline">\(\rm{corr}(X_{1},X_2)=1\)</span> and <span class="math inline">\(Y=0.5X_1+0.5X_2\)</span>. While Lasso will probably estimate <span class="math inline">\(\beta_1=1, \beta_2=0\)</span>, Ridge will probably estimate correctly <span class="math inline">\(\beta_1=0.5, \beta_2=0.5\)</span>.</p>
<blockquote class="def">
<p><strong>Definition. (Elastic net)</strong> <em>For <span class="math inline">\(\lambda&gt;0, \alpha \in (0,1)\)</span>, and <span class="math inline">\(J^{elastic.net}(\beta)= \sum_{j=1}^p \alpha |\beta_j| + (1-\alpha) \beta_j^2\)</span>, we call</em>
<span class="math display">\[\begin{align*}
\hat{\beta}_\lambda^{\text {elastic.net }} &amp; \in \underset{\beta \in \mathbb{R}^d}{\arg \min }\left\{\hat{R}_n(\beta)+J^{elastic.net}_\lambda(\beta)\right\} \\
\end{align*}\]</span>
<em><strong>elastic net</strong> estimator.</em></p>
</blockquote>
</div>
</div>
<div id="nonparametric-regression" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> Nonparametric Regression<a href="probabilistic-machine-learning.html#nonparametric-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Linear models are quite restrictive and one may ask how one can achieve more flexibility. In this chapter we will look at the nonparametric regression problem with squared loss <span class="math inline">\(L(y_1,y_2)=(y_1-y_2)^2\)</span>. We already know that the Bayes-rule is <span class="math inline">\(m^\ast(x)=\mathbb E[Y|X=x]\)</span>.</p>
<blockquote class="def">
<p><strong>Definition. (k-nearest-neighbor)</strong> <em>The k-nearest-neighbor estimator is </em></p>
<p><span class="math display">\[
\hat m^{knn}(x)= \frac 1 k \sum_{i \in \mathcal N_k(x)}Y_i,
\]</span></p>
<p><em>where <span class="math inline">\(\mathcal N_k(x)\)</span> contains the indices of the <span class="math inline">\(k\)</span> closest points of <span class="math inline">\(\{X_1, \dots X_n\}\)</span> to <span class="math inline">\(x\)</span>.</em></p>
</blockquote>
<blockquote class="def">
<p><strong>Definition. (Linear Smoother)</strong> <em>An estimator is called linear smoother if it can be written as </em></p>
<p><span class="math display">\[
\hat m(x)= \sum_i w_i(x)Y_i,
\]</span></p>
<p><em>where the weight function <span class="math inline">\(w_i\)</span> can depend on <span class="math inline">\(\{X_1, \dots, X_n\}\)</span>.</em></p>
</blockquote>
<p><strong>Example.</strong> The k-nearest-neighbor estimator is a linear smoother:</p>
<p><span class="math display">\[
\hat m^{knn}(x)= \sum_i^n w_i(x_i) Y_i,
\]</span></p>
<p>with</p>
<span class="math display">\[
w_i(x)=\begin{cases}\frac 1 k &amp; X_i \ \text{belongs to the}\  k \ \text{closest points to}\  x \\ 0 &amp; else\end{cases}
\]</span>
<blockquote class="prop">
<p><strong>Proposition. (MSE k-nearest-neighbor)</strong> <em>Assume that</em></p>
<p><span class="math display">\[
E[Y|X=x]=m^\ast(x)\in \mathcal G_L = \{m: \mathbb R^p \mapsto \mathbb R| m \ \text{is L-Lipschitz continuous}\},
\]</span></p>
<p><em>and <span class="math inline">\(\textrm{Var}(Y|X=x)=\sigma^2(x)\leq \sigma^2.\)</span> Then </em></p>
<p><span class="math display">\[
\mathbb E[(\hat m^{knn}(x)-m^\ast(x))^2]\leq (cL)^2 \left(\frac k n \right)^{2/p}+\frac {\sigma^2}k.
\]</span></p>
<p><em>In particular, for <span class="math inline">\(k_n=O_p( n^{2/(2+p)})\)</span>, we get </em></p>
<p><span class="math display">\[
\mathbb E[(\hat m^{knn}(x)-m^\ast(x))^2]=O_p(n^{-2/(2+p)}).
\]</span></p>
</blockquote>
<details>
<summary>
<strong>Proof.</strong>
</summary>
<p>Write <span class="math inline">\(\mathbf X=X_1,\dots, X_n\)</span> and denote by <span class="math inline">\(Y_i^{(x)}\)</span> the <span class="math inline">\(i\)</span>th closest <span class="math inline">\(Y\)</span> to <span class="math inline">\(x\)</span> among <span class="math inline">\(Y_1,\dots Y_n\)</span>.
<span class="math display">\[\begin{align*}\mathbb E[(\hat m^{knn}(x)-m^\ast(x))^2]&amp; =\mathbb E \Big [{\left(\mathbb{E}[\hat m^{knn}(x)|\mathbf  X]-m^\ast(x)\right)^2}\Big]+{\mathbb{E}\Big[(\hat m^{knn}(x)-\mathbb{E}[\hat m^{knn}(x)|\mathbf  X])^2\Big]}\\
&amp;=\mathbb E\left[ \Big \{\frac{1}{k} \sum_{i \in \mathcal{N}_k(x)}\left(m^\ast\left(X_i\right)-m^\ast(x)\right)\Big \}^2\right] \\ &amp;\quad + \frac 1 {k^2} \mathbb E \left[ \sum_i^k \sum_j^k \{Y_i^{(x)}- \mathbb  E[Y_i^{(x)}| \mathbf X]\}\{Y_j^{(x)}- \mathbb  E[Y_j^{(x)}| \mathbf X]\} \right] \\
&amp; \leq \mathbb  E\left[ \left(\frac{L}{k} \sum_{i \in \mathcal{N}_k(x)}\left\|X_i-x\right\|_2\right)^2 \right]+\frac{\sigma^2}{k} \\
&amp;\leq^{(1)}  L^2 c \left(\frac k n \right)^{2/p}+\frac {\sigma^2}k
\end{align*}\]</span></p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\mathbb E\left[ \left \{\frac{1}{k} \sum_{i \in \mathcal{N}_k(x)}\left\|X_i-x\right\|_2 \right\}^2 \right]\leq c \left(\frac k n \right)^{2/p}\)</span>, see (Gyorfi et al. 2002, vol. 1, chap. 6.3). <span class="math inline">\(\blacksquare\)</span></li>
</ol>
</details>
<p>Note that this is slower than the “parametric” MSE of <span class="math inline">\(n^{-1}\)</span>. In particular the rate depends on <span class="math inline">\(p\)</span>. Even worse: It grows exponentially in <span class="math inline">\(p\)</span>.</p>
<p>We have learned that the knn estimator can be written as</p>
<p><span class="math display">\[
\hat m^{knn}(x)= \frac 1 k w_i(x_i) Y_i,
\]</span></p>
<p>Note that <span class="math inline">\(w_i(x)\)</span> is not smooth as a function of <span class="math inline">\(x\)</span>. This also makes the estimator not smooth. Given that we assume that <span class="math inline">\(m^\ast\)</span> is smooth, this may not be desirable. An alternative are kernel smoothers.</p>
<blockquote class="def">
<p><strong>Definition. (Kernel Smoother)</strong> <em>The kernel smoother a linear smoother with </em></p>
<p><span class="math display">\[
\hat m^{ks}(x)=  \sum_i w_i(x_i) Y_i,
\]</span></p>
<p><em>where </em></p>
<p><span class="math display">\[
w_i(x)=\frac{K\left(\frac{||x-X_i||}{h}\right)}{\sum_j K\left(\frac{||x-X_j||}{h}\right)}
\]</span></p>
<p><em>Often <span class="math inline">\(K=\prod_j k_j\)</span>, such that <span class="math inline">\(K\left(\frac{||x-X_i||}{h}\right)=\prod_j k(x-X_{ij})\)</span>. The function <span class="math inline">\(k: \mathbb R \mapsto \mathbb R\)</span> is usually a symmetric density function.</em></p>
</blockquote>
<blockquote class="prop">
<p><strong>Proposition. (MSE Kernel Smoother)</strong> <em>Assume that <span class="math inline">\(E[Y|X=x]=m^\ast(x)\in \mathcal G_L\)</span> with</em>
<span class="math display">\[
\mathcal G_L = \{m: \mathbb R^p \mapsto \mathbb R| m \ \text{is L-Lipschitz continuous}\},
\]</span></p>
<p><em>and <span class="math inline">\(\textrm{Var}(Y|X=x)=\sigma^2(x)\leq \sigma^2.\)</span> Then </em></p>
<p><span class="math display">\[
\mathbb E[(\hat m^{ks}(x)-m^\ast(x))^2]= O_p\left( \frac{1}{nh^p} + h^2 \right)
\]</span></p>
<p><em>In particular, for <span class="math inline">\(h_n=O_p(n^{-1/(2+p)})\)</span>, we get </em></p>
<p><span class="math display">\[
\mathbb E[(\hat m^{ks}(x)-m^\ast(x))^2]=O_p(n^{-2/(2+p)}).
\]</span></p>
</blockquote>
<div id="curse-of-dimensionality" class="section level3 hasAnchor" number="9.4.1">
<h3><span class="header-section-number">9.4.1</span> Curse of dimensionality<a href="probabilistic-machine-learning.html#curse-of-dimensionality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We have seen that under a Lipschitz condition, both kernel smoother and knn have an asymptotic mean squared error of order <span class="math inline">\(n^{-2/(2+p)}\)</span>. One can show that under the assumption that <span class="math inline">\(m^\ast\)</span> is twice continuously differentiable, the rate for both methods can be improved to</p>
<p><span class="math display">\[
n^{-4/(4+p)}.
\]</span></p>
<p>But this rate is still exponentially decreasing in <span class="math inline">\(p\)</span>. Furthermore, it has been shown that no method can do better under the given assumptions.</p>
<p>A new observation <span class="math inline">\(x_0\)</span> will have very few or no observations in its neighborhood. This leads to high variance and high bias when increasing the size of the neighborhood.</p>
<p>Under the model of the previous slide, the setting <span class="math inline">\(n=50,p=1\)</span> has the same expected amount of observations in a neighborhood as the setting <span class="math inline">\(n=7.5\times10^{110}, p=100\)</span>.</p>
<p>There are two ways to tackle the curse of dimensionality.</p>
<p><strong>Sparsity:</strong> Assume that the intrinsic dimension is lower. E.g. Not all variables are relevant. Or feature engineer a few highly predictive variables.</p>
<p><strong>Structure:</strong> Interactions are limited and structure can be exploited
e.g. an additive structure <span class="math inline">\(m(x)=m_1(x_1)+m_2(x_2).\)</span>. Remember that structure is essential for interpretability.</p>
</div>
<div id="splines" class="section level3 hasAnchor" number="9.4.2">
<h3><span class="header-section-number">9.4.2</span> Splines<a href="probabilistic-machine-learning.html#splines" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We want to establish a framework to estimate additive regression functions. To this end, assume <span class="math inline">\(p=1\)</span> until further notice.</p>
<blockquote class="def">
<p><strong>Definition. (Splines)</strong> <em>A <span class="math inline">\(k\)</span>th-order spline with <span class="math inline">\(l\)</span> knotpoints <span class="math inline">\(x_1 &lt;\dots&lt;x_l\)</span></em></p>
<ul>
<li><em>is a polynomial of degree <span class="math inline">\(k\)</span> on each interval <span class="math inline">\((-\infty,x_1],[x_1,x_2]\dots,[x_l,\infty)\)</span></em></li>
<li><em>has continuous derivatives of orders <span class="math inline">\(0,...,k-1\)</span> on the knotpoints <span class="math inline">\(x_1 &lt;\dots&lt;x_l\)</span></em></li>
</ul>
</blockquote>
<p><strong>Example.</strong> A <span class="math inline">\(k\)</span>th-order spline <span class="math inline">\(m\)</span> with <span class="math inline">\(l\)</span> knotpoints can an be uniquely written as</p>
<p><span class="math display">\[
m(x)=\sum_{j=1}^{k+1+l}\theta_jg_j(x)
\]</span></p>
<ul>
<li>truncated power basis
<ul>
<li>For <span class="math inline">\(j=1,\dots, k+1\)</span>: <span class="math inline">\(g_{j}=x^{j-1}\)</span></li>
<li>For <span class="math inline">\(j=1,\dots,l:\)</span> <span class="math inline">\(g_{k+1+j}=(x-x_j)^k_+\)</span>
<ul>
<li><span class="math inline">\((x)_+:= \max(x,0)\)</span></li>
</ul></li>
</ul></li>
<li>B-splines
<ul>
<li>more complicated, but computationally more robust and faster to compute.</li>
</ul></li>
</ul>
<p>Splines (used for regression, see next slide) have high variance at the boundaries. Solution: Let the piecewise polynomial function have a lower degree at <span class="math inline">\((-\infty,x_1],[x_l,\infty)\)</span>.</p>
<blockquote class="def">
<p><strong>Definition. (Natural Splines)</strong> <em>A <span class="math inline">\(k\)</span>th-order natural spline (<span class="math inline">\(k=\)</span> odd number) with knotpoints <span class="math inline">\(x_1 &lt;\dots&lt;x_l\)</span></em></p>
<ul>
<li><em>is a polynomial of degree <span class="math inline">\(k\)</span> on the intervals <span class="math inline">\([x_1,x_2]\dots,[x_{l-1},x_l)\)</span></em></li>
<li><em>is a polynomial of degree <span class="math inline">\((k-1)/2\)</span> on <span class="math inline">\((-\infty,x_1],[x_l,\infty)\)</span></em></li>
<li><em>has continuous derivatives of orders <span class="math inline">\(0,...,k-1\)</span> on the knotpoints <span class="math inline">\(x_1 &lt;\dots&lt;x_l\)</span></em></li>
</ul>
</blockquote>
<p>Note that natural splines have dimension <span class="math inline">\(l\)</span> which is in particular independent of the order <span class="math inline">\(k\)</span> (compare to dimension <span class="math inline">\(k+l\)</span> for splines). There is also a truncated power basis and a B-splines basis for natural splines.</p>
<p><strong>Linear regression with splines.</strong> We still assume the one-dimensional case, <span class="math inline">\(p=1\)</span>. Instead of looking at observations <span class="math inline">\((X_i,Y_i)_{i=1,\dots,n}\)</span> we can consider a natural splines basis and look at observations <span class="math inline">\((g_1(X_i), \dots, g_l(X_i), Y_i)_{i=1,\dots,n}.\)</span> By doing so we are able to approximate any natural spline in <span class="math inline">\(x\)</span> instead of just linear functions in <span class="math inline">\(x\)</span>, while still being in a linear regression framework, i.e.,</p>
<p><span class="math display">\[
\hat \beta = {\arg \min }_\beta \sum_i (Y_i - { G_i^T}\beta )^2= (\mathbf G^T\mathbf  G)^{-1}\mathbf  G^T\mathbf Y
\]</span></p>
<p>where <span class="math inline">\(G_i^T=(g_1(X_i), \dots, g_l(X_i))\)</span>, the rows of <span class="math inline">\(\mathbf G\)</span>. Problem: How do we choose the number of knotpoints <span class="math inline">\(l\)</span> and their position? First thought: Cross validation. But that would be quite expensive to run.</p>
<p>Let’s look at the following minimization problem:</p>
<p><span class="math display">\[
\hat m= \arg\min_{m} \sum_i (Y_i-m(X_i))^2+\lambda\int_a^b m&#39;&#39;(x)^2\mathrm dx,
\]</span></p>
<p>where minimization runs over all twice times differentiable functions <span class="math inline">\(m\)</span> and observations <span class="math inline">\(X_i\)</span> are in <span class="math inline">\([a,b]\)</span> for all <span class="math inline">\(i\)</span>.</p>
<blockquote class="thm">
<p><strong>Theorem (Smoothing splines)</strong> <em>If <span class="math inline">\(m\)</span> is twice differentiable and the solution to </em></p>
<p><span class="math display">\[
\arg\min_{m} \sum_i (Y_i-m(X_i))^2+\lambda\int_a^b m&#39;&#39;(x)^2\mathrm dx,
\]</span></p>
<p><em>then <span class="math inline">\(m\)</span> is a natural spline of order 3 (natural cubic spline).</em></p>
</blockquote>
<details>
<summary>
<strong>Proof.</strong>
</summary>
<p>Given a minimizer <span class="math inline">\(\tilde m\)</span>, we construct the unique natural cubic spline <span class="math inline">\(m\)</span> on <span class="math inline">\([a,b]\)</span> with knotpoints <span class="math inline">\(X_1,\dots, X_n\)</span> and <span class="math inline">\(m(X_i)=\tilde m(X_i)\)</span>. We will show that <span class="math inline">\(\tilde m=m\)</span>. Define <span class="math inline">\(h=\tilde m-m\)</span>. Note that <span class="math inline">\(h(X_j)=0 (j=1,\dots,n)\)</span>, <span class="math inline">\(m&#39;&#39;&#39;(x)=0\)</span> for <span class="math inline">\(x&lt;X_1\)</span> and <span class="math inline">\(x&gt;X_n\)</span> as well as <span class="math inline">\(m^{(4)}=0\)</span>. Hence by applying integration by parts twice we get
<span class="math display">\[\begin{align*}
\int_a^b m&#39;&#39;(x)h&#39;&#39;(x)\mathrm dx
&amp;= -\int_{X_1}^{X_n}m&#39;&#39;&#39;(x)h&#39;(x)\mathrm dx \\
&amp;= -\sum_{j=1}^{n-1}m&#39;&#39;&#39;(x)h(x)\Big|_{X_j}^{X_{j+1}} \\
&amp;=0
\end{align*}\]</span>
This implies</p>
<p><span class="math display">\[
\int_a^b \tilde m&#39;&#39;(x)^2\mathrm dx= \int_a^b \{m&#39;&#39;(x)+h(x)\}^2\mathrm dx=\int_a^b m&#39;&#39;(x)^2+h(x)^2\mathrm dx.
\]</span></p>
<p>meaning</p>
<p><span class="math display">\[
\int_a^b m&#39;&#39;(x)^2\mathrm dx \leq \int_a^b \tilde m&#39;&#39;(x)^2\mathrm dx.
\]</span></p>
<p>with equality only for <span class="math inline">\(h&#39;&#39;=0\)</span>, i.e, <span class="math inline">\(h\)</span> linear. Since <span class="math inline">\(h(X_i)=0 (i=1,\dots n)\)</span>, we have <span class="math inline">\(h=0\)</span> and so <span class="math inline">\(\tilde m=m\)</span>. <span class="math inline">\(\blacksquare\)</span></p>
</details>
<p>We can conclude the following:</p>
<ul>
<li>Let <span class="math inline">\(\mathbf G\)</span> be the matrix with with rows <span class="math inline">\(G_i=(g_1(X_i), \dots, g_l(X_i))\)</span>.
<ul>
<li><span class="math inline">\(\{g_j\}_{j=1,\dots,l}\)</span> is a basis for natural cubic splines.</li>
</ul></li>
<li>Define
<span class="math display">\[
  \hat \beta  = \arg\min_{\beta} \sum_i (Y_i- G_i^T\beta)^2+\lambda\int_0^1 \left\{{\sum_j \beta_jg_j&#39;&#39;}(x)\right\}^2\mathrm dx.
  \]</span>
Then,
<span class="math display">\[
  \sum_j \hat \beta_j g_j=\arg\min_{m} \sum_i (Y_i-m(X_i))^2+\lambda\int_0^1 m&#39;&#39;(x)^2\mathrm dx.
  \]</span></li>
</ul>
<p>Smoothing splines can be seen as a special case of generalized ridge regression:</p>
<ul>
<li>Write <span class="math inline">\(\mathbf W_{ij}=\int_0^1g_i&#39;&#39;(x)g_j&#39;&#39;(x)\mathrm dx,\)</span> then
<span class="math display">\[\begin{align*}
  &amp;\arg\min_{\beta} \sum_i (Y_i- G_i^T\beta)^2+\lambda\int_0^1 \left\{{\sum_j \beta_jg_j&#39;&#39;}(x)\right\}^2\mathrm dx\\=
  &amp;\arg\min_{\beta} \sum_i (Y_i- G_i^T\beta)^2+\lambda \beta^T \mathbf W \beta.
  \end{align*}\]</span>
Hence,
<span class="math display">\[
  \hat \beta= (\mathbf G^T\mathbf G+\lambda \mathbf W)^{-1}\mathbf G^T\mathbf Y.
  \]</span></li>
</ul>
<p>It can be shown the smoothing splines are asymptotically equivalent to kernel smoothers with varying bandwidth and a specific choice of kernel, see Silverman (1984) or Wang, Du, and Shen (2013) for a more recent contribution. In general, smoothing splines are more practical since they can be efficiently calculated while kernel smoothers are much easier to analyze theoretically.</p>
<p>We have seen that fully nonparametric methods suffer from the curse of dimensionality: the optimal rate of convergence for twice continuously differentiable functions is <span class="math inline">\(n^{-4/(4+p)}\)</span>. One solution is to restrict oneself to the class of additive functions</p>
<p><span class="math display">\[
\mathcal G=\{m| m(x)=m_1(x_1)+\cdots +m_p(x_p)\}
\]</span></p>
<p>Stone (1985) showed that the components <span class="math inline">\(m_k\)</span>, if twice continuously differentiable, can be estimated with one-dimensional rate of <span class="math inline">\(n^{-4/4+1}\)</span>. The components <span class="math inline">\(m_j\)</span> are usually estimated via the so called backfitting algorithm (Hastie and Tibshirani 1990).</p>
<p>Backffitting comprises the following two steps:</p>
<blockquote class="def">
<p><strong>Definition. (Backfitting Algorithm)</strong></p>
<ul>
<li><em>Intialize: <span class="math inline">\(\hat m_j^{[0]}=0, j=1,\dots,p\)</span></em></li>
<li><em>Iterate for <span class="math inline">\(r=1,\dots\)</span></em>
<ol style="list-style-type: decimal">
<li><em>Residuals: <span class="math inline">\(r_{ij}^{[r]}=Y_i-\sum_{k &lt; j} \hat{m}_{k}^{[r]}(x_{ik})-\sum_{k &gt; j} \hat{m}_{k}^{[r-1]}(x_{ik})\)</span>.</em></li>
<li><em>Smooth: <span class="math inline">\(\hat{m}_j^{[r]}=\operatorname{Smooth}\left(\left\{X_{ij},r_{ij}^{[r]}\}_{i=1,\dots,n}\right\}\right).\)</span></em></li>
<li><em>Center: <span class="math inline">\(\hat{m}_j^{[r]}=\hat{m}_j^{[r]}-\frac{1}{n} \sum_{i=1}^n \hat{m}_j^{[r]}\left(X_{i j}\right)\)</span>.</em></li>
</ol></li>
</ul>
</blockquote>
<p>Note that Smooth is a one-dimensional regression problem. In practice Smooth is most often a smoothing spline.
It has been shown backfitting via smoothing splines achieve optimal rate of <span class="math inline">\(n^{-4/4+1}\)</span> for each component and <span class="math inline">\(pn^{-4/4+1}\)</span> for the p-dimensional additive regression function.</p>
<p>Problem: Additive methods are still not optimal in the case of sparsity (i.e. some features being not relevant) and interactions between features.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="topics-in-non-life-insurance-mathematics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="quantative-risk-management.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
