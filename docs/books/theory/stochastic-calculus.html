<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 15 Stochastic calculus | Complete Theory</title>
  <meta name="description" content="Chapter 15 Stochastic calculus | Complete Theory" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 15 Stochastic calculus | Complete Theory" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 15 Stochastic calculus | Complete Theory" />
  
  
  

<meta name="author" content="Joakim Bilyk" />


<meta name="date" content="2023-02-13" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="continuous-time-stochastic-processes.html"/>
<link rel="next" href="linear-algebra.html"/>
<style type="text/css">
p.abstract{
  text-align: center;
  font-weight: bold;
}
div.abstract{
  margin: auto;
  width: 90%;
}
</style>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="https://code.jquery.com/jquery-1.9.1.js"></script>

<script>
    $(function() {
        var element = document.body;
        if (localStorage.chkbx && localStorage.chkbx != '') {
            $('#remember_me').attr('checked', 'checked');
            element.classList.toggle("dark-mode");
            document.querySelector('.book-header.fixed').click();
        } else {
            $('#remember_me').removeAttr('checked');
            document.querySelector('.book-header.fixed').click();
        }

        $('#remember_me').click(function() {

            if ($('#remember_me').is(':checked')) {
                // save username and password
                localStorage.chkbx = $('#remember_me').val();
                element.classList.toggle("dark-mode");
                document.querySelector('.book-header.fixed').click();
            } else {
                localStorage.chkbx = '';
                element.classList.toggle("dark-mode");
                document.querySelector('.book-header.fixed').click();
            }
        });
    });

</script>

<div class = "sticky-darkmode-toggle">
  <label class="switch">
  <input type="checkbox" value="remember-me" id="remember_me">
  <span class="slider round">
  </span>
  </label>
</div>

<script>
$(function() {
  $('body').after($('.sticky-darkmode-toggle'));
})
</script>

<style>

.sticky-darkmode-toggle {
  position: fixed;
  right: 20px;
  bottom: 20px;
}
</style>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Comlete theory</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#abbreviations"><i class="fa fa-check"></i><b>1.1</b> Abbreviations</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#to-do-reading"><i class="fa fa-check"></i><b>1.2</b> To-do reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="basic-life-insurance-mathematics.html"><a href="basic-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>2</b> Basic Life Insurance Mathematics</a></li>
<li class="chapter" data-level="3" data-path="stochastic-processes-in-life-insurance-mathematics.html"><a href="stochastic-processes-in-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>3</b> Stochastic Processes in Life Insurance Mathematics</a></li>
<li class="chapter" data-level="4" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>4</b> Topics in Life Insurance Mathematics</a>
<ul>
<li class="chapter" data-level="4.1" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html#markov-jump-processes"><i class="fa fa-check"></i><b>4.1</b> Markov Jump Processes</a></li>
<li class="chapter" data-level="4.2" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html#phase-type-distributions"><i class="fa fa-check"></i><b>4.2</b> Phase-type distributions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html"><i class="fa fa-check"></i><b>5</b> Continuous Time Finance</a>
<ul>
<li class="chapter" data-level="5.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#discrete-time-models"><i class="fa fa-check"></i><b>5.1</b> Discrete time models</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#one-period-time-models"><i class="fa fa-check"></i><b>5.1.1</b> One-period time models</a></li>
<li class="chapter" data-level="5.1.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#multi-period-model"><i class="fa fa-check"></i><b>5.1.2</b> Multi-period model</a></li>
<li class="chapter" data-level="5.1.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#generelised-one-period-model"><i class="fa fa-check"></i><b>5.1.3</b> Generelised one-period model</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#self-financing-portfolios"><i class="fa fa-check"></i><b>5.2</b> Self-financing portfolios</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#discrete-time-sf-portfolio"><i class="fa fa-check"></i><b>5.2.1</b> Discrete time SF portfolio</a></li>
<li class="chapter" data-level="5.2.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#continuous-time-sf-portfolio"><i class="fa fa-check"></i><b>5.2.2</b> Continuous time SF portfolio</a></li>
<li class="chapter" data-level="5.2.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#portfolio-weights"><i class="fa fa-check"></i><b>5.2.3</b> Portfolio weights</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#black-scholes-pde"><i class="fa fa-check"></i><b>5.3</b> Black-Scholes PDE</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#contingent-claims-and-arbitrage"><i class="fa fa-check"></i><b>5.3.1</b> Contingent Claims and Arbitrage</a></li>
<li class="chapter" data-level="5.3.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#risk-neutral-valuation-1"><i class="fa fa-check"></i><b>5.3.2</b> Risk Neutral Valuation</a></li>
<li class="chapter" data-level="5.3.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#black-scholes-formula"><i class="fa fa-check"></i><b>5.3.3</b> Black-Scholes formula</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#completeness-and-hedging"><i class="fa fa-check"></i><b>5.4</b> Completeness and Hedging</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#completeness-in-black-scholes"><i class="fa fa-check"></i><b>5.4.1</b> Completeness in Black-Scholes</a></li>
<li class="chapter" data-level="5.4.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#absence-of-arbitrage-1"><i class="fa fa-check"></i><b>5.4.2</b> Absence of Arbitrage</a></li>
<li class="chapter" data-level="5.4.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#incomplete-markets"><i class="fa fa-check"></i><b>5.4.3</b> Incomplete Markets</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#parity-relations"><i class="fa fa-check"></i><b>5.5</b> Parity relations</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#put-call-parity"><i class="fa fa-check"></i><b>5.5.1</b> Put-call Parity</a></li>
<li class="chapter" data-level="5.5.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#the-greeks"><i class="fa fa-check"></i><b>5.5.2</b> The Greeks</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#fundamental-pricing-theorem-i-and-ii"><i class="fa fa-check"></i><b>5.6</b> Fundamental pricing theorem I and II</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#completeness-1"><i class="fa fa-check"></i><b>5.6.1</b> Completeness</a></li>
<li class="chapter" data-level="5.6.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#risk-neutral-valuation-formula"><i class="fa fa-check"></i><b>5.6.2</b> Risk Neutral Valuation Formula</a></li>
<li class="chapter" data-level="5.6.3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#stochastic-discount-factors-1"><i class="fa fa-check"></i><b>5.6.3</b> Stochastic Discount Factors</a></li>
<li class="chapter" data-level="5.6.4" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#summary"><i class="fa fa-check"></i><b>5.6.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#mathematics-of-the-martingale-approach"><i class="fa fa-check"></i><b>5.7</b> Mathematics of the martingale approach</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#martingale-representation-theorem"><i class="fa fa-check"></i><b>5.7.1</b> Martingale representation theorem</a></li>
<li class="chapter" data-level="5.7.2" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#girsanov-theorem"><i class="fa fa-check"></i><b>5.7.2</b> Girsanov theorem</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#black-scholes-model---martingale-approach"><i class="fa fa-check"></i><b>5.8</b> Black-Scholes model - martingale approach</a></li>
<li class="chapter" data-level="5.9" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html#multidimensional-models"><i class="fa fa-check"></i><b>5.9</b> Multidimensional models</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="basic-non-life-insurance-mathematics.html"><a href="basic-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>6</b> Basic Non-Life Insurance Mathematics</a></li>
<li class="chapter" data-level="7" data-path="stochastic-processes-in-non-life-insurance-mathematics.html"><a href="stochastic-processes-in-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>7</b> Stochastic Processes in Non-Life Insurance Mathematics</a></li>
<li class="chapter" data-level="8" data-path="topics-in-non-life-insurance-mathematics.html"><a href="topics-in-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>8</b> Topics in Non-Life Insurance Mathematics</a></li>
<li class="chapter" data-level="9" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html"><i class="fa fa-check"></i><b>9</b> Probabilistic Machine Learning</a>
<ul>
<li class="chapter" data-level="9.1" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#supervised-learning"><i class="fa fa-check"></i><b>9.1</b> Supervised Learning</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#what-is-a-good-estimator"><i class="fa fa-check"></i><b>9.1.1</b> What is a good estimator?</a></li>
<li class="chapter" data-level="9.1.2" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#excess-risk"><i class="fa fa-check"></i><b>9.1.2</b> Excess risk</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#training-validating-and-testing"><i class="fa fa-check"></i><b>9.2</b> Training, Validating and Testing</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#estimating-risk"><i class="fa fa-check"></i><b>9.2.1</b> Estimating risk</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html#linear-models"><i class="fa fa-check"></i><b>9.3</b> Linear Models</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="quantative-risk-management.html"><a href="quantative-risk-management.html"><i class="fa fa-check"></i><b>10</b> Quantative Risk Management</a>
<ul>
<li class="chapter" data-level="10.1" data-path="quantative-risk-management.html"><a href="quantative-risk-management.html#the-loss-variable"><i class="fa fa-check"></i><b>10.1</b> The Loss Variable</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="quantative-risk-management.html"><a href="quantative-risk-management.html#risk-measures"><i class="fa fa-check"></i><b>10.1.1</b> Risk measures</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="measure-theory.html"><a href="measure-theory.html"><i class="fa fa-check"></i><b>11</b> Measure theory</a>
<ul>
<li class="chapter" data-level="11.1" data-path="measure-theory.html"><a href="measure-theory.html#axioms-of-probability"><i class="fa fa-check"></i><b>11.1</b> Axioms of Probability</a></li>
<li class="chapter" data-level="11.2" data-path="measure-theory.html"><a href="measure-theory.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>11.2</b> Conditional Probability and Independence</a></li>
<li class="chapter" data-level="11.3" data-path="measure-theory.html"><a href="measure-theory.html#equivalent-probability-measures"><i class="fa fa-check"></i><b>11.3</b> Equivalent Probability Measures</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="measure-theory.html"><a href="measure-theory.html#the-radon-nikodym-theorem"><i class="fa fa-check"></i><b>11.3.1</b> The Radon-Nikodym Theorem</a></li>
<li class="chapter" data-level="11.3.2" data-path="measure-theory.html"><a href="measure-theory.html#equivalent-probability-measures-1"><i class="fa fa-check"></i><b>11.3.2</b> Equivalent Probability Measures</a></li>
<li class="chapter" data-level="11.3.3" data-path="measure-theory.html"><a href="measure-theory.html#likelihood-processes"><i class="fa fa-check"></i><b>11.3.3</b> Likelihood processes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>12</b> Random Variables</a>
<ul>
<li class="chapter" data-level="12.1" data-path="random-variables.html"><a href="random-variables.html#introduction-1"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="random-variables.html"><a href="random-variables.html#conditional-expectation"><i class="fa fa-check"></i><b>12.2</b> Conditional expectation</a></li>
<li class="chapter" data-level="12.3" data-path="random-variables.html"><a href="random-variables.html#independence"><i class="fa fa-check"></i><b>12.3</b> Independence</a></li>
<li class="chapter" data-level="12.4" data-path="random-variables.html"><a href="random-variables.html#moment-generating-function"><i class="fa fa-check"></i><b>12.4</b> Moment generating function</a></li>
<li class="chapter" data-level="12.5" data-path="random-variables.html"><a href="random-variables.html#standard-distributions"><i class="fa fa-check"></i><b>12.5</b> Standard distributions</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="random-variables.html"><a href="random-variables.html#normal-disribution"><i class="fa fa-check"></i><b>12.5.1</b> Normal disribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html"><i class="fa fa-check"></i><b>13</b> Discrete Time Stochastic Processes</a>
<ul>
<li class="chapter" data-level="13.1" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#convergence-concepts"><i class="fa fa-check"></i><b>13.1</b> Convergence concepts</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#sums-and-average-processes"><i class="fa fa-check"></i><b>13.1.1</b> Sums and average processes</a></li>
<li class="chapter" data-level="13.1.2" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#ergodic-theory"><i class="fa fa-check"></i><b>13.1.2</b> Ergodic Theory</a></li>
<li class="chapter" data-level="13.1.3" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#weak-convergence"><i class="fa fa-check"></i><b>13.1.3</b> Weak Convergence</a></li>
<li class="chapter" data-level="13.1.4" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html#central-limit-theorems"><i class="fa fa-check"></i><b>13.1.4</b> Central Limit Theorems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="continuous-time-stochastic-processes.html"><a href="continuous-time-stochastic-processes.html"><i class="fa fa-check"></i><b>14</b> Continuous Time Stochastic Processes</a>
<ul>
<li class="chapter" data-level="14.1" data-path="continuous-time-stochastic-processes.html"><a href="continuous-time-stochastic-processes.html#brownian-motion"><i class="fa fa-check"></i><b>14.1</b> Brownian Motion</a></li>
<li class="chapter" data-level="14.2" data-path="continuous-time-stochastic-processes.html"><a href="continuous-time-stochastic-processes.html#filtration"><i class="fa fa-check"></i><b>14.2</b> Filtration</a></li>
<li class="chapter" data-level="14.3" data-path="continuous-time-stochastic-processes.html"><a href="continuous-time-stochastic-processes.html#martingale"><i class="fa fa-check"></i><b>14.3</b> Martingale</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html"><i class="fa fa-check"></i><b>15</b> Stochastic calculus</a>
<ul>
<li class="chapter" data-level="15.1" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#stochastic-integrals"><i class="fa fa-check"></i><b>15.1</b> Stochastic Integrals</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#information"><i class="fa fa-check"></i><b>15.1.1</b> Information</a></li>
<li class="chapter" data-level="15.1.2" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#stochastic-integrals-1"><i class="fa fa-check"></i><b>15.1.2</b> Stochastic Integrals</a></li>
<li class="chapter" data-level="15.1.3" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#martingales"><i class="fa fa-check"></i><b>15.1.3</b> Martingales</a></li>
<li class="chapter" data-level="15.1.4" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#stochastic-calculus-and-the-ito-formula"><i class="fa fa-check"></i><b>15.1.4</b> Stochastic Calculus and the Ito Formula</a></li>
<li class="chapter" data-level="15.1.5" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#the-multidimensional-ito-formula"><i class="fa fa-check"></i><b>15.1.5</b> The multidimensional Ito Formula</a></li>
<li class="chapter" data-level="15.1.6" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#correlated-brownian-motions"><i class="fa fa-check"></i><b>15.1.6</b> Correlated Brownian motions</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#discrete-stochastic-integrals"><i class="fa fa-check"></i><b>15.2</b> Discrete Stochastic Integrals</a></li>
<li class="chapter" data-level="15.3" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#stochastic-differential-equations"><i class="fa fa-check"></i><b>15.3</b> Stochastic Differential Equations</a></li>
<li class="chapter" data-level="15.4" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#partial-differential-equations"><i class="fa fa-check"></i><b>15.4</b> Partial differential equations</a></li>
<li class="chapter" data-level="15.5" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#the-product-integral"><i class="fa fa-check"></i><b>15.5</b> The Product Integral</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html#properties-of-the-product-integral"><i class="fa fa-check"></i><b>15.5.1</b> Properties of the Product Integral</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="linear-algebra.html"><a href="linear-algebra.html"><i class="fa fa-check"></i><b>16</b> Linear Algebra</a>
<ul>
<li class="chapter" data-level="16.1" data-path="linear-algebra.html"><a href="linear-algebra.html#invertible-matrices"><i class="fa fa-check"></i><b>16.1</b> Invertible matrices</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="coding.html"><a href="coding.html"><i class="fa fa-check"></i><b>17</b> Coding</a>
<ul>
<li class="chapter" data-level="17.1" data-path="coding.html"><a href="coding.html#r-packages"><i class="fa fa-check"></i><b>17.1</b> R-Packages</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="coding.html"><a href="coding.html#mlr3"><i class="fa fa-check"></i><b>17.1.1</b> mlr3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://joakim-bilyk.github.io/index.html">Back to main site</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Complete Theory</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="stochastic-calculus" class="section level1 hasAnchor" number="15">
<h1><span class="header-section-number">Chapter 15</span> Stochastic calculus<a href="stochastic-calculus.html#stochastic-calculus" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="stochastic-integrals" class="section level2 hasAnchor" number="15.1">
<h2><span class="header-section-number">15.1</span> Stochastic Integrals<a href="stochastic-calculus.html#stochastic-integrals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We want to formulate financial markets in continuous time and the most elegant theory is obtained from processes that can be defined in terms of <strong>stochastic differential equations</strong> or in other words by their dynamics. We may call them <strong>diffusion processes</strong>, as they may be approximated by a stochastic difference equation:</p>
<p><span class="math display">\[
X_{t+\Delta t}-X_t=\mu(t,X_t)\Delta t+\sigma(t,X_t)Z_t.\tag{4.1}
\]</span></p>
<p>Above <span class="math inline">\(Z_t\)</span> is a normally distributed random variable (a disturbance). In this formulation we say that <span class="math inline">\(S_t\)</span> is driven by two forces: on one hand a locally deterministic velocity or drift <span class="math inline">\(\mu(t,X_t)\)</span> and on the other hand a Gaussian term amplified by the deterministic factor <span class="math inline">\(\sigma(t,X_t)\)</span>.</p>
<div id="information" class="section level3 hasAnchor" number="15.1.1">
<h3><span class="header-section-number">15.1.1</span> Information<a href="stochastic-calculus.html#information" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We consider a primary process <span class="math inline">\(X_t\)</span> and we introduce the notion of information generated by <span class="math inline">\(X_t\)</span> in terms of the natural filtration. The idea can be summed up in the following definition.</p>
<blockquote class="def">
<p><strong>Definition 4.3. (Bjork)</strong> <em>The symbol <span class="math inline">\(\mathcal{F}^X_t\subseteq\mathcal{F}\)</span> denotes “the information generated by <span class="math inline">\(X_t\)</span> on the interval <span class="math inline">\([0,t]\)</span>”, or alternatively “what has happened to <span class="math inline">\(X_t\)</span> over ther interval <span class="math inline">\([0,t]\)</span>”.</em></p>
<ol style="list-style-type: decimal">
<li><em>If, based upon observations of the trajectory <span class="math inline">\(\{X_s;\ 0\le s\le t\}\)</span>, it is possible to decide whether a given event <span class="math inline">\(A\)</span> has occurred or not, then we write this as</em>
<span class="math display">\[
  A\in\mathcal{F}^X_t
  \]</span>
<em>or say that “<span class="math inline">\(A\)</span> is <span class="math inline">\(\mathcal{F}^X_t\)</span>-measurable”.</em></li>
<li><em>If the value of a given random variable <span class="math inline">\(Z\)</span> can be completely determined given observations of the tragectory <span class="math inline">\(\{X_s;\ 0\le s\le t\}\)</span>, then we also write</em>
<span class="math display">\[
  Z\in\mathcal{F}^X_t.\ \text{(}Z\text{ is }\mathcal{F}^X_t\text{-measurable)}
  \]</span>
3._ If <span class="math inline">\(Y\)</span> is a stochastic process such that we have_
<span class="math display">\[
  Y_t\in\mathcal{F}^X_t
  \]</span>
<em>for all <span class="math inline">\(t\ge0\)</span> then we say that <span class="math inline">\(Y_t\)</span> is <strong>adapted</strong> to the <strong>filtration</strong> <span class="math inline">\(\{\mathcal{F}^X_t\}_{t\ge 0}\)</span>. For brevity of notation, we will sometimes write the filtration as <span class="math inline">\(\{\mathcal{F}^X_t\}_{t\ge 0}=\mathbf{F}\)</span>.</em></li>
</ol>
</blockquote>
</div>
<div id="stochastic-integrals-1" class="section level3 hasAnchor" number="15.1.2">
<h3><span class="header-section-number">15.1.2</span> Stochastic Integrals<a href="stochastic-calculus.html#stochastic-integrals-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We will now formulate the theory of stochastic integrals, that is, processes written in terms of stochastic processes with stochastic integrator and/or stochastic integrant. We will consider some given standard Brownian motion <span class="math inline">\(W_t\)</span> and another stochastic process <span class="math inline">\(X_t\)</span>. We need som integrability condition on <span class="math inline">\(X_t\)</span> in order to do the calculations. We therefore determine a selection of suitable stochastic processes <span class="math inline">\(X\)</span> must be contained in.</p>
<blockquote class="def">
<p><strong>Definition 4.4. (Bjork)</strong> <em>Let <span class="math inline">\(X_t\)</span> be a stochastic process, then</em></p>
<ol style="list-style-type: lower-roman">
<li><em>We say that <span class="math inline">\(X_t\)</span> belongs to the class <span class="math inline">\(\mathcal{L}^2[a,b]\)</span> if <span class="math inline">\(X_t\)</span> is adapted to the filtration <span class="math inline">\(\mathcal{F}^X_t\)</span> and the following holds</em>
<span class="math display">\[\int_a^bE[X_s^2]\ ds&lt;\infty\]</span></li>
<li><em>We say that <span class="math inline">\(X_t\)</span> belongs to the class <span class="math inline">\(\mathcal{L}^2\)</span> if</em> <span class="math inline">\(X_t\in\mathcal{L}^2[0,t]\)</span> for all <span class="math inline">\(t&gt;0\)</span>.</li>
</ol>
</blockquote>
<p>We now want to define what we mean by</p>
<p><span class="math display">\[
\int_a^bX_t\ dW_s
\]</span></p>
<p>for some process <span class="math inline">\(X_t\in\mathcal{L}^2\)</span>. We see that a way to go about this problem is to start by defining the concept for a simple stochastic process <span class="math inline">\(X_t\)</span>. By <em>simple</em> we mean a process <span class="math inline">\(X_t\)</span> that is constant on between some deterministic points in time <span class="math inline">\(a=t_0&lt;t_1&lt;\cdots&lt;t_n=b\)</span>. In that case we may define the integral as</p>
<p><span class="math display">\[
\int_a^bX_s\ dW_s = \sum_{k=0}^{n-1}X_{t_k}[W_{t_{k+1}}-W_{t_k}].\tag{4.8}
\]</span></p>
<p>In the more general setting we may follow the following approach:</p>
<ol style="list-style-type: decimal">
<li>Approximate <span class="math inline">\(X\)</span> with a sequence <span class="math inline">\(\{X^n\}_{n\in\mathbb{N}}\)</span> of simple processes such that the following convergence criteria hold</li>
</ol>
<p><span class="math display">\[
  \int_a^bE[(X_s^n-X_s)^2]\ ds\to 0,\ n\to\infty
  \]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>For each <span class="math inline">\(n\)</span> the integral <span class="math inline">\(\int_a^b X_s^n\ dW_s:=Z^n\)</span> is well defined and it is possible to prove, using DCT, that a variable <span class="math inline">\(Z\)</span> exists such that <span class="math inline">\(Z^n\to Z\)</span> that is in <span class="math inline">\(L^2\)</span>.</li>
<li>We now define the stochastic integral by the limit</li>
</ol>
<p><span class="math display">\[
  \int_a^b X_s\ dW_s=\lim_{n\to \infty}\int_a^b X_s^n\ dW_s.\tag{4.9}
  \]</span></p>
<p>Obviously the hardest step is finding the processes <span class="math inline">\(X^n\)</span>. This stochastic har some properties we will use.</p>
<blockquote class="prop">
<strong>Proposition 4.5. (Bjork)</strong> <em>Let <span class="math inline">\(X_t\in\mathcal{L}^2\)</span>, then</em>
<span class="math display">\[\begin{align*}
&amp;E\left[\int_a^b X_s\ dW_s\right]=0.\tag{4.12}\\
&amp;E\left[\left(\int_a^b X_s\ dW_s\right)^2\right]=\int_a^b E[ X_s^2]\ dW_s.\tag{4.13}\\
&amp;\int_a^b X_s\ dW_s\ \text{ is }\mathcal{F}_b^W\text{-measurable.}\tag{4.14}
\end{align*}\]</span>
</blockquote>
</div>
<div id="martingales" class="section level3 hasAnchor" number="15.1.3">
<h3><span class="header-section-number">15.1.3</span> Martingales<a href="stochastic-calculus.html#martingales" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote class="def">
<p><strong>Definition 4.7. (Bjork)</strong> <em>Let <span class="math inline">\(M_t\)</span> be a stochastic process defined on a background space <span class="math inline">\((\Omega,\mathcal{F},P)\)</span>. Let <span class="math inline">\((\mathcal{F}_t)_{t\ge 0}\)</span> be a filtration. If <span class="math inline">\(M_t\)</span> is adapted to the filtration <span class="math inline">\(\mathcal{F}_t\)</span>, <span class="math inline">\(E\vert M_t\vert &lt;\infty\)</span> and</em></p>
<p><span class="math display">\[E[M_t\vert \mathcal{F}_s]=M_s,\hspace{20pt}P-\text{a.s.}\]</span></p>
<p><em>holds for any <span class="math inline">\(t&gt;s\)</span> we say that <span class="math inline">\(M_t\)</span> is a martingale (<span class="math inline">\(\mathbf{F}\)</span>-martingale). If the above has <span class="math inline">\(\ge\)</span> or <span class="math inline">\(\le\)</span> we say that <span class="math inline">\(M_t\)</span> is either a <strong>submartingale</strong> or <strong>supermartingale</strong> respectively.</em></p>
</blockquote>
<blockquote class="prop">
<p><strong>Proposition 4.8. (Bjork)</strong> <em>For any process <span class="math inline">\(X_t\in\mathcal{L}^2[s,t]\)</span> the following hold:</em></p>
<p><span class="math display">\[
E\left[\left.\int_s^t X_s\ dW_s\right\vert\mathcal{F}_s^W\right]=0
\]</span></p>
</blockquote>
<blockquote class="prop">
<p><strong>Corollary 4.9. (Bjork)</strong> <em>For any process <span class="math inline">\(X_t\in\mathcal{L}^2\)</span> the process</em></p>
<p><span class="math display">\[
M_t=\int_s^t X_s\ dW_s,
\]</span></p>
<p><em>is an <span class="math inline">\((\mathcal{F}_t^W)\)</span>-martingale. In other words, modulo an integrability condition, <strong>every stochastic integral is a martingale</strong>.</em></p>
</blockquote>
<blockquote class="lem">
<p><strong>Lemma 4.10. (Bjork)</strong> <em>Let <span class="math inline">\(M_t\)</span> be a stochastic process with stochastic differential, then <span class="math inline">\(M_t\)</span> is a martingale if and only if the stochastic differential has the form <span class="math inline">\(dM_t=X_t\ dW_t\)</span> i.e. <span class="math inline">\(M_t\)</span> as no <span class="math inline">\(dt\)</span>-term.</em></p>
</blockquote>
</div>
<div id="stochastic-calculus-and-the-ito-formula" class="section level3 hasAnchor" number="15.1.4">
<h3><span class="header-section-number">15.1.4</span> Stochastic Calculus and the Ito Formula<a href="stochastic-calculus.html#stochastic-calculus-and-the-ito-formula" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Given this breif introduction to stochastic integrals we may formulate som simple calculus revolving around Ito’s formula. We consider the stochastic process <span class="math inline">\(X_t\)</span> and we suppose that there exist a real number <span class="math inline">\(X_0\)</span> and adapted processes <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> wrt. <span class="math inline">\(\mathcal{F}_t^W\)</span> such that for all <span class="math inline">\(t\ge0\)</span> we have</p>
<p><span class="math display">\[
X_t=X_0+\int_0^t\mu_s\ ds+\int_0^t\sigma_s\ dW_s,\tag{4.16}
\]</span></p>
<p>where <span class="math inline">\(W_t\)</span> is a standard Brownian motion. We know from earlier courses that the above may be written in terms of the dynamics (pure notation):</p>
<p><span class="math display">\[
\left\{\begin{matrix}dX_t=\mu_t\ dt+\sigma_t\ dW_t,\tag{4.17/18}\\ X_0=X_0.\end{matrix}\right.
\]</span></p>
<p>Here we intepret the above as <span class="math inline">\(X_t\)</span> has boundary condition <span class="math inline">\(X_0\)</span> and evolves with a drift <span class="math inline">\(\mu_t\ dt\)</span> amplified and distorted by the drift <span class="math inline">\(\sigma_t\ dW_t\)</span>. We say that <span class="math inline">\(X_t\)</span> has <strong>stochastic differential</strong> <span class="math inline">\(dX_t\)</span> and initial condition <span class="math inline">\(X_0\)</span>.</p>
<p>We want to understand how transformation of such an integral behaves and therefore we introduce some calculus which will tell how for instance <span class="math inline">\(f(t,X_t)\)</span> (for some <span class="math inline">\(C^{1,2}\)</span>-function) behaves. This insight is given by the important Ito’s formula.</p>
<blockquote class="thm">
<p><strong>Thoerem 4.11. (Bjork)</strong> <strong>(Ito’s formula, one-dimensional)</strong> <em>Assume that the process <span class="math inline">\(X\)</span> has a stochastic differential form given by</em></p>
<p><span class="math display">\[
dX_t=\mu_t\ dt + \sigma_t\ dW_t,\tag{4.28}
\]</span></p>
<p><em>where <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are adapted processes, and let <span class="math inline">\(f:\mathbb{R}_+\times\mathbb{R}\to\mathbb{R}\)</span> be a <span class="math inline">\(C^{1,2}\)</span>-function. Define the process <span class="math inline">\(Z\)</span> by <span class="math inline">\(Z_t=f(t,X_t)\)</span>. Then <span class="math inline">\(Z\)</span> has stochastic differential given by</em></p>
<p><span class="math display">\[
df(t,X_t)=\left(\frac{\partial f}{\partial t}(t,X_t) + \mu_t\frac{\partial f}{\partial x}(t,X_t) + \frac{1}{2}\sigma^2_t\frac{\partial^2 f}{\partial x^2}(t,X_t)\right)\ dt+\sigma_t\frac{\partial f}{\partial x}(t,X_t)\ dW_t.\tag{4.29}
\]</span></p>
</blockquote>
<blockquote class="prop">
<p><strong>Proposition 4.12. (Bjork)</strong> <strong>(Ito’s formula, one-dimensional)</strong> <em>With assumptions as in theorem 4.11, <span class="math inline">\(df\)</span> is given by</em></p>
<p><span class="math display">\[
df=\frac{\partial f}{\partial t}\ dt + \frac{\partial f}{\partial x}\ dX_t + \frac{1}{2}\frac{\partial^2 f}{\partial x^2}\ (dX_t)^2,\tag{4.31}
\]</span></p>
<p><em>where we use the following table</em></p>
<p><span class="math display">\[
\left\{\begin{matrix}(dt)^2=0,\\ dt\cdot dW_t=0,\\ (dW_t)^2=dt.\end{matrix}\right.
\]</span></p>
</blockquote>
<blockquote class="lem">
<p><strong>Lemma 4.18. (Bjork)</strong> <em>Let <span class="math inline">\(\sigma(t)\)</span> be deterministic function of time and define the process <span class="math inline">\(X\)</span> by</em></p>
<p><span class="math display">\[
X_t=\int_0^t \sigma(s)\ dW_s.\tag{4.37}
\]</span></p>
<p><em>Then</em></p>
<p><span class="math display">\[
X_t\sim\mathcal{N}\left(0,\int_0^t\sigma^2(s)\ ds\right).
\]</span></p>
</blockquote>
</div>
<div id="the-multidimensional-ito-formula" class="section level3 hasAnchor" number="15.1.5">
<h3><span class="header-section-number">15.1.5</span> The multidimensional Ito Formula<a href="stochastic-calculus.html#the-multidimensional-ito-formula" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider a vector process <span class="math inline">\(X=(X^1,...,X^n)^\top\)</span> where each component <span class="math inline">\(X^i\)</span> has stochastic differential</p>
<p><span class="math display">\[
d X_t^i=\mu_t^i\ dt+\sum_{j=1}^d\sigma^{ij}_t\ dW_t^j
\]</span></p>
<p>where <span class="math inline">\(W^1,...,W^d\)</span> is independent Brownian motions. Then we have respectively the drift vector process <span class="math inline">\(\mu_t\)</span> in <span class="math inline">\(n\)</span> dimensions, the vector Brownian motion in <span class="math inline">\(d\)</span> dimensions and a <span class="math inline">\(n\times d\)</span>-dimensional <strong>diffusion matrix</strong> <span class="math inline">\(\sigma_t\)</span> given as below</p>
<p><span class="math display">\[
\mu_t=\begin{bmatrix}\mu^1_t\\ \vdots\\ \mu^n_t\end{bmatrix},\hspace{10pt}W_t=\begin{bmatrix}W^1_t\\ \vdots\\ W^d_t\end{bmatrix},\hspace{10pt}\sigma_t=\begin{bmatrix}\sigma^{11}_t &amp; \cdots &amp; \sigma^{1d}_t \\ \vdots &amp; \ddots &amp; \vdots\\ \sigma^{n1}_t &amp;\cdots&amp; \sigma^{nd}_t\end{bmatrix}.
\]</span></p>
<p>Given this we may write the dynamics of <span class="math inline">\(X\)</span> as</p>
<p><span class="math display">\[
d X_t=\mu_t\ dt+\sigma_t\ dW_t\in\mathbb{R}^n.
\]</span></p>
<p>Consider now a function <span class="math inline">\(f:\mathbb{R}_+\times \mathbb{R}^n\to\mathbb{R}\)</span> which is a <span class="math inline">\(C^{1,2}\)</span>-mapping. We want to study the dynamics of the process</p>
<p><span class="math display">\[
Z_t=f(t,X_t).
\]</span></p>
<p>The dynamics is given in the multidimensional version of Ito’s formula.</p>
<blockquote class="thm">
<p><strong>Thoerem 4.19. (Bjork)</strong> <strong>(Ito’s formula, multi-dimensional)</strong> <em>Let <span class="math inline">\(X\)</span> be given as above. Then the following holds:</em></p>
<ul>
<li><em>The process <span class="math inline">\(f(t,X_t)\)</span> has the stochastisc differential given by</em>
<span class="math display">\[
  df(t,X_t)=\left(\frac{\partial f}{\partial t}(t,X_t) + \sum_{i=1}^n\mu^i_t\frac{\partial f}{\partial x^i}(t,X_t) + \frac{1}{2}\sum_{i,j=1}^nC_t^{ij}\frac{\partial^2 f}{\partial x^i\partial x^j}(t,X_t)\right)\ dt+\sum_{i=1}^n\sigma^i_t\frac{\partial f}{\partial x^i}(t,X_t)\ dW_t.
  \]</span>
<em>Here the row vector <span class="math inline">\(\sigma^i_t\)</span> is the <span class="math inline">\(i\)</span>’th row of the matrix <span class="math inline">\(\sigma_t\)</span> and the matrix <span class="math inline">\(C\)</span> is defined by <span class="math inline">\(C=\sigma\sigma^\top\)</span>.</em></li>
<li><em>Alternatively, the differential is given by the formula</em>
<span class="math display">\[
  df(t,X_t)=\frac{\partial f}{\partial t}(t,X_t)\ dt + \sum_{i=1}^n\frac{\partial f}{\partial x^i}(t,X_t)\ dX^i_t + \frac{1}{2}\sum_{i,j=1}^n\frac{\partial^2 f}{\partial x^i\partial x^j}(t,X_t)\ dX^i_tdX^j_t,
  \]</span>
<em>with the formal multiplication table</em>
<span class="math display">\[
  \left\{\begin{matrix}(dt)^2=0,\\  dt\cdot dW_t^i=0, &amp; i = 1,...,d,\\ (dW_t^i)^2=dt, &amp; i=1,...,d, \\ dW_t^i\cdot dW_t^i =0, &amp; i\ne j.\end{matrix}\right.
  \]</span></li>
</ul>
</blockquote>
<p>Obviously, one can write the differential in Ito’s formula in many other ways including a matrix-wise version using the Hessian matrix <span class="math inline">\(H_{ij}=\frac{\partial^2 f}{\partial x^i\partial x^j}\)</span>.</p>
</div>
<div id="correlated-brownian-motions" class="section level3 hasAnchor" number="15.1.6">
<h3><span class="header-section-number">15.1.6</span> Correlated Brownian motions<a href="stochastic-calculus.html#correlated-brownian-motions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the previous section the <span class="math inline">\(d\)</span>-dimensional Brownian was assumed to have independent Brownian motions. However we may instead consider a variation where we have some dependence between the Brownian motions.</p>
<p>This section has not been finished.
</p>
</div>
</div>
<div id="discrete-stochastic-integrals" class="section level2 hasAnchor" number="15.2">
<h2><span class="header-section-number">15.2</span> Discrete Stochastic Integrals<a href="stochastic-calculus.html#discrete-stochastic-integrals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This section has not been finished.
</p>
</div>
<div id="stochastic-differential-equations" class="section level2 hasAnchor" number="15.3">
<h2><span class="header-section-number">15.3</span> Stochastic Differential Equations<a href="stochastic-calculus.html#stochastic-differential-equations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We start the chapter by formalising some used objects. We consider the following objects.</p>
<ul>
<li><span class="math inline">\(M(n,d)\)</span> denotes the class of <span class="math inline">\(n\times d\)</span>-matrices.</li>
<li><span class="math inline">\(W\)</span> is a <span class="math inline">\(d\)</span>-dimensional Brownian motion</li>
<li><span class="math inline">\(\mu\)</span> is a <span class="math inline">\(\mathbb{R}^n\)</span>-valued function with arguments <span class="math inline">\((t,X_t)\)</span> with <span class="math inline">\(X_t\)</span> being a <span class="math inline">\(n\)</span>-dimensional stochastic process.</li>
<li><span class="math inline">\(\sigma\)</span> a <span class="math inline">\(M(n,d)\)</span>-valued function with arguments as in <span class="math inline">\(\mu\)</span>.</li>
<li><span class="math inline">\(x_0\)</span> a <span class="math inline">\(\mathbb{R}^n\)</span>-valued vector.</li>
</ul>
<p>We want then to understand when the following has a solution</p>
<p><span class="math display">\[
dX_t=\mu(t,X_t)\ dt + \sigma(t,X_t)\ dW_t,\ \ X_0=x_0.\tag{5.1/2}
\]</span></p>
<p>We call such an equation the <strong>stochastic differential equation</strong> or simply SDE. We know that the above is loosely notation for the integral form as</p>
<p><span class="math display">\[
X_t=x_0+\int_0^t\mu(s,X_s)\ ds +\int_0^t\sigma(s,X_s)\ dW_s,\tag{5.3}
\]</span></p>
<p>for all <span class="math inline">\(t\ge 0\)</span>. The following proposition tells us when an solution exist to the problem above. In the below <span class="math inline">\(\Vert \cdot \Vert\)</span> is usual euclidian norm</p>
<p><span class="math display">\[
\Vert x\Vert=\sqrt{\sum_{i=1}^nx_i^2}.
\]</span></p>
<blockquote class="prop">
<p><strong>Proposition 5.1. (Bjork)</strong> <em>Suppose that there existis a constant <span class="math inline">\(K\)</span> such that the following conditions are satisfied for all <span class="math inline">\(x,y\)</span> and <span class="math inline">\(t\)</span>.</em>
<span class="math display">\[\begin{align*}
\Vert \mu(t,x) - \mu(t,y) \Vert &amp;\le K\Vert x-y\Vert,\tag{5.6}\\
\Vert \sigma(t,x) - \sigma(t,y) \Vert &amp;\le K\Vert x-y\Vert,\tag{5.7}\\
\Vert \mu(t,x) \Vert +\Vert \sigma(t,x) \Vert&amp;\le K(1+\Vert x\Vert).\tag{5.8}
\end{align*}\]</span>
<em>Then there exists a unique solution to the SDE above. Furthermore, the solution has the properties</em></p>
<ol style="list-style-type: decimal">
<li><em><span class="math inline">\(X\)</span> is <span class="math inline">\(\mathcal{F}_t^W\)</span>-adapted.</em></li>
<li><em><span class="math inline">\(X\)</span> has continuous trajectories.</em></li>
<li><em><span class="math inline">\(X\)</span> is a Markov process.</em></li>
<li><em>There exists a constant <span class="math inline">\(C\)</span> such that</em>
<span class="math display">\[
  E[\Vert X_t\Vert^2]\le Ce^{Ct}(1+\Vert x_0\Vert^2).\tag{5.9}
  \]</span></li>
</ol>
</blockquote>
<p>In genereal the solution to an SDE is so complicated, that it in practical terms is unsolvable and may only be approximated on a finely subdividet grid as jumps. There does however exist som nontrivial cases where we may infer a analytical solution. One is the rather important <strong>Geometric Brownian motion</strong>.</p>
<blockquote class="prop">
<p><strong>Proposition 5.2. (Bjork)</strong> <em>Consider the SDE</em></p>
<p><span class="math display">\[
dX_t=\alpha X_t\ dt+\sigma X_t\ dW_t,\tag{5.13}
\]</span></p>
<p><em>with <span class="math inline">\(X_0=x_0\)</span>. Then the solution is given as</em></p>
<p><span class="math display">\[
X_t=x_0\cdot \exp\left\{\left(\alpha- \frac{\sigma^2}{2}\right)t+\sigma W_t\right\}.\tag{5.15}
\]</span></p>
<p><em>The expected value of <span class="math inline">\(X\)</span> is given as <span class="math inline">\(E[X_t]=x_0e^{\alpha t}\)</span> (eq. 5.16).</em></p>
</blockquote>
<p>One other generalisation that is analytically solvable is the Linear SDE.</p>
<blockquote class="prop">
<p><strong>Proposition 5.3. (Bjork)</strong> <em>Consider the SDE</em></p>
<p><span class="math display">\[
dX_t=(A X_t + b_t)\ dt+ \sigma_t\ dW_t,\tag{5.19}
\]</span></p>
<p><em>with <span class="math inline">\(X_0=x_0\)</span> and <span class="math inline">\(A\in M(n,n)\)</span> and <span class="math inline">\(b_t\)</span> being a real-valued function. Then the solution is given as</em></p>
<p><span class="math display">\[
X_t=e^{At}x_0+\int_0^te^{A(t-s)}b_s\ ds+\int_0^te^{A(t-s)}\sigma_s\ dW_s.\tag{5.20}
\]</span></p>
<p><em>Where we define the exponential of a matrix as below</em></p>
<p><span class="math display">\[
e^{At}=\sum_{k=0}^\infty A^k\frac{1}{k!}t^k.
\]</span></p>
</blockquote>
<p>In general with the SDE we have a partial differential operator <span class="math inline">\(\mathcal{A}\)</span> called the <strong>infinitesimal operator</strong> of <span class="math inline">\(X\)</span> which has some interesting analytical properties regarding <span class="math inline">\(X\)</span>.</p>
<blockquote class="def">
<p><strong>Definition 5.4. (Bjork)</strong> <em>Consider the SDE</em></p>
<p><span class="math display">\[
dX_t=\mu(t,X_t)\ dt+\sigma(t,X_t)\ dW_t.\tag{5.21}
\]</span></p>
<p><em>The partial differential operator <span class="math inline">\(\mathcal{A}\)</span> is defined, for any function <span class="math inline">\(h\in C^2(\mathbb{R}^n)\)</span>, by</em></p>
<p><span class="math display">\[
\mathcal{A}h(t,x)=\sum_{i=1}^n\mu_i(t,x)\frac{\partial h}{\partial x_i}(x) + \frac{1}{2}\sum_{i,j=1}^n (\sigma(t,x)\sigma(t,x)^\top)_{ij}\frac{\partial^2h}{\partial x_i\partial x_j}(x).
\]</span></p>
</blockquote>
<p>We see that in terms of Ito’s formula the operator is included as such</p>
<p><span class="math display">\[
df(t,X_t)=\left\{\frac{\partial f}{\partial t}(t,X_t)+\mathcal{A}f(t,x)\right\}\ dt+[\nabla_xf](t,X_t)\sigma(t,X_t)\ dW_t,
\]</span></p>
<p>where <span class="math inline">\(\nabla_x\)</span> is the gradient for function <span class="math inline">\(h\in C^1(\mathbb{R}^n)\)</span> as</p>
<p><span class="math display">\[
\nabla_xh(x)=\left[\frac{\partial h}{\partial x_1}(x),...,\frac{\partial h}{\partial x_n}(x)\right].
\]</span></p>
</div>
<div id="partial-differential-equations" class="section level2 hasAnchor" number="15.4">
<h2><span class="header-section-number">15.4</span> Partial differential equations<a href="stochastic-calculus.html#partial-differential-equations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<blockquote class="prop">
<p><strong>Proposition 5.5. (Bjork)</strong> <strong>(Feynmann-Kac)</strong> <em>Assume that <span class="math inline">\(F\)</span> is a solution to the boundary value problem</em></p>
<p><span class="math display">\[
\frac{\partial F}{\partial t}(t,x)+\mu(t,x)\frac{\partial F}{\partial x}(x,t)+\frac{1}{2}\sigma^2(t,x)\frac{\partial^2 F}{\partial x^2}(t,x)=0,
\]</span></p>
<p><em>with boundary condition <span class="math inline">\(F(T,x)=\Phi(x)\)</span>. Assume furthermore that the process</em></p>
<p><span class="math display">\[
\sigma(s,X_s)\frac{\partial F}{\partial x}(s,X_s) \in \mathcal{L}^2
\]</span></p>
<p><em>as per definition 4.4, where <span class="math inline">\(X\)</span> is defined below. Then <span class="math inline">\(F\)</span> has the representation</em></p>
<p><span class="math display">\[
F(t,x)=E_{t,x}[\Phi(X_T)]=E[\Phi(X_T)\ \vert\ X_t=x],\tag{5.29}
\]</span></p>
<p><em>where <span class="math inline">\(X\)</span> satisfies the SDE</em></p>
<p><span class="math display">\[
dX_s=\mu(s,X_s)\ ds+\sigma(s,X_s)\ dW_s,\tag{5.30}
\]</span></p>
<p><em>with boundary condition <span class="math inline">\(X_t=x\)</span>.</em></p>
</blockquote>
<blockquote class="prop">
<p><strong>Proposition 5.6. (Bjork)</strong> <strong>(Feynmann-Kac)</strong> <em>Assume that <span class="math inline">\(F\)</span> is a solution to the boundary value problem</em></p>
<p><span class="math display">\[
\frac{\partial F}{\partial t}(t,x)+\mu(t,x)\frac{\partial F}{\partial x}(x,t)+\frac{1}{2}\sigma^2(t,x)\frac{\partial^2 F}{\partial x^2}(t,x)-rF(t,x)=0,\tag{5.34}
\]</span></p>
<p><em>with boundary condition <span class="math inline">\(F(T,x)=\Phi(x)\)</span>. Assume furthermore that the process</em></p>
<p><span class="math display">\[
e^{-rs}\sigma(s,X_s)\frac{\partial F}{\partial x}(s,X_s) \in \mathcal{L}^2
\]</span></p>
<p><em>as per definition 4.4, where <span class="math inline">\(X\)</span> is defined below. Then <span class="math inline">\(F\)</span> has the representation</em></p>
<p><span class="math display">\[
F(t,x)=e^{-r(T-t)}E_{t,x}[\Phi(X_T)]=e^{-r(T-t)}E[\Phi(X_T)\ \vert\ X_t=x],\tag{5.36}
\]</span></p>
<p><em>where <span class="math inline">\(X\)</span> satisfies the SDE</em></p>
<p><span class="math display">\[
dX_s=\mu(s,X_s)\ ds+\sigma(s,X_s)\ dW_s,\tag{5.37}
\]</span></p>
<p><em>with boundary condition <span class="math inline">\(X_t=x\)</span>.</em></p>
</blockquote>
<blockquote class="prop">
<p><strong>Proposition 5.8. (Bjork)</strong> <strong>(Feynmann-Kac)</strong> <em>Assume that <span class="math inline">\(F\)</span> is a solution to the boundary value problem</em></p>
<p><span class="math display">\[
\frac{\partial F}{\partial t}(t,x)+\sum_{i=1}^n\mu_i(t,x)\frac{\partial F}{\partial x}(x,t)+\frac{1}{2}\sum_{i,j=1}^n C_{ij}(t,x)\frac{\partial^2 F}{\partial x^2}(t,x)-rF(t,x)=0,
\]</span></p>
<p><em>with boundary condition <span class="math inline">\(F(T,x)=\Phi(x)\)</span> and <span class="math inline">\(C_{ij}=\sigma \sigma^\top\)</span>. Assume furthermore that the process</em></p>
<p><span class="math display">\[
e^{-rs}\sum_{i=1}^n\sigma_i(s,X_s)\frac{\partial F}{\partial x}(s,X_s) \in \mathcal{L}^2
\]</span></p>
<p><em>as per definition 4.4, where <span class="math inline">\(X\)</span> is defined below. Then <span class="math inline">\(F\)</span> has the representation</em></p>
<p><span class="math display">\[
F(t,x)=e^{-r(T-t)}E_{t,x}[\Phi(X_T)],\tag{5.39}
\]</span></p>
<p><em>where <span class="math inline">\(X\)</span> satisfies the SDE</em></p>
<p><span class="math display">\[
dX_s=\mu(s,X_s)\ ds+\sigma(s,X_s)\ dW_s,\tag{5.40}
\]</span></p>
<p><em>with boundary condition <span class="math inline">\(X_t=x\)</span>.</em></p>
</blockquote>
<blockquote class="prop">
<p><strong>Proposition 5.9. (Bjork)</strong> <em>Consider as given a vector process <span class="math inline">\(X\)</span> with generator <span class="math inline">\(\mathcal{A}\)</span>, and a function <span class="math inline">\(F(t,x)\)</span>. Then, modulo some integrability condition, the following hold:</em></p>
<ul>
<li><em>The process <span class="math inline">\(F(t,X_t)\)</span> is a martingale relative to the filtration <span class="math inline">\(\mathcal{F}^X\)</span> if and only if <span class="math inline">\(F\)</span> satisfies the PDE</em>
<span class="math display">\[
  \frac{\partial F}{\partial t}+\mathcal{A}F=0.
  \]</span></li>
<li><em>The process <span class="math inline">\(F(t,X_t)\)</span> is a martingale relative to the filtration <span class="math inline">\(\mathcal{F}^X\)</span> if and only if, for every <span class="math inline">\((t,x)\)</span> and <span class="math inline">\(T\ge t\)</span>, we have</em>
<span class="math display">\[
  F(t,x)=E_{t,x}[F(T,X_T)].
  \]</span></li>
</ul>
</blockquote>
</div>
<div id="the-product-integral" class="section level2 hasAnchor" number="15.5">
<h2><span class="header-section-number">15.5</span> The Product Integral<a href="stochastic-calculus.html#the-product-integral" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Consider the (stochastic) function <span class="math inline">\(Y : \mathbb{R} \to \mathbb{R}^{n\times n}\)</span>, where <span class="math inline">\(\mathbb{R}^{n\times n}\)</span> is the set of all <span class="math inline">\(n\times n\)</span> real-valued matrices, that is <span class="math inline">\(Y\)</span> has the matrix-representation</p>
<p><span class="math display">\[
Y(t)=\begin{bmatrix}
Y_{11}(t) &amp; \cdots &amp; Y_{1n}(t)\\
Y_{21}(t) &amp; \cdots &amp; Y_{2n}(t)\\
\vdots &amp; \ddots &amp; \vdots \\
Y_{n1}(t) &amp; \cdots &amp; Y_{nn}(t)
\end{bmatrix}.
\]</span></p>
<p>Assume furthermore that for each coordinate function <span class="math inline">\(Y_{ij}(t)\)</span> the equation</p>
<p><span class="math display">\[
\frac{dY_{ij}}{dt}(t)=Y_{i1}(t)A_{1j}(t)+\cdots+Y_{in}(t)A_{nj}(t),\hspace{15pt}Y_{ij}(s)=C_{ij},
\]</span></p>
<p>is satisfied. That is on matrix form the linear system of differential equation</p>
<p><span class="math display">\[
\frac{dY}{dt}(t)=Y(t)A(t),\hspace{15pt}Y(s)=C,
\]</span></p>
<p>for some function <span class="math inline">\(A : \mathbb{R}\to\mathbb{R}^{n\times n}\)</span> and initial condition <span class="math inline">\(C\in \mathbb{R}^{n\times n}\)</span>. If <span class="math inline">\(A\)</span> is continuous we know that <span class="math inline">\(Y\)</span> is well-defined and absolutely continuous. We may then state the following theorem regarding uniqueness and existence of such a function above.</p>
<blockquote class="thm">
<p><strong>Theorem 1.1. (Bladt)</strong> <strong>(Uniqueness)</strong> <em>Consider the homogeneous system of linear differential equations</em></p>
<p><span class="math display">\[
\mathbf{Y}&#39;(t)=\mathbf{Y}(t)\mathbf{A}(t),\hspace{15pt} \mathbf{Y}(s)=\mathbf{C},\tag{1}
\]</span></p>
<p><em>where <span class="math inline">\(\mathbf{Y}(t)\)</span>, <span class="math inline">\(\mathbf{A}(t)\)</span> and <span class="math inline">\(\mathbf{C}\)</span> are <span class="math inline">\(n\times n\)</span>-matrices and <span class="math inline">\(\mathbf{A}(t)\)</span> is continuous on <span class="math inline">\([s,t]\)</span>. Then (1) has at most one solution.</em></p>
</blockquote>
<blockquote class="thm">
<p><strong>Theorem 1.2. (Bladt)</strong> <strong>(Existence)</strong> <em>The matrix function</em></p>
<p><span class="math display">\[
\mathbf{Y}(t)=\sum_{k=0}^\infty \mathbf{Y}_k(t),\tag{3}
\]</span></p>
<p><em>converges uniformly and absolutely on finite intervals, and solves the differential equation</em></p>
<p><span class="math display">\[
\mathbf{Y}&#39;(t)=\mathbf{Y}(t)\mathbf{A}(t),\hspace{15pt} \mathbf{Y}(s)=\mathbf{C}.
\]</span></p>
</blockquote>
<p>Now, we know that for any system as in (1) with a continuous function <span class="math inline">\(\mathbf{A}(t)\)</span> we can always construct the solution as some converging series as per theorem 1.2 then theorem 1.1 gives that the solution is unique. We can then with a piece of mind define a symbol for such a solution, without care for the <em>exact</em> solution.</p>
<blockquote class="def">
<p><strong>Definition 1.3. (Bladt)</strong> <strong>(The Product Integral)</strong> <em>For any continuous matrix function <span class="math inline">\(\mathbf{A}(t)\)</span> we define the product integral as</em></p>
<p><span class="math display">\[
\prod_{s}^t(\mathbf{I}+\mathbf{A}(x)\ dx)
\]</span></p>
<p><em>as the unique solution <span class="math inline">\(\mathbf{Y}(t)\)</span> to</em></p>
<p><span class="math display">\[
\mathbf{Y}&#39;(t)=\mathbf{Y}(t)\mathbf{A}(t),\hspace{15pt} \mathbf{Y}(s)=\mathbf{I}.
\]</span></p>
</blockquote>
<p>From a simple integral argument we may construct <em>a</em> converging series not containing <span class="math inline">\(\mathbf{Y}\)</span> itself. We see that
<span class="math display">\[\begin{align*}
\prod_{s}^t(\mathbf{I}+\mathbf{A}(x)\ dx)&amp;=\mathbf{I}+\int_s^t\mathbf{Y}&#39;(x)\ dx=\mathbf{I}+\int_s^t\mathbf{Y}(x)\mathbf{A}(x)\ dx\\
&amp;=\mathbf{I}+\int_s^t\left[ \mathbf{I}+\int_s^{x_1}\mathbf{Y}&#39;(x_2)\ dx_2\right]\mathbf{A}(x_1)\ dx_1\\
&amp;=\mathbf{I}+\int_s^t\left[ \mathbf{I}+\int_s^{x_1}\mathbf{Y}(x_2)\mathbf{A}(x_2)\ dx_2\right]\mathbf{A}(x_1)\ dx_1\\
&amp;=\mathbf{I}+\int_s^t\mathbf{A}(x_1)\ dx_1+\int_s^t\int_s^{x_1}\mathbf{Y}(x_2)\mathbf{A}(x_2)\mathbf{A}(x_1)\ dx_2\ dx_1.
\end{align*}\]</span>
One can continue indefinitely and see that we have the following representation.</p>
<blockquote class="prop">
<p><strong>Corollary 1.4. (Bladt)</strong> <strong>(Peano Representation)</strong> <em>The prduct integral has series representation given by</em>
<span class="math display">\[\begin{align*}
\prod_{s}^t(\mathbf{I}+\mathbf{A}(x)\ dx)&amp;=\mathbf{I}+\sum_{i=1}^\infty\int_s^t\int_s^{x_1}\cdots\int_s^{x_n}A(x_n)\cdots\mathbf{A}(x_2)\mathbf{A}(x_1)\ dx_n\cdots dx_2\ dx_1\\
&amp;=\mathbf{I}+\int_s^t\mathbf{A}(x_1)\ dx_1+\sum_{i=2}^\infty\int_s^t\int_s^{x_1}\cdots\int_s^{x_n}A(x_n)\cdots\mathbf{A}(x_2)\mathbf{A}(x_1)\ dx_n\cdots dx_2\ dx_1.
\end{align*}\]</span></p>
</blockquote>
<div id="properties-of-the-product-integral" class="section level3 hasAnchor" number="15.5.1">
<h3><span class="header-section-number">15.5.1</span> Properties of the Product Integral<a href="stochastic-calculus.html#properties-of-the-product-integral" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The product integral is the fundamental solution in the sense that if</p>
<p><span class="math display">\[
\mathbf{Y}&#39;(t)=\mathbf{Y}(t)\mathbf{A}(t),\hspace{15pt}\mathbf{Y}(s)=\mathbf{C},
\]</span></p>
<p>then</p>
<p><span class="math display">\[
\mathbf{Y}(t)=\mathbf{C}\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big).
\]</span></p>
<p>We furthermore have for any <span class="math inline">\(s,t,u\)</span> have</p>
<p><span class="math display">\[
\mathbf{Y}(t)=\mathbf{Y}(s)\prod_{s}^u\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\prod_{u}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big).
\]</span></p>
<p>From uniqueness we then get the following theorem.</p>
<blockquote class="thm">
<p><strong>Theorem 1.5. (Bladt)</strong> <em>For any <span class="math inline">\(s,t,u\)</span> we have that</em></p>
<p><span class="math display">\[
\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)=\prod_{s}^u\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\prod_{u}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big).
\]</span></p>
</blockquote>
<p>By choosing <span class="math inline">\(u=t\)</span> in the above we get the following corollary.</p>
<blockquote class="prop">
<p><strong>Corollary 1.6. (Bladt)</strong> <em>The inverse of the product integral is</em></p>
<p><span class="math display">\[
\left[\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\right]^{-1}=\prod_{t}^s\big(\mathbf{I}+\mathbf{A}(x)\ dx\big).
\]</span></p>
</blockquote>
<blockquote class="thm">
<p><strong>Theorem 1.7. (Bladt)</strong> <em>If <span class="math inline">\(\mathbf{A}(x)\)</span> commutes withall <span class="math inline">\(\mathbf{B}(x=\)</span> i.e. <span class="math inline">\(\mathbf{A}(x)\mathbf{B}(x)=\mathbf{B}(x)\mathbf{A}(x)\)</span>, then</em></p>
<p><span class="math display">\[
\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\prod_{s}^t\big(\mathbf{I}+\mathbf{B}(x)\ dx\big)=\prod_{s}^t\big(\mathbf{I}+\left(\mathbf{A}(x)+\mathbf{B}(x)\right)\ dx\big).
\]</span></p>
</blockquote>
<blockquote class="prop">
<p><strong>Corollary 1.8. (Bladt)</strong> <em>Let <span class="math inline">\(r\)</span> be a real-valued function, then</em></p>
<p><span class="math display">\[
\exp\left(-\int_s^t r(x)\ dx\right)\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)=\prod_{s}^t\big(\mathbf{I}+\left(\mathbf{A}(x)-r(x)\mathbf{I}\right)\ dx\big).
\]</span></p>
</blockquote>
<blockquote class="thm">
<p><strong>Theorem 1.9. (Bladt)</strong> <em>If <span class="math inline">\(\mathbf{A}(x)\)</span> commutes for all <span class="math inline">\(x\)</span> i.e. <span class="math inline">\(\mathbf{A}(y)\mathbf{A}(x)=\mathbf{A}(x)\mathbf{A}(y)\)</span>, then</em></p>
<p><span class="math display">\[
\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)=e^{\int_s^t\mathbf{A}(x)\ dx}.
\]</span></p>
<p><em>In particular, if <span class="math inline">\(\mathbf{A}(x)=\mathbf{A}\lambda(x)\)</span> for some real-valued function <span class="math inline">\(\lambda\)</span> and a <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(\mathbf{A}\)</span> then</em></p>
<p><span class="math display">\[
\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)=e^{\mathbf{A}\int_s^t\lambda(x)\ dx}.
\]</span></p>
</blockquote>
<p>Taking the function <span class="math inline">\(\lambda=1\)</span> we have that <span class="math inline">\(\int_s^t\lambda(x)\ dx=(t-s)\)</span> and so we get the result.</p>
<blockquote class="thm">
<p><strong>Theorem 1.10. (Bladt)</strong> <em>If <span class="math inline">\(\mathbf{A}(x)=\mathbf{A}\)</span> is constant then</em></p>
<p><span class="math display">\[
\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)=e^{\mathbf{A}(t-s)}.
\]</span></p>
</blockquote>
<blockquote class="thm">
<p><strong>Theorem 1.11. (Bladt)</strong> <em>The product integral satisfies</em></p>
<p><span class="math display">\[
\frac{\partial}{\partial s}\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)=-\mathbf{A}(s)\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big).
\]</span></p>
<p><em>On the other hand, the solution to the system of differential equations</em></p>
<p><span class="math display">\[
\frac{\partial}{\partial s}\mathbf{X}(s)=-\mathbf{A}(s)\mathbf{X}(s)
\]</span></p>
<p><em>with initial condition <span class="math inline">\(\mathbf{X}(t)=\mathbf{I}\)</span> is the function</em></p>
<p><span class="math display">\[
s\mapsto\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)
\]</span></p>
</blockquote>
<p>We have a very useful result for insurance mathematics and markov chains given by the Van Loan’s theorem giving the product integral of a block matrix with zero lower left block.</p>
<blockquote class="thm">
<p><strong>Theorem 1.12. (Bladt)</strong> <em>Let <span class="math inline">\(\mathbf{A}(x)\)</span>, <span class="math inline">\(\mathbf{B}(x)\)</span> and <span class="math inline">\(\mathbf{C}(x)\)</span> be continuous matrix functions such that</em></p>
<p><span class="math display">\[
\mathbf{D}(x)=\begin{bmatrix}
\mathbf{A}(x) &amp; \mathbf{B}(x)\\
\mathbf{0} &amp; \mathbf{C}(x)
\end{bmatrix},
\]</span></p>
<p><em>is a square matrix. Then the product integral of <span class="math inline">\(\mathbf{D}\)</span> is</em></p>
<p><span class="math display">\[
\prod_{s}^t\big(\mathbf{I}+\mathbf{D}(x)\ dx\big)=
\begin{bmatrix}
\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big) &amp; \int_s^t\prod_{s}^u\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\mathbf{B}(u)\prod_{u}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\ du\\
\mathbf{0} &amp; \prod_{s}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)
\end{bmatrix}.
\]</span></p>
</blockquote>
<details>
<summary>
<strong>Proof.</strong>
</summary>
<p>Start by defining <span class="math inline">\(\mathbf{X}(t)\)</span> as below
<span class="math display">\[\begin{align*}
\mathbf{X}(t)&amp;=
\begin{bmatrix}
\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big) &amp; \int_s^t\prod_{s}^u\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\mathbf{B}(u)\prod_{u}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\ du\\
\mathbf{0} &amp; \prod_{s}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)
\end{bmatrix}\\
&amp;:=\begin{bmatrix}
\mathbf{X}_{11}(t) &amp; \mathbf{X}_{12}(t)\\
\mathbf{X}_{21}(t) &amp; \mathbf{X}_{22}(t)
\end{bmatrix}.
\end{align*}\]</span>
The derivative is then
<span class="math display">\[\begin{align*}
\frac{d}{dt}\mathbf{X}(t)&amp;=
\begin{bmatrix}
\frac{d}{dt}\mathbf{X}_{11}(t) &amp; \frac{d}{dt}\mathbf{X}_{12}(t)\\
\frac{d}{dt}\mathbf{X}_{21}(t) &amp; \frac{d}{dt}\mathbf{X}_{22}(t)
\end{bmatrix}.
\end{align*}\]</span>
with
<span class="math display">\[\begin{align*}
\frac{d}{dt}\mathbf{X}_{11}(t)&amp;=\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\mathbf{A}(t),\\
\frac{d}{dt}\mathbf{X}_{12}(t)&amp;= \frac{d}{dt}\int_s^t\prod_{s}^u\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\mathbf{B}(u)\prod_{u}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\ du,\\
\frac{d}{dt}\mathbf{X}_{21}(t)&amp;=\mathbf{0},\\
\frac{d}{dt}\mathbf{X}_{22}(t)&amp;=\prod_{s}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\mathbf{C}(t).
\end{align*}\]</span>
Consider that
<span class="math display">\[\begin{align*}
\prod_{u}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)&amp;=\prod_{u}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\underbrace{\prod_{t}^s\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\prod_{s}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)}_{=\mathbf{I}}\\
&amp;=\prod_{u}^s\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\prod_{s}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big),
\end{align*}\]</span>
hence using af Riemann approximation of the integral <span class="math inline">\(\mathbf{X}_{12}(t)\)</span> we may write
<span class="math display">\[\begin{align*}
\mathbf{X}_{12}(t)&amp;=\int_s^t\prod_{s}^u\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\mathbf{B}(u)\prod_{u}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\ du\\
&amp;=\int_s^t\prod_{s}^u\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\mathbf{B}(u)\prod_{u}^s\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\prod_{s}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\ du\\
&amp;=\lim_{n\to \infty}\frac{t-s}{n}\sum_{i=0}^n\prod_{s}^{s+(t-s)i/n}\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\mathbf{B}(s+(t-s)i/n)\prod_{s+(t-s)i/n}^s\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\\
&amp;\prod_{s}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\\
&amp;=\left\{\lim_{n\to \infty}\frac{t-s}{n}\sum_{i=0}^n\prod_{s}^{s+(t-s)i/n}\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\mathbf{B}(s+(t-s)i/n)\prod_{s+(t-s)i/n}^s\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\right\}\\
&amp;\prod_{s}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\\
&amp;=\left\{\int_s^t\prod_{s}^u\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\mathbf{B}(u)\prod_{u}^s\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\ du\right\}\prod_{s}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big).
\end{align*}\]</span>
We then get that
<span class="math display">\[\begin{align*}
\frac{d}{dt}\mathbf{X}_{12}(t)&amp;=\frac{d}{dt}\left\{\int_s^t\prod_{s}^u\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\mathbf{B}(u)\prod_{u}^s\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\ du\right\}\prod_{s}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\\
&amp;=\left\{\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\mathbf{B}(t)\prod_{t}^s\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\right\}\prod_{s}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\\
&amp;+\left\{\int_s^t\prod_{s}^u\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\mathbf{B}(u)\prod_{u}^s\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\ du\right\}\prod_{s}^t\big(\mathbf{I}+\mathbf{C}(x)\ dx\big)\mathbf{C}(t)\\
&amp;=\prod_{s}^t\big(\mathbf{I}+\mathbf{A}(x)\ dx\big)\mathbf{B}(t)+\mathbf{X}_{12}(t)\mathbf{C}(t).
\end{align*}\]</span>
We hope to show that <span class="math inline">\(\frac{d}{dt}\mathbf{X}(t)=\mathbf{X}(t)\mathbf{D}(t)\)</span>. Calculating the right side we have
<span class="math display">\[\begin{align*}
\mathbf{X}(t)\mathbf{D}(t)&amp;=
\begin{bmatrix}
\mathbf{X}_{11}(t) &amp; \mathbf{X}_{12}(t)\\
\mathbf{0} &amp; \mathbf{X}_{22}(t)
\end{bmatrix}
\begin{bmatrix}
\mathbf{A}(x) &amp; \mathbf{B}(x)\\
\mathbf{0} &amp; \mathbf{C}(x)
\end{bmatrix}\\
&amp;=\begin{bmatrix}
\mathbf{X}_{11}(t)\mathbf{A}(x) &amp; \mathbf{X}_{11}(t)\mathbf{B}(x)+\mathbf{X}_{12}(t)\mathbf{C}(x)\\
\mathbf{0} &amp; \mathbf{X}_{22}(t)\mathbf{C}(x)
\end{bmatrix},
\end{align*}\]</span>
given that <span class="math inline">\(\mathbf{X}\)</span> satisfies the desired differential equation and so it follows that <span class="math inline">\(\mathbf{X}\)</span> is the product integral <span class="math inline">\(\prod_{s}^t\big(\mathbf{I}+\mathbf{D}(x)\ dx\big)\)</span> as desired.<span class="math inline">\(\blacksquare\)</span></p>
</details>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="continuous-time-stochastic-processes.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linear-algebra.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
