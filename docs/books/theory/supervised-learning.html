<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>10.1 Supervised Learning | Mathematics of the Actuarial Sciences</title>
  <meta name="description" content="This is a description of the document." />
  <meta name="generator" content="bookdown 0.33 and GitBook 2.6.7" />

  <meta property="og:title" content="10.1 Supervised Learning | Mathematics of the Actuarial Sciences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a description of the document." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="10.1 Supervised Learning | Mathematics of the Actuarial Sciences" />
  
  <meta name="twitter:description" content="This is a description of the document." />
  

<meta name="author" content="Joakim Bilyk" />


<meta name="date" content="2023-04-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="probabilistic-machine-learning.html"/>
<link rel="next" href="training-validating-and-testing.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.6.2/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.9/grViz.js"></script>
<script src="https://code.jquery.com/jquery-1.9.1.js"></script>

<script>
    $(function() {
        var element = document.body;
        if (localStorage.chkbx && localStorage.chkbx != '') {
            $('#remember_me').attr('checked', 'checked');
            element.classList.toggle("dark-mode");
            document.querySelector('.book-header.fixed').click();
        } else {
            $('#remember_me').removeAttr('checked');
            document.querySelector('.book-header.fixed').click();
        }

        $('#remember_me').click(function() {

            if ($('#remember_me').is(':checked')) {
                // save username and password
                localStorage.chkbx = $('#remember_me').val();
                element.classList.toggle("dark-mode");
                document.querySelector('.book-header.fixed').click();
            } else {
                localStorage.chkbx = '';
                element.classList.toggle("dark-mode");
                document.querySelector('.book-header.fixed').click();
            }
        });
    });

</script>

<div class = "sticky-darkmode-toggle">
  <label class="switch">
  <input type="checkbox" value="remember-me" id="remember_me">
  <span class="slider round">
  </span>
  </label>
</div>

<script>
$(function() {
  $('body').after($('.sticky-darkmode-toggle'));
})
</script>

<style>

.sticky-darkmode-toggle {
  position: fixed;
  right: 20px;
  bottom: 20px;
}
</style>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Comlete theory</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="abbreviations.html"><a href="abbreviations.html"><i class="fa fa-check"></i><b>1.1</b> Abbreviations</a></li>
<li class="chapter" data-level="1.2" data-path="to-do-reading.html"><a href="to-do-reading.html"><i class="fa fa-check"></i><b>1.2</b> To-do reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="basic-life-insurance-mathematics.html"><a href="basic-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>2</b> Basic Life Insurance Mathematics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="paymentstreams-interest-and-mortality.html"><a href="paymentstreams-interest-and-mortality.html"><i class="fa fa-check"></i><b>2.1</b> Paymentstreams, interest and mortality</a></li>
<li class="chapter" data-level="2.2" data-path="insurance-of-a-single-life.html"><a href="insurance-of-a-single-life.html"><i class="fa fa-check"></i><b>2.2</b> Insurance of a single life</a></li>
<li class="chapter" data-level="2.3" data-path="expenses.html"><a href="expenses.html"><i class="fa fa-check"></i><b>2.3</b> Expenses</a></li>
<li class="chapter" data-level="2.4" data-path="multi-life-insurances.html"><a href="multi-life-insurances.html"><i class="fa fa-check"></i><b>2.4</b> Multi-life insurances</a></li>
<li class="chapter" data-level="2.5" data-path="markov-chains-in-life-insurance.html"><a href="markov-chains-in-life-insurance.html"><i class="fa fa-check"></i><b>2.5</b> Markov chains in life insurance</a></li>
<li class="chapter" data-level="2.6" data-path="safety-loadings-and-bonus.html"><a href="safety-loadings-and-bonus.html"><i class="fa fa-check"></i><b>2.6</b> Safety loadings and bonus</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="stochastic-processes-in-life-insurance-mathematics.html"><a href="stochastic-processes-in-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>3</b> Stochastic Processes in Life Insurance Mathematics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="lebesgue-stieltjes-calculus.html"><a href="lebesgue-stieltjes-calculus.html"><i class="fa fa-check"></i><b>3.1</b> Lebesgue-Stieltjes calculus</a></li>
<li class="chapter" data-level="3.2" data-path="stochastic-processes.html"><a href="stochastic-processes.html"><i class="fa fa-check"></i><b>3.2</b> Stochastic processes</a></li>
<li class="chapter" data-level="3.3" data-path="life-insurance-models.html"><a href="life-insurance-models.html"><i class="fa fa-check"></i><b>3.3</b> Life insurance models</a></li>
<li class="chapter" data-level="3.4" data-path="introduction-to-survival-and-event-history-analysis.html"><a href="introduction-to-survival-and-event-history-analysis.html"><i class="fa fa-check"></i><b>3.4</b> Introduction to survival and event history analysis</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>4</b> Topics in Life Insurance Mathematics</a>
<ul>
<li class="chapter" data-level="4.1" data-path="markov-jump-processes.html"><a href="markov-jump-processes.html"><i class="fa fa-check"></i><b>4.1</b> Markov Jump Processes</a></li>
<li class="chapter" data-level="4.2" data-path="phase-type-distributions.html"><a href="phase-type-distributions.html"><i class="fa fa-check"></i><b>4.2</b> Phase-type distributions</a></li>
<li class="chapter" data-level="4.3" data-path="interest-rates.html"><a href="interest-rates.html"><i class="fa fa-check"></i><b>4.3</b> Interest rates</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="interest-rates.html"><a href="interest-rates.html#basic-definitions-and-properties"><i class="fa fa-check"></i><b>4.3.1</b> Basic definitions and properties</a></li>
<li class="chapter" data-level="4.3.2" data-path="interest-rates.html"><a href="interest-rates.html#phase-type-representation-of-bond-prices"><i class="fa fa-check"></i><b>4.3.2</b> Phase-type representation of bond prices</a></li>
<li class="chapter" data-level="4.3.3" data-path="interest-rates.html"><a href="interest-rates.html#term-structure-models"><i class="fa fa-check"></i><b>4.3.3</b> Term structure models</a></li>
<li class="chapter" data-level="4.3.4" data-path="interest-rates.html"><a href="interest-rates.html#estimation-of-ph-bond-models"><i class="fa fa-check"></i><b>4.3.4</b> Estimation of PH bond models</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="survival-and-mortality-rates.html"><a href="survival-and-mortality-rates.html"><i class="fa fa-check"></i><b>4.4</b> Survival and mortality rates</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="survival-and-mortality-rates.html"><a href="survival-and-mortality-rates.html#survival-probabilities-and-forward-mortality-rates"><i class="fa fa-check"></i><b>4.4.1</b> Survival probabilities and forward mortality rates</a></li>
<li class="chapter" data-level="4.4.2" data-path="survival-and-mortality-rates.html"><a href="survival-and-mortality-rates.html#forward-transistion-rates"><i class="fa fa-check"></i><b>4.4.2</b> Forward transistion rates</a></li>
<li class="chapter" data-level="4.4.3" data-path="survival-and-mortality-rates.html"><a href="survival-and-mortality-rates.html#reserves-revisited"><i class="fa fa-check"></i><b>4.4.3</b> Reserves revisited</a></li>
<li class="chapter" data-level="4.4.4" data-path="survival-and-mortality-rates.html"><a href="survival-and-mortality-rates.html#stochastic-mortality-rates"><i class="fa fa-check"></i><b>4.4.4</b> Stochastic mortality rates</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html"><i class="fa fa-check"></i><b>4.5</b> Matrix methods in life insurance</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html#basic-setup"><i class="fa fa-check"></i><b>4.5.1</b> Basic setup</a></li>
<li class="chapter" data-level="4.5.2" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html#interest-rate-free-analysis"><i class="fa fa-check"></i><b>4.5.2</b> Interest rate free analysis</a></li>
<li class="chapter" data-level="4.5.3" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html#transform-of-rewards-and-higher-order-moments"><i class="fa fa-check"></i><b>4.5.3</b> Transform of rewards and higher order moments</a></li>
<li class="chapter" data-level="4.5.4" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html#markovian-interest-rates"><i class="fa fa-check"></i><b>4.5.4</b> Markovian interest rates</a></li>
<li class="chapter" data-level="4.5.5" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html#reserves"><i class="fa fa-check"></i><b>4.5.5</b> Reserves</a></li>
<li class="chapter" data-level="4.5.6" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html#higher-order-moments"><i class="fa fa-check"></i><b>4.5.6</b> Higher order moments</a></li>
<li class="chapter" data-level="4.5.7" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html#equivalence-premium"><i class="fa fa-check"></i><b>4.5.7</b> Equivalence premium</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html"><i class="fa fa-check"></i><b>4.6</b> Financial Mathematics in Life Insurance</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#background-and-simple-claims"><i class="fa fa-check"></i><b>4.6.1</b> Background and Simple Claims</a></li>
<li class="chapter" data-level="4.6.2" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#payment-streams"><i class="fa fa-check"></i><b>4.6.2</b> Payment Streams</a></li>
<li class="chapter" data-level="4.6.3" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#unit-link-insurance"><i class="fa fa-check"></i><b>4.6.3</b> Unit-Link Insurance</a></li>
<li class="chapter" data-level="4.6.4" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#with-profit-insurance-and-the-dynamics-of-the-surplus"><i class="fa fa-check"></i><b>4.6.4</b> With-Profit Insurance and the Dynamics of the Surplus</a></li>
<li class="chapter" data-level="4.6.5" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#cash-dividends-and-market-reserve"><i class="fa fa-check"></i><b>4.6.5</b> Cash Dividends and Market Reserve</a></li>
<li class="chapter" data-level="4.6.6" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#the-pure-case-of-cash-dividends"><i class="fa fa-check"></i><b>4.6.6</b> The Pure Case of Cash Dividends</a></li>
<li class="chapter" data-level="4.6.7" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#bonus-payments-and-market-reserve"><i class="fa fa-check"></i><b>4.6.7</b> Bonus Payments and Market Reserve</a></li>
<li class="chapter" data-level="4.6.8" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#the-pure-case-of-bonus-payments"><i class="fa fa-check"></i><b>4.6.8</b> The Pure Case of Bonus Payments</a></li>
<li class="chapter" data-level="4.6.9" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#incidental-policy-holder-behavior"><i class="fa fa-check"></i><b>4.6.9</b> Incidental Policy Holder Behavior</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="projects-in-the-mathematics-of-life-insurance.html"><a href="projects-in-the-mathematics-of-life-insurance.html"><i class="fa fa-check"></i><b>5</b> Projects in the Mathematics of Life Insurance</a>
<ul>
<li class="chapter" data-level="5.1" data-path="cash-flows-markov-models-and-policyholder-behavior.html"><a href="cash-flows-markov-models-and-policyholder-behavior.html"><i class="fa fa-check"></i><b>5.1</b> Cash flows, Markov models, and policyholder behavior</a></li>
<li class="chapter" data-level="5.2" data-path="transaction-time-modeling.html"><a href="transaction-time-modeling.html"><i class="fa fa-check"></i><b>5.2</b> Transaction time modeling</a></li>
<li class="chapter" data-level="5.3" data-path="parametric-estimation-in-markov-models.html"><a href="parametric-estimation-in-markov-models.html"><i class="fa fa-check"></i><b>5.3</b> Parametric estimation in Markov models</a></li>
<li class="chapter" data-level="5.4" data-path="non-parametric-estimation-in-markov-models.html"><a href="non-parametric-estimation-in-markov-models.html"><i class="fa fa-check"></i><b>5.4</b> Non-parametric estimation in Markov models</a></li>
<li class="chapter" data-level="5.5" data-path="non-markov-modeling.html"><a href="non-markov-modeling.html"><i class="fa fa-check"></i><b>5.5</b> Non-Markov modeling</a></li>
<li class="chapter" data-level="5.6" data-path="outlook.html"><a href="outlook.html"><i class="fa fa-check"></i><b>5.6</b> Outlook</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html"><i class="fa fa-check"></i><b>6</b> Continuous Time Finance</a>
<ul>
<li class="chapter" data-level="6.1" data-path="discrete-time-models.html"><a href="discrete-time-models.html"><i class="fa fa-check"></i><b>6.1</b> Discrete time models</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="discrete-time-models.html"><a href="discrete-time-models.html#one-period-time-models"><i class="fa fa-check"></i><b>6.1.1</b> One-period time models</a></li>
<li class="chapter" data-level="6.1.2" data-path="discrete-time-models.html"><a href="discrete-time-models.html#multi-period-model"><i class="fa fa-check"></i><b>6.1.2</b> Multi-period model</a></li>
<li class="chapter" data-level="6.1.3" data-path="discrete-time-models.html"><a href="discrete-time-models.html#generelised-one-period-model"><i class="fa fa-check"></i><b>6.1.3</b> Generelised one-period model</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="self-financing-portfolios.html"><a href="self-financing-portfolios.html"><i class="fa fa-check"></i><b>6.2</b> Self-financing portfolios</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="self-financing-portfolios.html"><a href="self-financing-portfolios.html#discrete-time-sf-portfolio"><i class="fa fa-check"></i><b>6.2.1</b> Discrete time SF portfolio</a></li>
<li class="chapter" data-level="6.2.2" data-path="self-financing-portfolios.html"><a href="self-financing-portfolios.html#continuous-time-sf-portfolio"><i class="fa fa-check"></i><b>6.2.2</b> Continuous time SF portfolio</a></li>
<li class="chapter" data-level="6.2.3" data-path="self-financing-portfolios.html"><a href="self-financing-portfolios.html#portfolio-weights"><i class="fa fa-check"></i><b>6.2.3</b> Portfolio weights</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="black-scholes-pde.html"><a href="black-scholes-pde.html"><i class="fa fa-check"></i><b>6.3</b> Black-Scholes PDE</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="black-scholes-pde.html"><a href="black-scholes-pde.html#contingent-claims-and-arbitrage"><i class="fa fa-check"></i><b>6.3.1</b> Contingent Claims and Arbitrage</a></li>
<li class="chapter" data-level="6.3.2" data-path="black-scholes-pde.html"><a href="black-scholes-pde.html#risk-neutral-valuation-1"><i class="fa fa-check"></i><b>6.3.2</b> Risk Neutral Valuation</a></li>
<li class="chapter" data-level="6.3.3" data-path="black-scholes-pde.html"><a href="black-scholes-pde.html#black-scholes-formula"><i class="fa fa-check"></i><b>6.3.3</b> Black-Scholes formula</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="completeness-and-hedging.html"><a href="completeness-and-hedging.html"><i class="fa fa-check"></i><b>6.4</b> Completeness and Hedging</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="completeness-and-hedging.html"><a href="completeness-and-hedging.html#completeness-in-black-scholes"><i class="fa fa-check"></i><b>6.4.1</b> Completeness in Black-Scholes</a></li>
<li class="chapter" data-level="6.4.2" data-path="completeness-and-hedging.html"><a href="completeness-and-hedging.html#absence-of-arbitrage-1"><i class="fa fa-check"></i><b>6.4.2</b> Absence of Arbitrage</a></li>
<li class="chapter" data-level="6.4.3" data-path="completeness-and-hedging.html"><a href="completeness-and-hedging.html#incomplete-markets"><i class="fa fa-check"></i><b>6.4.3</b> Incomplete Markets</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="parity-relations.html"><a href="parity-relations.html"><i class="fa fa-check"></i><b>6.5</b> Parity relations</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="parity-relations.html"><a href="parity-relations.html#put-call-parity"><i class="fa fa-check"></i><b>6.5.1</b> Put-call Parity</a></li>
<li class="chapter" data-level="6.5.2" data-path="parity-relations.html"><a href="parity-relations.html#the-greeks"><i class="fa fa-check"></i><b>6.5.2</b> The Greeks</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="fundamental-pricing-theorem-i-and-ii.html"><a href="fundamental-pricing-theorem-i-and-ii.html"><i class="fa fa-check"></i><b>6.6</b> Fundamental pricing theorem I and II</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="fundamental-pricing-theorem-i-and-ii.html"><a href="fundamental-pricing-theorem-i-and-ii.html#completeness-1"><i class="fa fa-check"></i><b>6.6.1</b> Completeness</a></li>
<li class="chapter" data-level="6.6.2" data-path="fundamental-pricing-theorem-i-and-ii.html"><a href="fundamental-pricing-theorem-i-and-ii.html#risk-neutral-valuation-formula"><i class="fa fa-check"></i><b>6.6.2</b> Risk Neutral Valuation Formula</a></li>
<li class="chapter" data-level="6.6.3" data-path="fundamental-pricing-theorem-i-and-ii.html"><a href="fundamental-pricing-theorem-i-and-ii.html#stochastic-discount-factors-1"><i class="fa fa-check"></i><b>6.6.3</b> Stochastic Discount Factors</a></li>
<li class="chapter" data-level="6.6.4" data-path="fundamental-pricing-theorem-i-and-ii.html"><a href="fundamental-pricing-theorem-i-and-ii.html#summary"><i class="fa fa-check"></i><b>6.6.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="mathematics-of-the-martingale-approach.html"><a href="mathematics-of-the-martingale-approach.html"><i class="fa fa-check"></i><b>6.7</b> Mathematics of the martingale approach</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="mathematics-of-the-martingale-approach.html"><a href="mathematics-of-the-martingale-approach.html#martingale-representation-theorem"><i class="fa fa-check"></i><b>6.7.1</b> Martingale representation theorem</a></li>
<li class="chapter" data-level="6.7.2" data-path="mathematics-of-the-martingale-approach.html"><a href="mathematics-of-the-martingale-approach.html#girsanov-theorem"><i class="fa fa-check"></i><b>6.7.2</b> Girsanov theorem</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="black-scholes-model---martingale-approach.html"><a href="black-scholes-model---martingale-approach.html"><i class="fa fa-check"></i><b>6.8</b> Black-Scholes model - martingale approach</a></li>
<li class="chapter" data-level="6.9" data-path="multidimensional-models.html"><a href="multidimensional-models.html"><i class="fa fa-check"></i><b>6.9</b> Multidimensional models</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="basic-non-life-insurance-mathematics.html"><a href="basic-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>7</b> Basic Non-Life Insurance Mathematics</a>
<ul>
<li class="chapter" data-level="7.1" data-path="the-basic-model.html"><a href="the-basic-model.html"><i class="fa fa-check"></i><b>7.1</b> The Basic Model</a></li>
<li class="chapter" data-level="7.2" data-path="models-for-the-claim-number-process.html"><a href="models-for-the-claim-number-process.html"><i class="fa fa-check"></i><b>7.2</b> Models for the Claim Number Process</a></li>
<li class="chapter" data-level="7.3" data-path="the-total-claim-amount.html"><a href="the-total-claim-amount.html"><i class="fa fa-check"></i><b>7.3</b> The Total Claim Amount</a></li>
<li class="chapter" data-level="7.4" data-path="ruin-theory.html"><a href="ruin-theory.html"><i class="fa fa-check"></i><b>7.4</b> Ruin Theory</a></li>
<li class="chapter" data-level="7.5" data-path="bayes-estimation.html"><a href="bayes-estimation.html"><i class="fa fa-check"></i><b>7.5</b> Bayes Estimation</a></li>
<li class="chapter" data-level="7.6" data-path="linear-bayes-estimation.html"><a href="linear-bayes-estimation.html"><i class="fa fa-check"></i><b>7.6</b> Linear Bayes Estimation</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="stochastic-processes-in-non-life-insurance-mathematics.html"><a href="stochastic-processes-in-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>8</b> Stochastic Processes in Non-Life Insurance Mathematics</a>
<ul>
<li class="chapter" data-level="8.1" data-path="preliminaries.html"><a href="preliminaries.html"><i class="fa fa-check"></i><b>8.1</b> Preliminaries</a></li>
<li class="chapter" data-level="8.2" data-path="the-cramer-lundberg-model.html"><a href="the-cramer-lundberg-model.html"><i class="fa fa-check"></i><b>8.2</b> The Cramer-Lundberg model</a></li>
<li class="chapter" data-level="8.3" data-path="the-renewal-risk-model.html"><a href="the-renewal-risk-model.html"><i class="fa fa-check"></i><b>8.3</b> The renewal risk model</a></li>
<li class="chapter" data-level="8.4" data-path="modern-ruin-theory.html"><a href="modern-ruin-theory.html"><i class="fa fa-check"></i><b>8.4</b> Modern ruin theory</a></li>
<li class="chapter" data-level="8.5" data-path="claims-reserving.html"><a href="claims-reserving.html"><i class="fa fa-check"></i><b>8.5</b> Claims reserving</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="topics-in-non-life-insurance-mathematics.html"><a href="topics-in-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>9</b> Topics in Non-Life Insurance Mathematics</a></li>
<li class="chapter" data-level="10" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html"><i class="fa fa-check"></i><b>10</b> Probabilistic Machine Learning</a>
<ul>
<li class="chapter" data-level="10.1" data-path="supervised-learning.html"><a href="supervised-learning.html"><i class="fa fa-check"></i><b>10.1</b> Supervised Learning</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="supervised-learning.html"><a href="supervised-learning.html#what-is-a-good-estimator"><i class="fa fa-check"></i><b>10.1.1</b> What is a good estimator?</a></li>
<li class="chapter" data-level="10.1.2" data-path="supervised-learning.html"><a href="supervised-learning.html#excess-risk"><i class="fa fa-check"></i><b>10.1.2</b> Excess risk</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="training-validating-and-testing.html"><a href="training-validating-and-testing.html"><i class="fa fa-check"></i><b>10.2</b> Training, Validating and Testing</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="training-validating-and-testing.html"><a href="training-validating-and-testing.html#estimating-risk"><i class="fa fa-check"></i><b>10.2.1</b> Estimating risk</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>10.3</b> Linear Models</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="linear-models.html"><a href="linear-models.html#least-squares-estimator"><i class="fa fa-check"></i><b>10.3.1</b> Least Squares Estimator</a></li>
<li class="chapter" data-level="10.3.2" data-path="linear-models.html"><a href="linear-models.html#ridge-regression"><i class="fa fa-check"></i><b>10.3.2</b> Ridge Regression</a></li>
<li class="chapter" data-level="10.3.3" data-path="linear-models.html"><a href="linear-models.html#lasso-regression"><i class="fa fa-check"></i><b>10.3.3</b> Lasso Regression</a></li>
<li class="chapter" data-level="10.3.4" data-path="linear-models.html"><a href="linear-models.html#conclusion"><i class="fa fa-check"></i><b>10.3.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html"><i class="fa fa-check"></i><b>10.4</b> Nonparametric Regression</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html#linear-smoothers"><i class="fa fa-check"></i><b>10.4.1</b> Linear Smoothers</a></li>
<li class="chapter" data-level="10.4.2" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html#curse-of-dimensionality"><i class="fa fa-check"></i><b>10.4.2</b> Curse of dimensionality</a></li>
<li class="chapter" data-level="10.4.3" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html#splines"><i class="fa fa-check"></i><b>10.4.3</b> Splines</a></li>
<li class="chapter" data-level="10.4.4" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html#linear-regression-with-splines."><i class="fa fa-check"></i><b>10.4.4</b> Linear regression with splines.</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="trees-and-forests.html"><a href="trees-and-forests.html"><i class="fa fa-check"></i><b>10.5</b> Trees and forests</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="trees-and-forests.html"><a href="trees-and-forests.html#cart"><i class="fa fa-check"></i><b>10.5.1</b> CART</a></li>
<li class="chapter" data-level="10.5.2" data-path="trees-and-forests.html"><a href="trees-and-forests.html#pruning"><i class="fa fa-check"></i><b>10.5.2</b> Pruning</a></li>
<li class="chapter" data-level="10.5.3" data-path="trees-and-forests.html"><a href="trees-and-forests.html#bagging"><i class="fa fa-check"></i><b>10.5.3</b> Bagging</a></li>
<li class="chapter" data-level="10.5.4" data-path="trees-and-forests.html"><a href="trees-and-forests.html#random-forests"><i class="fa fa-check"></i><b>10.5.4</b> Random Forests</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="boosting-and-additive-trees.html"><a href="boosting-and-additive-trees.html"><i class="fa fa-check"></i><b>10.6</b> Boosting and additive trees</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="boosting-and-additive-trees.html"><a href="boosting-and-additive-trees.html#gradient-boosting-machines"><i class="fa fa-check"></i><b>10.6.1</b> Gradient Boosting Machines</a></li>
<li class="chapter" data-level="10.6.2" data-path="boosting-and-additive-trees.html"><a href="boosting-and-additive-trees.html#bayesian-additive-regression-trees"><i class="fa fa-check"></i><b>10.6.2</b> Bayesian additive regression trees</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="some-practical-considerations.html"><a href="some-practical-considerations.html"><i class="fa fa-check"></i><b>10.7</b> Some practical considerations</a></li>
<li class="chapter" data-level="10.8" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>10.8</b> Neural Networks</a></li>
<li class="chapter" data-level="10.9" data-path="local-explanations.html"><a href="local-explanations.html"><i class="fa fa-check"></i><b>10.9</b> Local explanations</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="local-explanations.html"><a href="local-explanations.html#interpretability"><i class="fa fa-check"></i><b>10.9.1</b> Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="causality.html"><a href="causality.html"><i class="fa fa-check"></i><b>10.10</b> Causality</a></li>
<li class="chapter" data-level="10.11" data-path="local-and-global-explanations.html"><a href="local-and-global-explanations.html"><i class="fa fa-check"></i><b>10.11</b> Local and Global Explanations</a>
<ul>
<li class="chapter" data-level="10.11.1" data-path="local-and-global-explanations.html"><a href="local-and-global-explanations.html#interpretability-1"><i class="fa fa-check"></i><b>10.11.1</b> Interpretability</a></li>
<li class="chapter" data-level="10.11.2" data-path="local-and-global-explanations.html"><a href="local-and-global-explanations.html#partial-dependence-plots"><i class="fa fa-check"></i><b>10.11.2</b> Partial dependence plots</a></li>
<li class="chapter" data-level="10.11.3" data-path="local-and-global-explanations.html"><a href="local-and-global-explanations.html#a-functional-decomposition"><i class="fa fa-check"></i><b>10.11.3</b> A functional decomposition</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="quantative-risk-management.html"><a href="quantative-risk-management.html"><i class="fa fa-check"></i><b>11</b> Quantative Risk Management</a>
<ul>
<li class="chapter" data-level="11.1" data-path="the-loss-variable.html"><a href="the-loss-variable.html"><i class="fa fa-check"></i><b>11.1</b> The Loss Variable</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="the-loss-variable.html"><a href="the-loss-variable.html#risk-measures"><i class="fa fa-check"></i><b>11.1.1</b> Risk measures</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="extreme-value-theory.html"><a href="extreme-value-theory.html"><i class="fa fa-check"></i><b>11.2</b> Extreme value theory</a></li>
<li class="chapter" data-level="11.3" data-path="elliptical-distributions-and-copulas.html"><a href="elliptical-distributions-and-copulas.html"><i class="fa fa-check"></i><b>11.3</b> Elliptical distributions and copulas</a></li>
<li class="chapter" data-level="11.4" data-path="credit-risk-modelling.html"><a href="credit-risk-modelling.html"><i class="fa fa-check"></i><b>11.4</b> Credit risk modelling</a></li>
<li class="chapter" data-level="11.5" data-path="models-for-operational-risk.html"><a href="models-for-operational-risk.html"><i class="fa fa-check"></i><b>11.5</b> Models for operational risk</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="measure-theory.html"><a href="measure-theory.html"><i class="fa fa-check"></i><b>A</b> Measure theory</a>
<ul>
<li class="chapter" data-level="A.1" data-path="axioms-of-probability.html"><a href="axioms-of-probability.html"><i class="fa fa-check"></i><b>A.1</b> Axioms of Probability</a></li>
<li class="chapter" data-level="A.2" data-path="conditional-probability-and-independence.html"><a href="conditional-probability-and-independence.html"><i class="fa fa-check"></i><b>A.2</b> Conditional Probability and Independence</a></li>
<li class="chapter" data-level="A.3" data-path="probabilities-on-a-finite-or-countable-space.html"><a href="probabilities-on-a-finite-or-countable-space.html"><i class="fa fa-check"></i><b>A.3</b> Probabilities on a Finite or Countable Space</a></li>
<li class="chapter" data-level="A.4" data-path="construction-of-a-probability-measure-on-mathbb-r.html"><a href="construction-of-a-probability-measure-on-mathbb-r.html"><i class="fa fa-check"></i><b>A.4</b> Construction of a Probability Measure on <span class="math inline">\(\mathbb R\)</span></a></li>
<li class="chapter" data-level="A.5" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>A.5</b> Random Variables</a></li>
<li class="chapter" data-level="A.6" data-path="integration-with-respect-to-a-probability-measure.html"><a href="integration-with-respect-to-a-probability-measure.html"><i class="fa fa-check"></i><b>A.6</b> Integration with Respect to a Probability Measure</a></li>
<li class="chapter" data-level="A.7" data-path="independent-random-variables.html"><a href="independent-random-variables.html"><i class="fa fa-check"></i><b>A.7</b> Independent Random Variables</a></li>
<li class="chapter" data-level="A.8" data-path="probability-distributions-on-mathbb-r.html"><a href="probability-distributions-on-mathbb-r.html"><i class="fa fa-check"></i><b>A.8</b> Probability Distributions on <span class="math inline">\(\mathbb R\)</span></a></li>
<li class="chapter" data-level="A.9" data-path="probability-distributions-on-mathbb-rn.html"><a href="probability-distributions-on-mathbb-rn.html"><i class="fa fa-check"></i><b>A.9</b> Probability Distributions on <span class="math inline">\(\mathbb R^n\)</span></a></li>
<li class="chapter" data-level="A.10" data-path="equivalent-probability-measures.html"><a href="equivalent-probability-measures.html"><i class="fa fa-check"></i><b>A.10</b> Equivalent Probability Measures</a>
<ul>
<li class="chapter" data-level="A.10.1" data-path="equivalent-probability-measures.html"><a href="equivalent-probability-measures.html#the-radon-nikodym-theorem"><i class="fa fa-check"></i><b>A.10.1</b> The Radon-Nikodym Theorem</a></li>
<li class="chapter" data-level="A.10.2" data-path="equivalent-probability-measures.html"><a href="equivalent-probability-measures.html#equivalent-probability-measures-1"><i class="fa fa-check"></i><b>A.10.2</b> Equivalent Probability Measures</a></li>
<li class="chapter" data-level="A.10.3" data-path="equivalent-probability-measures.html"><a href="equivalent-probability-measures.html#likelihood-processes"><i class="fa fa-check"></i><b>A.10.3</b> Likelihood processes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="random-variables-1.html"><a href="random-variables-1.html"><i class="fa fa-check"></i><b>B</b> Random Variables</a>
<ul>
<li class="chapter" data-level="B.1" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>B.1</b> Introduction</a></li>
<li class="chapter" data-level="B.2" data-path="conditional-expectation.html"><a href="conditional-expectation.html"><i class="fa fa-check"></i><b>B.2</b> Conditional expectation</a></li>
<li class="chapter" data-level="B.3" data-path="independence.html"><a href="independence.html"><i class="fa fa-check"></i><b>B.3</b> Independence</a></li>
<li class="chapter" data-level="B.4" data-path="moment-generating-function.html"><a href="moment-generating-function.html"><i class="fa fa-check"></i><b>B.4</b> Moment generating function</a></li>
<li class="chapter" data-level="B.5" data-path="standard-distributions.html"><a href="standard-distributions.html"><i class="fa fa-check"></i><b>B.5</b> Standard distributions</a>
<ul>
<li class="chapter" data-level="B.5.1" data-path="standard-distributions.html"><a href="standard-distributions.html#normal-disribution"><i class="fa fa-check"></i><b>B.5.1</b> Normal disribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html"><i class="fa fa-check"></i><b>C</b> Discrete Time Stochastic Processes</a>
<ul>
<li class="chapter" data-level="C.1" data-path="convergence-concepts.html"><a href="convergence-concepts.html"><i class="fa fa-check"></i><b>C.1</b> Convergence concepts</a>
<ul>
<li class="chapter" data-level="C.1.1" data-path="convergence-concepts.html"><a href="convergence-concepts.html#sums-and-average-processes"><i class="fa fa-check"></i><b>C.1.1</b> Sums and average processes</a></li>
<li class="chapter" data-level="C.1.2" data-path="convergence-concepts.html"><a href="convergence-concepts.html#ergodic-theory"><i class="fa fa-check"></i><b>C.1.2</b> Ergodic Theory</a></li>
<li class="chapter" data-level="C.1.3" data-path="convergence-concepts.html"><a href="convergence-concepts.html#weak-convergence"><i class="fa fa-check"></i><b>C.1.3</b> Weak Convergence</a></li>
<li class="chapter" data-level="C.1.4" data-path="convergence-concepts.html"><a href="convergence-concepts.html#central-limit-theorems"><i class="fa fa-check"></i><b>C.1.4</b> Central Limit Theorems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="markov-chains.html"><a href="markov-chains.html"><i class="fa fa-check"></i><b>D</b> Markov Chains</a>
<ul>
<li class="chapter" data-level="D.1" data-path="definition-of-a-markov-chain.html"><a href="definition-of-a-markov-chain.html"><i class="fa fa-check"></i><b>D.1</b> Definition of a Markov Chain</a></li>
<li class="chapter" data-level="D.2" data-path="classification-of-states.html"><a href="classification-of-states.html"><i class="fa fa-check"></i><b>D.2</b> Classification of states</a></li>
<li class="chapter" data-level="D.3" data-path="limit-results-and-invariant-probabilities.html"><a href="limit-results-and-invariant-probabilities.html"><i class="fa fa-check"></i><b>D.3</b> Limit results and invariant probabilities</a></li>
<li class="chapter" data-level="D.4" data-path="absorbing-probabilities.html"><a href="absorbing-probabilities.html"><i class="fa fa-check"></i><b>D.4</b> Absorbing probabilities</a></li>
<li class="chapter" data-level="D.5" data-path="markov-chains-in-continuous-times.html"><a href="markov-chains-in-continuous-times.html"><i class="fa fa-check"></i><b>D.5</b> Markov Chains in Continuous Times</a></li>
<li class="chapter" data-level="D.6" data-path="properties-of-transitionsprobabilities.html"><a href="properties-of-transitionsprobabilities.html"><i class="fa fa-check"></i><b>D.6</b> Properties of transitionsprobabilities</a></li>
<li class="chapter" data-level="D.7" data-path="invariant-probabilies-and-absorption.html"><a href="invariant-probabilies-and-absorption.html"><i class="fa fa-check"></i><b>D.7</b> Invariant probabilies and absorption</a></li>
<li class="chapter" data-level="D.8" data-path="birth-death-processes.html"><a href="birth-death-processes.html"><i class="fa fa-check"></i><b>D.8</b> Birth-death processes</a></li>
</ul></li>
<li class="chapter" data-level="E" data-path="continuous-time-stochastic-processes.html"><a href="continuous-time-stochastic-processes.html"><i class="fa fa-check"></i><b>E</b> Continuous Time Stochastic Processes</a>
<ul>
<li class="chapter" data-level="E.1" data-path="brownian-motion.html"><a href="brownian-motion.html"><i class="fa fa-check"></i><b>E.1</b> Brownian Motion</a></li>
<li class="chapter" data-level="E.2" data-path="filtration.html"><a href="filtration.html"><i class="fa fa-check"></i><b>E.2</b> Filtration</a></li>
<li class="chapter" data-level="E.3" data-path="martingale.html"><a href="martingale.html"><i class="fa fa-check"></i><b>E.3</b> Martingale</a></li>
</ul></li>
<li class="chapter" data-level="F" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html"><i class="fa fa-check"></i><b>F</b> Stochastic calculus</a>
<ul>
<li class="chapter" data-level="F.1" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html"><i class="fa fa-check"></i><b>F.1</b> Stochastic Integrals</a>
<ul>
<li class="chapter" data-level="F.1.1" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html#information"><i class="fa fa-check"></i><b>F.1.1</b> Information</a></li>
<li class="chapter" data-level="F.1.2" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html#stochastic-integrals-1"><i class="fa fa-check"></i><b>F.1.2</b> Stochastic Integrals</a></li>
<li class="chapter" data-level="F.1.3" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html#martingales"><i class="fa fa-check"></i><b>F.1.3</b> Martingales</a></li>
<li class="chapter" data-level="F.1.4" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html#stochastic-calculus-and-the-ito-formula"><i class="fa fa-check"></i><b>F.1.4</b> Stochastic Calculus and the Ito Formula</a></li>
<li class="chapter" data-level="F.1.5" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html#the-multidimensional-ito-formula"><i class="fa fa-check"></i><b>F.1.5</b> The multidimensional Ito Formula</a></li>
<li class="chapter" data-level="F.1.6" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html#the-multidimensional-ito-formula-with-states"><i class="fa fa-check"></i><b>F.1.6</b> The multidimensional Ito Formula with states</a></li>
<li class="chapter" data-level="F.1.7" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html#correlated-brownian-motions"><i class="fa fa-check"></i><b>F.1.7</b> Correlated Brownian motions</a></li>
</ul></li>
<li class="chapter" data-level="F.2" data-path="discrete-stochastic-integrals.html"><a href="discrete-stochastic-integrals.html"><i class="fa fa-check"></i><b>F.2</b> Discrete Stochastic Integrals</a></li>
<li class="chapter" data-level="F.3" data-path="stochastic-differential-equations.html"><a href="stochastic-differential-equations.html"><i class="fa fa-check"></i><b>F.3</b> Stochastic Differential Equations</a></li>
<li class="chapter" data-level="F.4" data-path="partial-differential-equations.html"><a href="partial-differential-equations.html"><i class="fa fa-check"></i><b>F.4</b> Partial differential equations</a></li>
<li class="chapter" data-level="F.5" data-path="the-product-integral.html"><a href="the-product-integral.html"><i class="fa fa-check"></i><b>F.5</b> The Product Integral</a>
<ul>
<li class="chapter" data-level="F.5.1" data-path="the-product-integral.html"><a href="the-product-integral.html#properties-of-the-product-integral"><i class="fa fa-check"></i><b>F.5.1</b> Properties of the Product Integral</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="G" data-path="linear-algebra.html"><a href="linear-algebra.html"><i class="fa fa-check"></i><b>G</b> Linear Algebra</a>
<ul>
<li class="chapter" data-level="G.1" data-path="invertible-matrices.html"><a href="invertible-matrices.html"><i class="fa fa-check"></i><b>G.1</b> Invertible matrices</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://joakim-bilyk.github.io/index.html">Back to main site</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mathematics of the Actuarial Sciences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="supervised-learning" class="section level2 hasAnchor" number="10.1">
<h2><span class="header-section-number">10.1</span> Supervised Learning<a href="supervised-learning.html#supervised-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter we restrict our selves to the area of <em>Supervised Learning</em> as we use numerical methods and machine learning algorithms to estimate models in a restricted framework. Take for instance the random forest, this algorithm’s estimation method is perfectly capable of being written recursively and so no “leaning” is done in the sense, that the calculations are predetermined from the algorithm. We therefore call the area of study supervised learning instead of the wider area of study <em>machine learning</em>. Let us define what we mean by supervised learning.</p>
<blockquote class="def">
<p><strong>Definition. (Supervised Learning)</strong> <em>Supervised learning is a field in machine learning that works with labeled data, i.e. data consisting of a set of features <span class="math inline">\(X\)</span>, and a response <span class="math inline">\(Y\)</span>. The goal is to learn a function <span class="math inline">\(m^*\)</span> that maps a given input <span class="math inline">\(x\)</span> to an output <span class="math inline">\(y\)</span>.</em></p>
</blockquote>
<p>We will in this chapter only use data in the form of a spread sheet e.g.</p>
<p><span class="math display">\[
\mathcal{D}_n=
\left(X_i, Y_i \right)_{i=1,...,n}=
\left[
\begin{array}{cccc|c}
X_{11} &amp; X_{12} &amp; \cdots &amp; X_{1p} &amp; Y_1\\
X_{21} &amp; X_{22} &amp; \cdots &amp; X_{2p} &amp; Y_2\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots\\
X_{n1} &amp; X_{n2} &amp; \cdots &amp; X_{np} &amp; Y_n
\end{array}
\right],
\]</span></p>
<p>we could however consider any data that may be interpreted by computer software.</p>
<p>The setting is then; assume that we have <span class="math inline">\(n\)</span> independent copies of the random variable <span class="math inline">\(D=(X,Y)\in \mathcal{X}\times \mathcal{Y}\)</span>, where <span class="math inline">\(X\)</span> is <span class="math inline">\(p\)</span>-dimensional and <span class="math inline">\(Y\)</span> is one-dimensional. We make no assumption on whether <span class="math inline">\(X_j\)</span>, <span class="math inline">\(j=1,..,p\)</span> and <span class="math inline">\(Y\)</span> are discrete or continuous, however in concrete cases this will be specified. We combine the sample of the <span class="math inline">\(n\)</span> observations in the matrix <span class="math inline">\(\mathcal{D}_n=(X_i,Y_i)_{i=1,...,n}\)</span> being a <span class="math inline">\(n\times p+1\)</span> matrix as in the above. We call <span class="math inline">\(\mathcal{D}_n\)</span> the <strong>training data</strong>.</p>
<p>This specification does indeed imply that <span class="math inline">\(D_i=(X_i,Y_i)\)</span> are iid. This is actually a bit controversial as we would expect that the distribution of <span class="math inline">\(D\)</span> will shift over time. For instance, the distribution of ages in a population changes over time and have been more right skewed as humanity advances. This may be accounted for by transforming the data such that the distribution becomes the same. This may be done in a variety of ways some example include: 1) transforming to uniform variable with the time dependent distribution <span class="math inline">\(F_t\)</span>, 2) normalizing using a price index and so forth. One should therefore start any analysis by ensuring that the data a given algorithm is trained on is iid.</p>
<p>The job becomes finding a good estimator such that we may predict <span class="math inline">\(Y\)</span> given <span class="math inline">\(X\)</span> i.e. <span class="math inline">\(Y\ \vert\ X\)</span>. Let us define what an estimator is.</p>
<blockquote class="def">
<p><strong>Definition. (Estimator)</strong> <em>Consider a training dataset <span class="math inline">\(\mathcal{D}_n\)</span>. A estimator <span class="math inline">\(m\)</span> is a function-valued mapping that takes <span class="math inline">\(\mathcal{D}_n\)</span> as input and associates a function <span class="math inline">\(m_n : \mathcal{X}\to \mathcal{Y}\)</span> i.e. <span class="math inline">\(m\)</span> takes the form</em></p>
<p><span class="math display">\[
m(\mathcal{D}_n)=m_n:\mathcal{X}\to \mathcal{Y}
\]</span></p>
<p><em>the class of estimators is called <span class="math inline">\(\mathcal{G}\)</span>.</em></p>
</blockquote>
<div id="what-is-a-good-estimator" class="section level3 hasAnchor" number="10.1.1">
<h3><span class="header-section-number">10.1.1</span> What is a good estimator?<a href="supervised-learning.html#what-is-a-good-estimator" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>It is easy to construct an estimator <span class="math inline">\(\hat{m}\)</span> for instance by maximum likelihood esitmation, bayes optimization or simply by taking conditional expectations. We are however interested in two problems:</p>
<ol style="list-style-type: decimal">
<li>What is the best class of estimators <span class="math inline">\(\mathcal{G}_0\subset\mathcal{G}\)</span>,</li>
<li>In the subset of estimators <span class="math inline">\(m \in \mathcal{G}_0\)</span>, what is then the best estimator.</li>
</ol>
<p>We will now discuss the meaning of being the <em>“best”</em> estimator. Obviously, the first type of consideration is regarding the inherent restrictions of some algorithm, where the second is the problem of error comming from the restriction that we do not have infinite observations. We therefore have two problems namely the <strong>inductive bias</strong> from the class <span class="math inline">\(\mathcal{G}_0\)</span> and the <strong>estimation error</strong> from the available data. A typical problem is that the larger a class <span class="math inline">\(\mathcal{G}_0\)</span> gives low inductive bias we then may not be able to estimate anything and so the estimation error will be large. The converse also applies.</p>
<blockquote class="def">
<p><strong>Definition.</strong> <em>Let <span class="math inline">\(D=(X,Y)\)</span> be a random variable on the background space <span class="math inline">\((\Omega, \mathcal{F},P)\)</span>. Then we define the following:</em></p>
<ul>
<li><em>A <strong>decision rule</strong> is a deterministic function <span class="math inline">\(m:\mathcal{X}\to \mathcal{Y}\)</span>,</em></li>
<li><em>A <strong>loss function</strong> is a deterministic function <span class="math inline">\(L: \mathcal{Y}\times \mathcal{Y}\to \mathbb{R}_+\)</span>,</em></li>
<li><em>The <strong>risk</strong> of a decision rule <span class="math inline">\(m\)</span> is given a loss function <span class="math inline">\(L\)</span> is <span class="math inline">\(r(m)=E[L(Y,m(X))]\)</span>.</em></li>
</ul>
</blockquote>
<p>Notice that in the definition of risk we see that <span class="math inline">\(m\)</span> is included inside the expectation. This means in particular that the training data <span class="math inline">\(\mathcal{D}_n\)</span> is also accounted for i.e. by the tower rule we have</p>
<p><span class="math display">\[
r(m)=\mathbb{E}[L(Y,m(X))]=\mathbb{E}\left[\mathbb{E}\Big[L(Y,m_n(X))\ \Big\vert\ \mathcal{D}_n\Big]\right]:=\mathbb{E}\left[R(m)\right].
\]</span></p>
<p>Some widely used loss function include</p>
<ul>
<li>Quadratic loss function: <span class="math inline">\(L(y_1,y_2)=(y_1-y_2)^2\)</span>,</li>
<li>Poisson Deviance: <span class="math inline">\(L(y_1,y_2)=2\left(y_1\log\frac{y_1}{y_2}-y_1+y_2\right)\)</span>,</li>
<li>Binary loss function: <span class="math inline">\(L(y_1,y_2)=1_{y_1\ne y_2}\)</span>.</li>
</ul>
<p>Given a loss function <span class="math inline">\(L\)</span> we may find a (possibly non-unique) solution <span class="math inline">\(m^*\)</span> that minimizes <span class="math inline">\(R(m)\)</span>. We call this the <strong>Bayes estimator</strong>. The quantity <span class="math inline">\(R(m^*)\)</span> is called the <strong>Bayes risk</strong>. On some special case loss functions we may determine the unique solution.</p>
<blockquote class="lem">
<p><strong>Lemma.</strong> <em>Assume <span class="math inline">\(Y\)</span> is <span class="math inline">\(L_2\)</span> (square integrable), then the decision function that minimized the risk for the quadratic loss function is</em></p>
<p><span class="math display">\[
m^*=\underset{m}{\text{argmin}}\ \mathbb{E}[(Y-m(X))^2]=E[Y\ \vert\ X=x]
\]</span>
i.e. the conditional expectation.</p>
</blockquote>
<details>
<summary>
<strong>Proof.</strong>
</summary>
<p>Consider the loss function <span class="math inline">\(L(y_1,y_2)=(y_1-y_2)^2\)</span> i.e. the <span class="math inline">\(L^2\)</span> loss function. For any estimator <span class="math inline">\(m(X)\in \mathcal G\)</span> we have
<span class="math display">\[\begin{align*}
R(m(X))&amp;=\mathbb E[L(m(X),Y)\ \vert\ X]=\mathbb E[(m(X)-Y)^2\ \vert\ X]\\
&amp;=\mathbb E[m(X)^2\ \vert\ X]+\mathbb E[Y^2\ \vert\ X]-2\mathbb E[m(X)Y\ \vert\ X]\\
&amp;=m(X)^2+\mathbb E[Y^2\ \vert\ X]-2m(X)\mathbb E[Y\ \vert\ X]
\end{align*}\]</span>
We see that the risk is minimized for the <span class="math inline">\(m\)</span> that minimizes <span class="math inline">\(m(X)^2-2m(X)\mathbb E[Y\ \vert\ X]\)</span>. The first order condition is then</p>
<p><span class="math display">\[
\frac{\partial}{\partial m}R(m(X))=2m(X)-2\mathbb E[Y\ \vert\ X]=0
\]</span></p>
<p>hence giving that</p>
<p><span class="math display">\[
m(X)=\mathbb E[Y\ \vert\ X]
\]</span></p>
<p>as desired. <span class="math inline">\(\blacksquare\)</span></p>
</details>
<p><strong>Remarks on the <span class="math inline">\(L^2\)</span>-loss.</strong> The loss function <span class="math inline">\(L(y_1,y_2)=(y_1-y_2)^2\)</span> i.e. the <span class="math inline">\(L^2\)</span> loss function gives some nice interpretations. We know that <span class="math inline">\(L\)</span> as a norm on <span class="math inline">\(\mathbb R\)</span> forms a Hilbert Space. This means, for instance, that we have some nice geometric interpretations, but more importantly we have alot of tools from linear algebra. We know that the projection <span class="math inline">\(m^*\)</span> onto the space <span class="math inline">\(\mathcal G\)</span> and so any vector <span class="math inline">\(\hat m(X)-m^*(X)\)</span> is orthogonal to <span class="math inline">\(Y-m^*(X)\)</span>. In particular, this gives that
<span class="math display">\[\begin{align*}
r(\hat m(X))&amp;=\mathbb E[L(\hat m(X),Y)]=\mathbb E\left[(\hat m(X)-Y)^2\right]\\
&amp;=\mathbb E\left[(\hat m(X)-m^*(X)+m^*(X)-Y)^2\right]\\
&amp;\stackrel{(\dagger)}{=}\mathbb E\left[(\hat m(X)-m^*(X))^2\right]+\mathbb E\left[(m^*(X)-Y)^2\right]\\
&amp;=\mathbb E\left[(\hat m(X)-m^*(X))^2\right]+r(m^*(X))
\end{align*}\]</span>
Using in <span class="math inline">\((\dagger)\)</span> that <span class="math inline">\(\hat m(X)-m^*(X)\)</span> and <span class="math inline">\(m^*(X)-Y\)</span> are orthogonal with the last equation simply being the definition of risk. Rearranging the above gives</p>
<p><span class="math display">\[
r(\hat m(X))-r(m^*(X))=\mathbb E\left[(\hat m(X)-m^*(X))^2\right]=\text{MSE}(\hat m(x))
\]</span></p>
<p>We can further write out the Mean Squared Error in terms of variance and bias.
<span class="math display">\[\begin{align*}
\text{MSE}(\hat m(x))&amp;=\mathbb E\left[(\hat m(X)-m^*(X))^2\right]\\
&amp;=\mathbb E\left[(\hat m(X)-\mathbb E[\hat m(X)\vert X])^2\right]+\mathbb E\left[(\mathbb E[\hat m(X)\vert X]-m^*(X))^2\right]\\
&amp;=\text{Var}(\hat m(X))+\text{Bias}^2(\hat m(X)).
\end{align*}\]</span></p>
<blockquote class="lem">
<p><strong>Lemma.</strong> <em>Assume <span class="math inline">\(\mathcal{Y}=\{1,...,K\}\)</span>, the decision function that minimizes the risk for the binary loss function satisfies</em></p>
<p><span class="math display">\[
m^*=\underset{m}{\text{argmin}}\ \mathbb{E}[1_{Y\ne m(X)}]=\underset{m}{\text{argmin}}\  \mathbb{P}(Y\ne m(X))=\underset{k=1,..,K}{\text{argmax}}\ \mathbb{P}(Y=k\ \vert\ X=x).
\]</span></p>
</blockquote>
<p>We can now define the prediction risk and the generalization error which relates to the balance of a sufficiently large class <span class="math inline">\(\mathcal{G}_0\)</span> and how effective the optimal estimator is conditional on the class <span class="math inline">\(\mathcal{G}_0\)</span>.</p>
<blockquote class="def">
<p><strong>Definition. (Conditional risk)</strong> <em>Let <span class="math inline">\(\mathcal{D}_n\)</span> be some training data. Given an estimator <span class="math inline">\(\hat{m}_n\)</span> we call</em></p>
<p><span class="math display">\[
R(\hat{m}_n)=\mathbb{E}[L(Y,\hat{m}_n(X))\ \vert\ \mathcal{D}_n]
\]</span></p>
<p><em>the prediction risk or conditional generalized error.</em></p>
</blockquote>
<blockquote class="def">
<p><strong>Definition. (Risk)</strong> <em>We call</em></p>
<p><span class="math display">\[
r(\hat{m}_n)=\mathbb{E}[R(\hat{m}_n)],
\]</span></p>
<p><em>the prediction risk or generalized error.</em></p>
</blockquote>
</div>
<div id="excess-risk" class="section level3 hasAnchor" number="10.1.2">
<h3><span class="header-section-number">10.1.2</span> Excess risk<a href="supervised-learning.html#excess-risk" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote class="def">
<p><strong>Definition. (Excess Risk)</strong> <em>Consider the set <span class="math inline">\(\mathcal{G}\)</span> be the set of all measurable estimators. Fix a subset <span class="math inline">\(\mathcal{G}_0\subset\mathcal{G}\)</span>. Given some training data <span class="math inline">\(\mathcal{D}_n\)</span> consider the Bayes estimator restricted to <span class="math inline">\(\mathcal{G}_0\)</span> denoted by <span class="math inline">\(\hat{m}_n\)</span> and the unconditional Bayes estimator restricted to <span class="math inline">\(\mathcal{G}\)</span> we define the quantity</em></p>
<p><span class="math display">\[
R(\hat{m}_n)-r(m^*)
\]</span></p>
<p><em>or</em></p>
<p><span class="math display">\[
\mathbb{E}[R(\hat{m}_n)\ \vert\ X_1,...,X_n]-r(m^*),
\]</span></p>
<p><em>as the excess risk. This is the difference between the generalization error and the risk obtained by an optimal decision function.</em></p>
</blockquote>
<p>In the context of the above definition we can decompose the risk associated with the optimal estimator <span class="math inline">\(\hat{m}_n\in\mathcal{G}_0\)</span> into the estimation error and the inductive bias.</p>
<p><span class="math display">\[
R(\hat{m}_n)-r(m^*)=\underbrace{\left[R(\hat{m}_n)-\inf_{m\in\mathcal{G}_0}R(m)\right]}_{\text{estimation error}}+\underbrace{\left[\inf_{m\in\mathcal{G}_0}R(m)-R(m^*)\right].}_{\text{inductions bias/approximation error}}
\]</span>
where we have to balance the trade-off with a larger <span class="math inline">\(\mathcal{G}_0\)</span> infer a lower induction bias but larger estimation error and a smaller class <span class="math inline">\(\mathcal{G}_0\)</span> infer a lower estimation error but larger induction bias.</p>
<blockquote class="def">
<p><strong>Definition. (Empirical risk and empirical risk minimizer)</strong> <em>Given training data <span class="math inline">\(\mathcal{D}_n\)</span> and a loss function <span class="math inline">\(L\)</span>, we call</em></p>
<p><span class="math display">\[
\hat{R}_n(m):=\sum_{i=1}^nL(Y_i,m(X_i))
\]</span></p>
<p><em>the <strong>empirical risk</strong>. Given an additional function class <span class="math inline">\(\mathcal{G}_0\)</span>,</em></p>
<p><span class="math display">\[
\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \hat{R}_n(m)=\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \sum_{i=1}^nL(Y_i,m(X_i))
\]</span></p>
<p><em>is called <strong>empirical risk minimizer</strong> or (standard leaner).</em></p>
</blockquote>
<p>For larger function classes <span class="math inline">\(\mathcal{G}_0\)</span> the empirical risk minimizer might not be unique and possibly too noisy. In this case one sometimes adds a penalty term <span class="math inline">\(J_\lambda : \mathcal{G}\to \mathbb{R}_+\)</span> that penalizes the complexity of <span class="math inline">\(m\)</span> and minimizes the penalized empirical risk:</p>
<p><span class="math display">\[
\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \hat{R}_{n,\lambda}:=\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \sum_{i=1}^nL(Y_i,m(X_i)) + J_\lambda(m).
\]</span></p>
<p>If <span class="math inline">\(J_\lambda\)</span> and <span class="math inline">\(\hat{R}_n\)</span> is convex one can show that</p>
<p><span class="math display">\[
\underset{m\in\mathcal{G}_0}{\text{argmin}}\ \hat{R}_{n,\lambda}=\underset{m\in\mathcal{G}_\eta}{\text{argmin}}\ \hat{R}_{n}
\]</span></p>
<p>for the class <span class="math inline">\(\mathcal{G}_\eta=\{m\in \mathcal{G}_0\ \vert\ J_\lambda(m)\le \eta\}\)</span>. Some penalty terms could be</p>
<ul>
<li><span class="math inline">\(J_\lambda(m)=\lambda\int m&#39;&#39;(x)\ dx\)</span>,</li>
<li><span class="math inline">\(J_\lambda(m)=\lambda \int\vert m&#39;(x)\vert\ dx\)</span>,</li>
<li><span class="math inline">\(J_\lambda(m)=\lambda \int(m(x))^2\ dx\)</span>.</li>
</ul>
<blockquote class="prop">
<p><strong>Proposition. (Probability bounds)</strong> <em>Let <span class="math inline">\(\tilde{m}=\underset{m}{\text{argmin}}\ r(m)\)</span>. We have</em></p>
<p><span class="math display">\[
r(\hat{m}_n)-r(\tilde{m})\le 2\sup_{m\in\mathcal{G}_0}\Big\vert\hat{R}_n(m) - r(m) \Big\vert,
\]</span></p>
<p><em>and for all <span class="math inline">\(\lambda \in \Lambda\)</span>,</em></p>
<p><span class="math display">\[
r(\hat{m}_{n,\lambda})-r(\tilde{m})\le 2\sup_{m\in\mathcal{G}_0}\Big\vert\hat{R}_{n,\lambda}(m) - r(m) \Big\vert + J_\lambda(\tilde{m})-J_\lambda(\hat{m}_n).
\]</span></p>
</blockquote>
<blockquote class="def">
<p><strong>Definition.</strong> <em>We say <span class="math inline">\(\hat{m}_n\)</span> is <span class="math inline">\(\varepsilon\)</span>-accurate with probabiltiy <span class="math inline">\(1-\delta\)</span>, if</em></p>
<p><span class="math display">\[
P\Big(R(\hat{m}_n)-\inf_{m\in\mathcal{G}}r(m)&gt;\varepsilon\Big)&lt;\delta.
\]</span></p>
</blockquote>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probabilistic-machine-learning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="training-validating-and-testing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["theory.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
