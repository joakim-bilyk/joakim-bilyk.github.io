<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9.3 Linear Models | Mathematics of the Actuarial Sciences</title>
  <meta name="description" content="This document contains lecture notes from the courses i attended during my education. The notes mostly contains results from the master courses but there are also included some results from the bachelor as these lay out some of the fundamentals of the mathematics used during the master courses. I want to stress that this is a work in progress and as such is subject to some small and some severy errors. The contents of these notes have not been supervised by anyone other than myself and so, although i an confident in most of the content, i would not take any of the below as clear facts. Always due your own research and derivations to confirm the results." />
  <meta name="generator" content="bookdown 0.33 and GitBook 2.6.7" />

  <meta property="og:title" content="9.3 Linear Models | Mathematics of the Actuarial Sciences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This document contains lecture notes from the courses i attended during my education. The notes mostly contains results from the master courses but there are also included some results from the bachelor as these lay out some of the fundamentals of the mathematics used during the master courses. I want to stress that this is a work in progress and as such is subject to some small and some severy errors. The contents of these notes have not been supervised by anyone other than myself and so, although i an confident in most of the content, i would not take any of the below as clear facts. Always due your own research and derivations to confirm the results." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9.3 Linear Models | Mathematics of the Actuarial Sciences" />
  
  <meta name="twitter:description" content="This document contains lecture notes from the courses i attended during my education. The notes mostly contains results from the master courses but there are also included some results from the bachelor as these lay out some of the fundamentals of the mathematics used during the master courses. I want to stress that this is a work in progress and as such is subject to some small and some severy errors. The contents of these notes have not been supervised by anyone other than myself and so, although i an confident in most of the content, i would not take any of the below as clear facts. Always due your own research and derivations to confirm the results." />
  

<meta name="author" content="Joakim Bilyk" />


<meta name="date" content="2023-04-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="training-validating-and-testing.html"/>
<link rel="next" href="nonparametric-regression.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.6.2/htmlwidgets.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.9/grViz.js"></script>
<script src="https://code.jquery.com/jquery-1.9.1.js"></script>

<script>
    $(function() {
        var element = document.body;
        if (localStorage.chkbx && localStorage.chkbx != '') {
            $('#remember_me').attr('checked', 'checked');
            element.classList.toggle("dark-mode");
            document.querySelector('.book-header.fixed').click();
        } else {
            $('#remember_me').removeAttr('checked');
            document.querySelector('.book-header.fixed').click();
        }

        $('#remember_me').click(function() {

            if ($('#remember_me').is(':checked')) {
                // save username and password
                localStorage.chkbx = $('#remember_me').val();
                element.classList.toggle("dark-mode");
                document.querySelector('.book-header.fixed').click();
            } else {
                localStorage.chkbx = '';
                element.classList.toggle("dark-mode");
                document.querySelector('.book-header.fixed').click();
            }
        });
    });

</script>

<div class = "sticky-darkmode-toggle">
  <label class="switch">
  <input type="checkbox" value="remember-me" id="remember_me">
  <span class="slider round">
  </span>
  </label>
</div>

<script>
$(function() {
  $('body').after($('.sticky-darkmode-toggle'));
})
</script>

<style>

.sticky-darkmode-toggle {
  position: fixed;
  right: 20px;
  bottom: 20px;
}
</style>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Comlete theory</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i>Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="abbreviations.html"><a href="abbreviations.html"><i class="fa fa-check"></i>Abbreviations</a></li>
<li class="chapter" data-level="" data-path="to-do-reading.html"><a href="to-do-reading.html"><i class="fa fa-check"></i>To-do reading</a></li>
<li class="chapter" data-level="" data-path="notation.html"><a href="notation.html"><i class="fa fa-check"></i>Notation</a></li>
</ul></li>
<li class="part"><span><b>I The Mathematics of Life Insurance and Financial Contracts</b></span></li>
<li class="chapter" data-level="1" data-path="basic-life-insurance-mathematics.html"><a href="basic-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>1</b> Basic Life Insurance Mathematics</a>
<ul>
<li class="chapter" data-level="1.1" data-path="payments-interest-and-mortality.html"><a href="payments-interest-and-mortality.html"><i class="fa fa-check"></i><b>1.1</b> Payments, interest and mortality</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="payments-interest-and-mortality.html"><a href="payments-interest-and-mortality.html#payments"><i class="fa fa-check"></i><b>1.1.1</b> Payments</a></li>
<li class="chapter" data-level="1.1.2" data-path="payments-interest-and-mortality.html"><a href="payments-interest-and-mortality.html#interests"><i class="fa fa-check"></i><b>1.1.2</b> Interests</a></li>
<li class="chapter" data-level="1.1.3" data-path="payments-interest-and-mortality.html"><a href="payments-interest-and-mortality.html#valuation-of-paymentstreams"><i class="fa fa-check"></i><b>1.1.3</b> Valuation of paymentstreams</a></li>
<li class="chapter" data-level="1.1.4" data-path="payments-interest-and-mortality.html"><a href="payments-interest-and-mortality.html#mortality"><i class="fa fa-check"></i><b>1.1.4</b> Mortality</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="insurance-of-a-single-life.html"><a href="insurance-of-a-single-life.html"><i class="fa fa-check"></i><b>1.2</b> Insurance of a single life</a></li>
<li class="chapter" data-level="1.3" data-path="expenses.html"><a href="expenses.html"><i class="fa fa-check"></i><b>1.3</b> Expenses</a></li>
<li class="chapter" data-level="1.4" data-path="multi-life-insurances.html"><a href="multi-life-insurances.html"><i class="fa fa-check"></i><b>1.4</b> Multi-life insurances</a></li>
<li class="chapter" data-level="1.5" data-path="markov-chains-in-life-insurance.html"><a href="markov-chains-in-life-insurance.html"><i class="fa fa-check"></i><b>1.5</b> Markov chains in life insurance</a></li>
<li class="chapter" data-level="1.6" data-path="safety-loadings-and-bonus.html"><a href="safety-loadings-and-bonus.html"><i class="fa fa-check"></i><b>1.6</b> Safety loadings and bonus</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="stochastic-processes-in-life-insurance-mathematics.html"><a href="stochastic-processes-in-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>2</b> Stochastic Processes in Life Insurance Mathematics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="lebesgue-stieltjes-calculus.html"><a href="lebesgue-stieltjes-calculus.html"><i class="fa fa-check"></i><b>2.1</b> Lebesgue-Stieltjes calculus</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="lebesgue-stieltjes-calculus.html"><a href="lebesgue-stieltjes-calculus.html#cadlag-functions"><i class="fa fa-check"></i><b>2.1.1</b> CADLAG functions</a></li>
<li class="chapter" data-level="2.1.2" data-path="lebesgue-stieltjes-calculus.html"><a href="lebesgue-stieltjes-calculus.html#functions-of-finite-variation"><i class="fa fa-check"></i><b>2.1.2</b> Functions of finite variation</a></li>
<li class="chapter" data-level="2.1.3" data-path="lebesgue-stieltjes-calculus.html"><a href="lebesgue-stieltjes-calculus.html#lebesgue-stieltjes-integration"><i class="fa fa-check"></i><b>2.1.3</b> Lebesgue-Stieltjes integration</a></li>
<li class="chapter" data-level="2.1.4" data-path="lebesgue-stieltjes-calculus.html"><a href="lebesgue-stieltjes-calculus.html#change-of-variables-formula-ito-formula-for-fv-functions"><i class="fa fa-check"></i><b>2.1.4</b> Change of variables formula (Ito formula for FV-functions)</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="stochastic-processes.html"><a href="stochastic-processes.html"><i class="fa fa-check"></i><b>2.2</b> Stochastic processes</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="stochastic-processes.html"><a href="stochastic-processes.html#general-theory-of-stochastic-processes"><i class="fa fa-check"></i><b>2.2.1</b> General theory of stochastic processes</a></li>
<li class="chapter" data-level="2.2.2" data-path="stochastic-processes.html"><a href="stochastic-processes.html#markov-processes"><i class="fa fa-check"></i><b>2.2.2</b> Markov processes</a></li>
<li class="chapter" data-level="2.2.3" data-path="stochastic-processes.html"><a href="stochastic-processes.html#finite-variation-processes"><i class="fa fa-check"></i><b>2.2.3</b> Finite variation processes</a></li>
<li class="chapter" data-level="2.2.4" data-path="stochastic-processes.html"><a href="stochastic-processes.html#finite-variation-martingales"><i class="fa fa-check"></i><b>2.2.4</b> Finite variation martingales</a></li>
<li class="chapter" data-level="2.2.5" data-path="stochastic-processes.html"><a href="stochastic-processes.html#integral-processes"><i class="fa fa-check"></i><b>2.2.5</b> Integral processes</a></li>
<li class="chapter" data-level="2.2.6" data-path="stochastic-processes.html"><a href="stochastic-processes.html#counting-processes-and-point-processes"><i class="fa fa-check"></i><b>2.2.6</b> Counting processes and point processes</a></li>
<li class="chapter" data-level="2.2.7" data-path="stochastic-processes.html"><a href="stochastic-processes.html#piecewise-constant-processes-on-finite-state-spaces"><i class="fa fa-check"></i><b>2.2.7</b> Piecewise constant processes on finite state spaces</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="life-insurance-models.html"><a href="life-insurance-models.html"><i class="fa fa-check"></i><b>2.3</b> Life insurance models</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="life-insurance-models.html"><a href="life-insurance-models.html#general-definition-of-reserves"><i class="fa fa-check"></i><b>2.3.1</b> General definition of reserves</a></li>
<li class="chapter" data-level="2.3.2" data-path="life-insurance-models.html"><a href="life-insurance-models.html#multi-state-policy-general-model"><i class="fa fa-check"></i><b>2.3.2</b> Multi-state policy, general model</a></li>
<li class="chapter" data-level="2.3.3" data-path="life-insurance-models.html"><a href="life-insurance-models.html#standard-multi-state-policy-markov-model"><i class="fa fa-check"></i><b>2.3.3</b> Standard multi-state policy, Markov model</a></li>
<li class="chapter" data-level="2.3.4" data-path="life-insurance-models.html"><a href="life-insurance-models.html#models-with-state-duration-semi-markov-model"><i class="fa fa-check"></i><b>2.3.4</b> Models with state duration, semi-Markov model</a></li>
<li class="chapter" data-level="2.3.5" data-path="life-insurance-models.html"><a href="life-insurance-models.html#surplus-and-dividends"><i class="fa fa-check"></i><b>2.3.5</b> Surplus and dividends</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-survival-and-event-history-analysis.html"><a href="introduction-to-survival-and-event-history-analysis.html"><i class="fa fa-check"></i><b>2.4</b> Introduction to survival and event history analysis</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction-to-survival-and-event-history-analysis.html"><a href="introduction-to-survival-and-event-history-analysis.html#hazard-rate-force-of-mortality"><i class="fa fa-check"></i><b>2.4.1</b> Hazard rate (force of mortality)</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction-to-survival-and-event-history-analysis.html"><a href="introduction-to-survival-and-event-history-analysis.html#examples-of-basic-counting-processes-models"><i class="fa fa-check"></i><b>2.4.2</b> Examples of basic counting processes models</a></li>
<li class="chapter" data-level="2.4.3" data-path="introduction-to-survival-and-event-history-analysis.html"><a href="introduction-to-survival-and-event-history-analysis.html#multiplicative-intensity-model"><i class="fa fa-check"></i><b>2.4.3</b> Multiplicative intensity model</a></li>
<li class="chapter" data-level="2.4.4" data-path="introduction-to-survival-and-event-history-analysis.html"><a href="introduction-to-survival-and-event-history-analysis.html#nonparametric-models"><i class="fa fa-check"></i><b>2.4.4</b> Nonparametric models</a></li>
<li class="chapter" data-level="2.4.5" data-path="introduction-to-survival-and-event-history-analysis.html"><a href="introduction-to-survival-and-event-history-analysis.html#parametric-models"><i class="fa fa-check"></i><b>2.4.5</b> Parametric models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="continuous-time-finance.html"><a href="continuous-time-finance.html"><i class="fa fa-check"></i><b>3</b> Continuous Time Finance</a>
<ul>
<li class="chapter" data-level="3.1" data-path="discrete-time-models.html"><a href="discrete-time-models.html"><i class="fa fa-check"></i><b>3.1</b> Discrete time models</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="discrete-time-models.html"><a href="discrete-time-models.html#one-period-time-models"><i class="fa fa-check"></i><b>3.1.1</b> One-period time models</a></li>
<li class="chapter" data-level="3.1.2" data-path="discrete-time-models.html"><a href="discrete-time-models.html#multi-period-model"><i class="fa fa-check"></i><b>3.1.2</b> Multi-period model</a></li>
<li class="chapter" data-level="3.1.3" data-path="discrete-time-models.html"><a href="discrete-time-models.html#generelised-one-period-model"><i class="fa fa-check"></i><b>3.1.3</b> Generelised one-period model</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="self-financing-portfolios.html"><a href="self-financing-portfolios.html"><i class="fa fa-check"></i><b>3.2</b> Self-financing portfolios</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="self-financing-portfolios.html"><a href="self-financing-portfolios.html#discrete-time-sf-portfolio"><i class="fa fa-check"></i><b>3.2.1</b> Discrete time SF portfolio</a></li>
<li class="chapter" data-level="3.2.2" data-path="self-financing-portfolios.html"><a href="self-financing-portfolios.html#continuous-time-sf-portfolio"><i class="fa fa-check"></i><b>3.2.2</b> Continuous time SF portfolio</a></li>
<li class="chapter" data-level="3.2.3" data-path="self-financing-portfolios.html"><a href="self-financing-portfolios.html#portfolio-weights"><i class="fa fa-check"></i><b>3.2.3</b> Portfolio weights</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="black-scholes-pde.html"><a href="black-scholes-pde.html"><i class="fa fa-check"></i><b>3.3</b> Black-Scholes PDE</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="black-scholes-pde.html"><a href="black-scholes-pde.html#contingent-claims-and-arbitrage"><i class="fa fa-check"></i><b>3.3.1</b> Contingent Claims and Arbitrage</a></li>
<li class="chapter" data-level="3.3.2" data-path="black-scholes-pde.html"><a href="black-scholes-pde.html#risk-neutral-valuation-1"><i class="fa fa-check"></i><b>3.3.2</b> Risk Neutral Valuation</a></li>
<li class="chapter" data-level="3.3.3" data-path="black-scholes-pde.html"><a href="black-scholes-pde.html#black-scholes-formula"><i class="fa fa-check"></i><b>3.3.3</b> Black-Scholes formula</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="completeness-and-hedging.html"><a href="completeness-and-hedging.html"><i class="fa fa-check"></i><b>3.4</b> Completeness and Hedging</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="completeness-and-hedging.html"><a href="completeness-and-hedging.html#completeness-in-black-scholes"><i class="fa fa-check"></i><b>3.4.1</b> Completeness in Black-Scholes</a></li>
<li class="chapter" data-level="3.4.2" data-path="completeness-and-hedging.html"><a href="completeness-and-hedging.html#absence-of-arbitrage-1"><i class="fa fa-check"></i><b>3.4.2</b> Absence of Arbitrage</a></li>
<li class="chapter" data-level="3.4.3" data-path="completeness-and-hedging.html"><a href="completeness-and-hedging.html#incomplete-markets"><i class="fa fa-check"></i><b>3.4.3</b> Incomplete Markets</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="parity-relations.html"><a href="parity-relations.html"><i class="fa fa-check"></i><b>3.5</b> Parity relations</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="parity-relations.html"><a href="parity-relations.html#put-call-parity"><i class="fa fa-check"></i><b>3.5.1</b> Put-call Parity</a></li>
<li class="chapter" data-level="3.5.2" data-path="parity-relations.html"><a href="parity-relations.html#the-greeks"><i class="fa fa-check"></i><b>3.5.2</b> The Greeks</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="fundamental-pricing-theorem-i-and-ii.html"><a href="fundamental-pricing-theorem-i-and-ii.html"><i class="fa fa-check"></i><b>3.6</b> Fundamental pricing theorem I and II</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="fundamental-pricing-theorem-i-and-ii.html"><a href="fundamental-pricing-theorem-i-and-ii.html#completeness-1"><i class="fa fa-check"></i><b>3.6.1</b> Completeness</a></li>
<li class="chapter" data-level="3.6.2" data-path="fundamental-pricing-theorem-i-and-ii.html"><a href="fundamental-pricing-theorem-i-and-ii.html#risk-neutral-valuation-formula"><i class="fa fa-check"></i><b>3.6.2</b> Risk Neutral Valuation Formula</a></li>
<li class="chapter" data-level="3.6.3" data-path="fundamental-pricing-theorem-i-and-ii.html"><a href="fundamental-pricing-theorem-i-and-ii.html#stochastic-discount-factors-1"><i class="fa fa-check"></i><b>3.6.3</b> Stochastic Discount Factors</a></li>
<li class="chapter" data-level="3.6.4" data-path="fundamental-pricing-theorem-i-and-ii.html"><a href="fundamental-pricing-theorem-i-and-ii.html#summary"><i class="fa fa-check"></i><b>3.6.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="mathematics-of-the-martingale-approach.html"><a href="mathematics-of-the-martingale-approach.html"><i class="fa fa-check"></i><b>3.7</b> Mathematics of the martingale approach</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="mathematics-of-the-martingale-approach.html"><a href="mathematics-of-the-martingale-approach.html#martingale-representation-theorem"><i class="fa fa-check"></i><b>3.7.1</b> Martingale representation theorem</a></li>
<li class="chapter" data-level="3.7.2" data-path="mathematics-of-the-martingale-approach.html"><a href="mathematics-of-the-martingale-approach.html#girsanov-theorem"><i class="fa fa-check"></i><b>3.7.2</b> Girsanov theorem</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="black-scholes-model---martingale-approach.html"><a href="black-scholes-model---martingale-approach.html"><i class="fa fa-check"></i><b>3.8</b> Black-Scholes model - martingale approach</a></li>
<li class="chapter" data-level="3.9" data-path="multidimensional-models.html"><a href="multidimensional-models.html"><i class="fa fa-check"></i><b>3.9</b> Multidimensional models</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="topics-in-life-insurance-mathematics.html"><a href="topics-in-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>4</b> Topics in Life Insurance Mathematics</a>
<ul>
<li class="chapter" data-level="4.1" data-path="markov-jump-processes.html"><a href="markov-jump-processes.html"><i class="fa fa-check"></i><b>4.1</b> Markov Jump Processes</a></li>
<li class="chapter" data-level="4.2" data-path="phase-type-distributions.html"><a href="phase-type-distributions.html"><i class="fa fa-check"></i><b>4.2</b> Phase-type distributions</a></li>
<li class="chapter" data-level="4.3" data-path="interest-rates.html"><a href="interest-rates.html"><i class="fa fa-check"></i><b>4.3</b> Interest rates</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="interest-rates.html"><a href="interest-rates.html#basic-definitions-and-properties"><i class="fa fa-check"></i><b>4.3.1</b> Basic definitions and properties</a></li>
<li class="chapter" data-level="4.3.2" data-path="interest-rates.html"><a href="interest-rates.html#phase-type-representation-of-bond-prices"><i class="fa fa-check"></i><b>4.3.2</b> Phase-type representation of bond prices</a></li>
<li class="chapter" data-level="4.3.3" data-path="interest-rates.html"><a href="interest-rates.html#term-structure-models"><i class="fa fa-check"></i><b>4.3.3</b> Term structure models</a></li>
<li class="chapter" data-level="4.3.4" data-path="interest-rates.html"><a href="interest-rates.html#estimation-of-ph-bond-models"><i class="fa fa-check"></i><b>4.3.4</b> Estimation of PH bond models</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="survival-and-mortality-rates.html"><a href="survival-and-mortality-rates.html"><i class="fa fa-check"></i><b>4.4</b> Survival and mortality rates</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="survival-and-mortality-rates.html"><a href="survival-and-mortality-rates.html#survival-probabilities-and-forward-mortality-rates"><i class="fa fa-check"></i><b>4.4.1</b> Survival probabilities and forward mortality rates</a></li>
<li class="chapter" data-level="4.4.2" data-path="survival-and-mortality-rates.html"><a href="survival-and-mortality-rates.html#forward-transistion-rates"><i class="fa fa-check"></i><b>4.4.2</b> Forward transistion rates</a></li>
<li class="chapter" data-level="4.4.3" data-path="survival-and-mortality-rates.html"><a href="survival-and-mortality-rates.html#reserves-revisited"><i class="fa fa-check"></i><b>4.4.3</b> Reserves revisited</a></li>
<li class="chapter" data-level="4.4.4" data-path="survival-and-mortality-rates.html"><a href="survival-and-mortality-rates.html#stochastic-mortality-rates"><i class="fa fa-check"></i><b>4.4.4</b> Stochastic mortality rates</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html"><i class="fa fa-check"></i><b>4.5</b> Matrix methods in life insurance</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html#basic-setup"><i class="fa fa-check"></i><b>4.5.1</b> Basic setup</a></li>
<li class="chapter" data-level="4.5.2" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html#interest-rate-free-analysis"><i class="fa fa-check"></i><b>4.5.2</b> Interest rate free analysis</a></li>
<li class="chapter" data-level="4.5.3" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html#transform-of-rewards-and-higher-order-moments"><i class="fa fa-check"></i><b>4.5.3</b> Transform of rewards and higher order moments</a></li>
<li class="chapter" data-level="4.5.4" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html#markovian-interest-rates"><i class="fa fa-check"></i><b>4.5.4</b> Markovian interest rates</a></li>
<li class="chapter" data-level="4.5.5" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html#reserves"><i class="fa fa-check"></i><b>4.5.5</b> Reserves</a></li>
<li class="chapter" data-level="4.5.6" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html#higher-order-moments"><i class="fa fa-check"></i><b>4.5.6</b> Higher order moments</a></li>
<li class="chapter" data-level="4.5.7" data-path="matrix-methods-in-life-insurance.html"><a href="matrix-methods-in-life-insurance.html#equivalence-premium"><i class="fa fa-check"></i><b>4.5.7</b> Equivalence premium</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html"><i class="fa fa-check"></i><b>4.6</b> Financial Mathematics in Life Insurance</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#background-and-simple-claims"><i class="fa fa-check"></i><b>4.6.1</b> Background and Simple Claims</a></li>
<li class="chapter" data-level="4.6.2" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#payment-streams"><i class="fa fa-check"></i><b>4.6.2</b> Payment Streams</a></li>
<li class="chapter" data-level="4.6.3" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#unit-link-insurance"><i class="fa fa-check"></i><b>4.6.3</b> Unit-Link Insurance</a></li>
<li class="chapter" data-level="4.6.4" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#with-profit-insurance-and-the-dynamics-of-the-surplus"><i class="fa fa-check"></i><b>4.6.4</b> With-Profit Insurance and the Dynamics of the Surplus</a></li>
<li class="chapter" data-level="4.6.5" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#cash-dividends-and-market-reserve"><i class="fa fa-check"></i><b>4.6.5</b> Cash Dividends and Market Reserve</a></li>
<li class="chapter" data-level="4.6.6" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#the-pure-case-of-cash-dividends"><i class="fa fa-check"></i><b>4.6.6</b> The Pure Case of Cash Dividends</a></li>
<li class="chapter" data-level="4.6.7" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#bonus-payments-and-market-reserve"><i class="fa fa-check"></i><b>4.6.7</b> Bonus Payments and Market Reserve</a></li>
<li class="chapter" data-level="4.6.8" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#the-pure-case-of-bonus-payments"><i class="fa fa-check"></i><b>4.6.8</b> The Pure Case of Bonus Payments</a></li>
<li class="chapter" data-level="4.6.9" data-path="financial-mathematics-in-life-insurance.html"><a href="financial-mathematics-in-life-insurance.html#incidental-policy-holder-behavior"><i class="fa fa-check"></i><b>4.6.9</b> Incidental Policy Holder Behavior</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="projects-in-the-mathematics-of-life-insurance.html"><a href="projects-in-the-mathematics-of-life-insurance.html"><i class="fa fa-check"></i><b>5</b> Projects in the Mathematics of Life Insurance</a>
<ul>
<li class="chapter" data-level="5.1" data-path="cash-flows-markov-models-and-policyholder-behavior.html"><a href="cash-flows-markov-models-and-policyholder-behavior.html"><i class="fa fa-check"></i><b>5.1</b> Cash flows, Markov models, and policyholder behavior</a></li>
<li class="chapter" data-level="5.2" data-path="transaction-time-modeling.html"><a href="transaction-time-modeling.html"><i class="fa fa-check"></i><b>5.2</b> Transaction time modeling</a></li>
<li class="chapter" data-level="5.3" data-path="parametric-estimation-in-markov-models.html"><a href="parametric-estimation-in-markov-models.html"><i class="fa fa-check"></i><b>5.3</b> Parametric estimation in Markov models</a></li>
<li class="chapter" data-level="5.4" data-path="non-parametric-estimation-in-markov-models.html"><a href="non-parametric-estimation-in-markov-models.html"><i class="fa fa-check"></i><b>5.4</b> Non-parametric estimation in Markov models</a></li>
<li class="chapter" data-level="5.5" data-path="non-markov-modeling.html"><a href="non-markov-modeling.html"><i class="fa fa-check"></i><b>5.5</b> Non-Markov modeling</a></li>
<li class="chapter" data-level="5.6" data-path="outlook.html"><a href="outlook.html"><i class="fa fa-check"></i><b>5.6</b> Outlook</a></li>
</ul></li>
<li class="part"><span><b>II The Mathematics and Methods of Non-Life Insurance</b></span></li>
<li class="chapter" data-level="6" data-path="basic-non-life-insurance-mathematics.html"><a href="basic-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>6</b> Basic Non-Life Insurance Mathematics</a>
<ul>
<li class="chapter" data-level="6.1" data-path="the-basic-model.html"><a href="the-basic-model.html"><i class="fa fa-check"></i><b>6.1</b> The Basic Model</a></li>
<li class="chapter" data-level="6.2" data-path="models-for-the-claim-number-process.html"><a href="models-for-the-claim-number-process.html"><i class="fa fa-check"></i><b>6.2</b> Models for the Claim Number Process</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="models-for-the-claim-number-process.html"><a href="models-for-the-claim-number-process.html#the-poisson-process"><i class="fa fa-check"></i><b>6.2.1</b> The Poisson Process</a></li>
<li class="chapter" data-level="6.2.2" data-path="models-for-the-claim-number-process.html"><a href="models-for-the-claim-number-process.html#the-homogeneous-poisson-process-the-intensity-function-the-cramér-lundberg-model"><i class="fa fa-check"></i><b>6.2.2</b> The Homogeneous Poisson Process, the Intensity Function, the Cramér-Lundberg Model</a></li>
<li class="chapter" data-level="6.2.3" data-path="models-for-the-claim-number-process.html"><a href="models-for-the-claim-number-process.html#the-markov-property"><i class="fa fa-check"></i><b>6.2.3</b> The Markov Property</a></li>
<li class="chapter" data-level="6.2.4" data-path="models-for-the-claim-number-process.html"><a href="models-for-the-claim-number-process.html#relations-between-the-homogeneous-and-the-inhomogeneous-poisson-process"><i class="fa fa-check"></i><b>6.2.4</b> Relations Between the Homogeneous and the Inhomogeneous Poisson Process</a></li>
<li class="chapter" data-level="6.2.5" data-path="models-for-the-claim-number-process.html"><a href="models-for-the-claim-number-process.html#the-homogeneous-poisson-process-as-a-renewal-process"><i class="fa fa-check"></i><b>6.2.5</b> The Homogeneous Poisson Process as a Renewal Process</a></li>
<li class="chapter" data-level="6.2.6" data-path="models-for-the-claim-number-process.html"><a href="models-for-the-claim-number-process.html#the-distribution-of-the-inter-arrival-times"><i class="fa fa-check"></i><b>6.2.6</b> The Distribution of the Inter-Arrival Times</a></li>
<li class="chapter" data-level="6.2.7" data-path="models-for-the-claim-number-process.html"><a href="models-for-the-claim-number-process.html#the-order-statistics-property"><i class="fa fa-check"></i><b>6.2.7</b> The Order Statistics Property</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="the-total-claim-amount.html"><a href="the-total-claim-amount.html"><i class="fa fa-check"></i><b>6.3</b> The Total Claim Amount</a></li>
<li class="chapter" data-level="6.4" data-path="ruin-theory.html"><a href="ruin-theory.html"><i class="fa fa-check"></i><b>6.4</b> Ruin Theory</a></li>
<li class="chapter" data-level="6.5" data-path="bayes-estimation.html"><a href="bayes-estimation.html"><i class="fa fa-check"></i><b>6.5</b> Bayes Estimation</a></li>
<li class="chapter" data-level="6.6" data-path="linear-bayes-estimation.html"><a href="linear-bayes-estimation.html"><i class="fa fa-check"></i><b>6.6</b> Linear Bayes Estimation</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="stochastic-processes-in-non-life-insurance-mathematics.html"><a href="stochastic-processes-in-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>7</b> Stochastic Processes in Non-Life Insurance Mathematics</a>
<ul>
<li class="chapter" data-level="7.1" data-path="preliminaries.html"><a href="preliminaries.html"><i class="fa fa-check"></i><b>7.1</b> Preliminaries</a></li>
<li class="chapter" data-level="7.2" data-path="the-cramer-lundberg-model.html"><a href="the-cramer-lundberg-model.html"><i class="fa fa-check"></i><b>7.2</b> The Cramer-Lundberg model</a></li>
<li class="chapter" data-level="7.3" data-path="the-renewal-risk-model.html"><a href="the-renewal-risk-model.html"><i class="fa fa-check"></i><b>7.3</b> The renewal risk model</a></li>
<li class="chapter" data-level="7.4" data-path="modern-ruin-theory.html"><a href="modern-ruin-theory.html"><i class="fa fa-check"></i><b>7.4</b> Modern ruin theory</a></li>
<li class="chapter" data-level="7.5" data-path="claims-reserving.html"><a href="claims-reserving.html"><i class="fa fa-check"></i><b>7.5</b> Claims reserving</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="topics-in-non-life-insurance-mathematics.html"><a href="topics-in-non-life-insurance-mathematics.html"><i class="fa fa-check"></i><b>8</b> Topics in Non-Life Insurance Mathematics</a></li>
<li class="chapter" data-level="9" data-path="probabilistic-machine-learning.html"><a href="probabilistic-machine-learning.html"><i class="fa fa-check"></i><b>9</b> Probabilistic Machine Learning</a>
<ul>
<li class="chapter" data-level="9.1" data-path="supervised-learning.html"><a href="supervised-learning.html"><i class="fa fa-check"></i><b>9.1</b> Supervised Learning</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="supervised-learning.html"><a href="supervised-learning.html#what-is-a-good-estimator"><i class="fa fa-check"></i><b>9.1.1</b> What is a good estimator?</a></li>
<li class="chapter" data-level="9.1.2" data-path="supervised-learning.html"><a href="supervised-learning.html#excess-risk"><i class="fa fa-check"></i><b>9.1.2</b> Excess risk</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="training-validating-and-testing.html"><a href="training-validating-and-testing.html"><i class="fa fa-check"></i><b>9.2</b> Training, Validating and Testing</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="training-validating-and-testing.html"><a href="training-validating-and-testing.html#estimating-risk"><i class="fa fa-check"></i><b>9.2.1</b> Estimating risk</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>9.3</b> Linear Models</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="linear-models.html"><a href="linear-models.html#least-squares-estimator"><i class="fa fa-check"></i><b>9.3.1</b> Least Squares Estimator</a></li>
<li class="chapter" data-level="9.3.2" data-path="linear-models.html"><a href="linear-models.html#ridge-regression"><i class="fa fa-check"></i><b>9.3.2</b> Ridge Regression</a></li>
<li class="chapter" data-level="9.3.3" data-path="linear-models.html"><a href="linear-models.html#lasso-regression"><i class="fa fa-check"></i><b>9.3.3</b> Lasso Regression</a></li>
<li class="chapter" data-level="9.3.4" data-path="linear-models.html"><a href="linear-models.html#conclusion"><i class="fa fa-check"></i><b>9.3.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html"><i class="fa fa-check"></i><b>9.4</b> Nonparametric Regression</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html#linear-smoothers"><i class="fa fa-check"></i><b>9.4.1</b> Linear Smoothers</a></li>
<li class="chapter" data-level="9.4.2" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html#curse-of-dimensionality"><i class="fa fa-check"></i><b>9.4.2</b> Curse of dimensionality</a></li>
<li class="chapter" data-level="9.4.3" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html#splines"><i class="fa fa-check"></i><b>9.4.3</b> Splines</a></li>
<li class="chapter" data-level="9.4.4" data-path="nonparametric-regression.html"><a href="nonparametric-regression.html#linear-regression-with-splines."><i class="fa fa-check"></i><b>9.4.4</b> Linear regression with splines.</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="trees-and-forests.html"><a href="trees-and-forests.html"><i class="fa fa-check"></i><b>9.5</b> Trees and forests</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="trees-and-forests.html"><a href="trees-and-forests.html#cart"><i class="fa fa-check"></i><b>9.5.1</b> CART</a></li>
<li class="chapter" data-level="9.5.2" data-path="trees-and-forests.html"><a href="trees-and-forests.html#pruning"><i class="fa fa-check"></i><b>9.5.2</b> Pruning</a></li>
<li class="chapter" data-level="9.5.3" data-path="trees-and-forests.html"><a href="trees-and-forests.html#bagging"><i class="fa fa-check"></i><b>9.5.3</b> Bagging</a></li>
<li class="chapter" data-level="9.5.4" data-path="trees-and-forests.html"><a href="trees-and-forests.html#random-forests"><i class="fa fa-check"></i><b>9.5.4</b> Random Forests</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="boosting-and-additive-trees.html"><a href="boosting-and-additive-trees.html"><i class="fa fa-check"></i><b>9.6</b> Boosting and additive trees</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="boosting-and-additive-trees.html"><a href="boosting-and-additive-trees.html#gradient-boosting-machines"><i class="fa fa-check"></i><b>9.6.1</b> Gradient Boosting Machines</a></li>
<li class="chapter" data-level="9.6.2" data-path="boosting-and-additive-trees.html"><a href="boosting-and-additive-trees.html#bayesian-additive-regression-trees"><i class="fa fa-check"></i><b>9.6.2</b> Bayesian additive regression trees</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="some-practical-considerations.html"><a href="some-practical-considerations.html"><i class="fa fa-check"></i><b>9.7</b> Some practical considerations</a></li>
<li class="chapter" data-level="9.8" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>9.8</b> Neural Networks</a></li>
<li class="chapter" data-level="9.9" data-path="local-explanations.html"><a href="local-explanations.html"><i class="fa fa-check"></i><b>9.9</b> Local explanations</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="local-explanations.html"><a href="local-explanations.html#interpretability"><i class="fa fa-check"></i><b>9.9.1</b> Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="9.10" data-path="causality.html"><a href="causality.html"><i class="fa fa-check"></i><b>9.10</b> Causality</a></li>
<li class="chapter" data-level="9.11" data-path="local-and-global-explanations.html"><a href="local-and-global-explanations.html"><i class="fa fa-check"></i><b>9.11</b> Local and Global Explanations</a>
<ul>
<li class="chapter" data-level="9.11.1" data-path="local-and-global-explanations.html"><a href="local-and-global-explanations.html#interpretability-1"><i class="fa fa-check"></i><b>9.11.1</b> Interpretability</a></li>
<li class="chapter" data-level="9.11.2" data-path="local-and-global-explanations.html"><a href="local-and-global-explanations.html#partial-dependence-plots"><i class="fa fa-check"></i><b>9.11.2</b> Partial dependence plots</a></li>
<li class="chapter" data-level="9.11.3" data-path="local-and-global-explanations.html"><a href="local-and-global-explanations.html#a-functional-decomposition"><i class="fa fa-check"></i><b>9.11.3</b> A functional decomposition</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="quantative-risk-management.html"><a href="quantative-risk-management.html"><i class="fa fa-check"></i><b>10</b> Quantative Risk Management</a>
<ul>
<li class="chapter" data-level="10.1" data-path="the-loss-variable.html"><a href="the-loss-variable.html"><i class="fa fa-check"></i><b>10.1</b> The Loss Variable</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="the-loss-variable.html"><a href="the-loss-variable.html#risk-measures"><i class="fa fa-check"></i><b>10.1.1</b> Risk measures</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="extreme-value-theory.html"><a href="extreme-value-theory.html"><i class="fa fa-check"></i><b>10.2</b> Extreme value theory</a></li>
<li class="chapter" data-level="10.3" data-path="elliptical-distributions-and-copulas.html"><a href="elliptical-distributions-and-copulas.html"><i class="fa fa-check"></i><b>10.3</b> Elliptical distributions and copulas</a></li>
<li class="chapter" data-level="10.4" data-path="credit-risk-modelling.html"><a href="credit-risk-modelling.html"><i class="fa fa-check"></i><b>10.4</b> Credit risk modelling</a></li>
<li class="chapter" data-level="10.5" data-path="models-for-operational-risk.html"><a href="models-for-operational-risk.html"><i class="fa fa-check"></i><b>10.5</b> Models for operational risk</a></li>
</ul></li>
<li class="part"><span><b>III Mathematical Prerequisites</b></span></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="measure-theory.html"><a href="measure-theory.html"><i class="fa fa-check"></i><b>A</b> Measure theory</a>
<ul>
<li class="chapter" data-level="A.1" data-path="axioms-of-probability.html"><a href="axioms-of-probability.html"><i class="fa fa-check"></i><b>A.1</b> Axioms of Probability</a></li>
<li class="chapter" data-level="A.2" data-path="conditional-probability-and-independence.html"><a href="conditional-probability-and-independence.html"><i class="fa fa-check"></i><b>A.2</b> Conditional Probability and Independence</a></li>
<li class="chapter" data-level="A.3" data-path="probabilities-on-a-finite-or-countable-space.html"><a href="probabilities-on-a-finite-or-countable-space.html"><i class="fa fa-check"></i><b>A.3</b> Probabilities on a Finite or Countable Space</a></li>
<li class="chapter" data-level="A.4" data-path="construction-of-a-probability-measure-on-mathbb-r.html"><a href="construction-of-a-probability-measure-on-mathbb-r.html"><i class="fa fa-check"></i><b>A.4</b> Construction of a Probability Measure on <span class="math inline">\(\mathbb R\)</span></a></li>
<li class="chapter" data-level="A.5" data-path="random-variables.html"><a href="random-variables.html"><i class="fa fa-check"></i><b>A.5</b> Random Variables</a></li>
<li class="chapter" data-level="A.6" data-path="integration-with-respect-to-a-probability-measure.html"><a href="integration-with-respect-to-a-probability-measure.html"><i class="fa fa-check"></i><b>A.6</b> Integration with Respect to a Probability Measure</a></li>
<li class="chapter" data-level="A.7" data-path="independent-random-variables.html"><a href="independent-random-variables.html"><i class="fa fa-check"></i><b>A.7</b> Independent Random Variables</a></li>
<li class="chapter" data-level="A.8" data-path="probability-distributions-on-mathbb-r.html"><a href="probability-distributions-on-mathbb-r.html"><i class="fa fa-check"></i><b>A.8</b> Probability Distributions on <span class="math inline">\(\mathbb R\)</span></a></li>
<li class="chapter" data-level="A.9" data-path="probability-distributions-on-mathbb-rn.html"><a href="probability-distributions-on-mathbb-rn.html"><i class="fa fa-check"></i><b>A.9</b> Probability Distributions on <span class="math inline">\(\mathbb R^n\)</span></a></li>
<li class="chapter" data-level="A.10" data-path="equivalent-probability-measures.html"><a href="equivalent-probability-measures.html"><i class="fa fa-check"></i><b>A.10</b> Equivalent Probability Measures</a>
<ul>
<li class="chapter" data-level="A.10.1" data-path="equivalent-probability-measures.html"><a href="equivalent-probability-measures.html#the-radon-nikodym-theorem"><i class="fa fa-check"></i><b>A.10.1</b> The Radon-Nikodym Theorem</a></li>
<li class="chapter" data-level="A.10.2" data-path="equivalent-probability-measures.html"><a href="equivalent-probability-measures.html#equivalent-probability-measures-1"><i class="fa fa-check"></i><b>A.10.2</b> Equivalent Probability Measures</a></li>
<li class="chapter" data-level="A.10.3" data-path="equivalent-probability-measures.html"><a href="equivalent-probability-measures.html#likelihood-processes"><i class="fa fa-check"></i><b>A.10.3</b> Likelihood processes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="random-variables-1.html"><a href="random-variables-1.html"><i class="fa fa-check"></i><b>B</b> Random Variables</a>
<ul>
<li class="chapter" data-level="B.1" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>B.1</b> Introduction</a></li>
<li class="chapter" data-level="B.2" data-path="conditional-expectation.html"><a href="conditional-expectation.html"><i class="fa fa-check"></i><b>B.2</b> Conditional expectation</a></li>
<li class="chapter" data-level="B.3" data-path="independence.html"><a href="independence.html"><i class="fa fa-check"></i><b>B.3</b> Independence</a></li>
<li class="chapter" data-level="B.4" data-path="moment-generating-function.html"><a href="moment-generating-function.html"><i class="fa fa-check"></i><b>B.4</b> Moment generating function</a></li>
<li class="chapter" data-level="B.5" data-path="standard-distributions.html"><a href="standard-distributions.html"><i class="fa fa-check"></i><b>B.5</b> Standard distributions</a>
<ul>
<li class="chapter" data-level="B.5.1" data-path="standard-distributions.html"><a href="standard-distributions.html#normal-disribution"><i class="fa fa-check"></i><b>B.5.1</b> Normal disribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="C" data-path="discrete-time-stochastic-processes.html"><a href="discrete-time-stochastic-processes.html"><i class="fa fa-check"></i><b>C</b> Discrete Time Stochastic Processes</a>
<ul>
<li class="chapter" data-level="C.1" data-path="convergence-concepts.html"><a href="convergence-concepts.html"><i class="fa fa-check"></i><b>C.1</b> Convergence concepts</a>
<ul>
<li class="chapter" data-level="C.1.1" data-path="convergence-concepts.html"><a href="convergence-concepts.html#sums-and-average-processes"><i class="fa fa-check"></i><b>C.1.1</b> Sums and average processes</a></li>
<li class="chapter" data-level="C.1.2" data-path="convergence-concepts.html"><a href="convergence-concepts.html#ergodic-theory"><i class="fa fa-check"></i><b>C.1.2</b> Ergodic Theory</a></li>
<li class="chapter" data-level="C.1.3" data-path="convergence-concepts.html"><a href="convergence-concepts.html#weak-convergence"><i class="fa fa-check"></i><b>C.1.3</b> Weak Convergence</a></li>
<li class="chapter" data-level="C.1.4" data-path="convergence-concepts.html"><a href="convergence-concepts.html#central-limit-theorems"><i class="fa fa-check"></i><b>C.1.4</b> Central Limit Theorems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="D" data-path="markov-chains.html"><a href="markov-chains.html"><i class="fa fa-check"></i><b>D</b> Markov Chains</a>
<ul>
<li class="chapter" data-level="D.1" data-path="definition-of-a-markov-chain.html"><a href="definition-of-a-markov-chain.html"><i class="fa fa-check"></i><b>D.1</b> Definition of a Markov Chain</a></li>
<li class="chapter" data-level="D.2" data-path="classification-of-states.html"><a href="classification-of-states.html"><i class="fa fa-check"></i><b>D.2</b> Classification of states</a></li>
<li class="chapter" data-level="D.3" data-path="limit-results-and-invariant-probabilities.html"><a href="limit-results-and-invariant-probabilities.html"><i class="fa fa-check"></i><b>D.3</b> Limit results and invariant probabilities</a></li>
<li class="chapter" data-level="D.4" data-path="absorbing-probabilities.html"><a href="absorbing-probabilities.html"><i class="fa fa-check"></i><b>D.4</b> Absorbing probabilities</a></li>
<li class="chapter" data-level="D.5" data-path="markov-chains-in-continuous-times.html"><a href="markov-chains-in-continuous-times.html"><i class="fa fa-check"></i><b>D.5</b> Markov Chains in Continuous Times</a></li>
<li class="chapter" data-level="D.6" data-path="properties-of-transitionsprobabilities.html"><a href="properties-of-transitionsprobabilities.html"><i class="fa fa-check"></i><b>D.6</b> Properties of transitionsprobabilities</a></li>
<li class="chapter" data-level="D.7" data-path="invariant-probabilies-and-absorption.html"><a href="invariant-probabilies-and-absorption.html"><i class="fa fa-check"></i><b>D.7</b> Invariant probabilies and absorption</a></li>
<li class="chapter" data-level="D.8" data-path="birth-death-processes.html"><a href="birth-death-processes.html"><i class="fa fa-check"></i><b>D.8</b> Birth-death processes</a></li>
</ul></li>
<li class="chapter" data-level="E" data-path="continuous-time-stochastic-processes.html"><a href="continuous-time-stochastic-processes.html"><i class="fa fa-check"></i><b>E</b> Continuous Time Stochastic Processes</a>
<ul>
<li class="chapter" data-level="E.1" data-path="brownian-motion.html"><a href="brownian-motion.html"><i class="fa fa-check"></i><b>E.1</b> Brownian Motion</a></li>
<li class="chapter" data-level="E.2" data-path="filtration.html"><a href="filtration.html"><i class="fa fa-check"></i><b>E.2</b> Filtration</a></li>
<li class="chapter" data-level="E.3" data-path="martingale.html"><a href="martingale.html"><i class="fa fa-check"></i><b>E.3</b> Martingale</a></li>
</ul></li>
<li class="chapter" data-level="F" data-path="stochastic-calculus.html"><a href="stochastic-calculus.html"><i class="fa fa-check"></i><b>F</b> Stochastic calculus</a>
<ul>
<li class="chapter" data-level="F.1" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html"><i class="fa fa-check"></i><b>F.1</b> Stochastic Integrals</a>
<ul>
<li class="chapter" data-level="F.1.1" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html#information"><i class="fa fa-check"></i><b>F.1.1</b> Information</a></li>
<li class="chapter" data-level="F.1.2" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html#stochastic-integrals-1"><i class="fa fa-check"></i><b>F.1.2</b> Stochastic Integrals</a></li>
<li class="chapter" data-level="F.1.3" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html#martingales"><i class="fa fa-check"></i><b>F.1.3</b> Martingales</a></li>
<li class="chapter" data-level="F.1.4" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html#stochastic-calculus-and-the-ito-formula"><i class="fa fa-check"></i><b>F.1.4</b> Stochastic Calculus and the Ito Formula</a></li>
<li class="chapter" data-level="F.1.5" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html#the-multidimensional-ito-formula"><i class="fa fa-check"></i><b>F.1.5</b> The multidimensional Ito Formula</a></li>
<li class="chapter" data-level="F.1.6" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html#the-multidimensional-ito-formula-with-states"><i class="fa fa-check"></i><b>F.1.6</b> The multidimensional Ito Formula with states</a></li>
<li class="chapter" data-level="F.1.7" data-path="stochastic-integrals.html"><a href="stochastic-integrals.html#correlated-brownian-motions"><i class="fa fa-check"></i><b>F.1.7</b> Correlated Brownian motions</a></li>
</ul></li>
<li class="chapter" data-level="F.2" data-path="discrete-stochastic-integrals.html"><a href="discrete-stochastic-integrals.html"><i class="fa fa-check"></i><b>F.2</b> Discrete Stochastic Integrals</a></li>
<li class="chapter" data-level="F.3" data-path="stochastic-differential-equations.html"><a href="stochastic-differential-equations.html"><i class="fa fa-check"></i><b>F.3</b> Stochastic Differential Equations</a></li>
<li class="chapter" data-level="F.4" data-path="partial-differential-equations.html"><a href="partial-differential-equations.html"><i class="fa fa-check"></i><b>F.4</b> Partial differential equations</a></li>
<li class="chapter" data-level="F.5" data-path="the-product-integral.html"><a href="the-product-integral.html"><i class="fa fa-check"></i><b>F.5</b> The Product Integral</a>
<ul>
<li class="chapter" data-level="F.5.1" data-path="the-product-integral.html"><a href="the-product-integral.html#properties-of-the-product-integral"><i class="fa fa-check"></i><b>F.5.1</b> Properties of the Product Integral</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="G" data-path="linear-algebra.html"><a href="linear-algebra.html"><i class="fa fa-check"></i><b>G</b> Linear Algebra</a>
<ul>
<li class="chapter" data-level="G.1" data-path="invertible-matrices.html"><a href="invertible-matrices.html"><i class="fa fa-check"></i><b>G.1</b> Invertible matrices</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://joakim-bilyk.github.io/index.html">Back to main site</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mathematics of the Actuarial Sciences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-models" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Linear Models<a href="linear-models.html#linear-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We may take the linear model as a case study of the methods introduced in the above chapter. As such we consider the squaed loss <span class="math inline">\(L(y_1,y_2)=(y_1-y_2)^2\)</span> for which we already know the Bayes rule:</p>
<p><span class="math display">\[
m^*(x)=\underset{m}{\text{argmin}}\ R(m)=\mathbb{E}[Y\ \vert\ X=x].
\]</span></p>
<p>The linear model has the following assumptions. There exists paramaters <span class="math inline">\(\beta_0^*,\beta_1^*,...,\beta_p^*\)</span>, with</p>
<p><span class="math display">\[
m^*(x)=\beta_0^*+\sum_{j=1}^{p}\beta_j^*x_j.
\]</span></p>
<p>In other words, we assume that <span class="math inline">\(m^*\)</span> is a linear function, i.e.,</p>
<p><span class="math display">\[
m^*\in\mathcal{G}=\{f : \mathbb{R}^p\to \mathbb{R}\ \vert\ f(x)=\beta^\top x\}.
\]</span></p>
<p>Given iid training data <span class="math inline">\((X_i,Y_i)_{i=1,...,n}\)</span> we have an additive noise model</p>
<p><span class="math display">\[
Y_i=\beta_0^*+\sum_{j=1}^{p}\beta_j^*X_{ij}+\varepsilon_i,
\]</span></p>
<p>with <span class="math inline">\(\varepsilon_i=Y_i-m^*(X_i)\)</span> and hence iid with <span class="math inline">\(\mathbb{E}[\varepsilon_i\ \vert\ X_i]=0\)</span>.</p>
<p>Notice, that since we are assuming <span class="math inline">\(m^*\in\mathcal{G}\)</span> we have by assumption no inductive bias and we therefore only consider estimation error i.e.</p>
<p><span class="math display">\[
R(\hat{m}_n)-r(m^*).
\]</span></p>
<p>Given the training data we may approximate the coefficients using the following.</p>
<blockquote class="lem">
<p><strong>Lemma. (Coefficients in the linear model)</strong> <em>Under the Linear model assumption we have for <span class="math inline">\(j=1,...,p\)</span></em></p>
<p><span class="math display">\[
\beta^*_j=\frac{\text{Cov}\Big(X_{1j},Y_1-\sum_{k\in \{1,...,p\}\setminus \{j\}} \beta_k^*X_{1k}\Big)}{\text{Var}(X_{1j})}
\]</span></p>
<p><em>In particular, if the components of <span class="math inline">\(X\)</span> are uncorrelated, we have</em></p>
<p><span class="math display">\[
\beta_j^*=\frac{\text{Cov}(X_{1j},Y_1)}{\text{Var}(X_{1j})}.
\]</span></p>
</blockquote>
<blockquote class="lem">
<p><strong>Lemma. (Bayes risk in the linear model)</strong> <em>Under the Linear model assumption we have</em></p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(r(m^*)=\text{Var}(\varepsilon_i)\)</span></li>
<li>For <span class="math inline">\(m(x)=\beta_0+\sum_{j=1}^p \beta_jx_j\)</span>,
<span class="math display">\[
  r(m)-r(m^*)=\Vert\Sigma^{1/2}(\beta -\beta^*) \Vert^2_2.
  \]</span></li>
</ol>
<p><em>with <span class="math inline">\(\Sigma = \mathbb E[\mathbf X\mathbf X^\top]\)</span>.</em></p>
</blockquote>
<details>
<summary>
<strong>Proof.</strong>
</summary>
<p>(1). We have by assumptions that <span class="math inline">\(m^*(X)=\mathbb E[Y\ \vert\ X]=X^\top\beta^*\)</span> is the Bayes estimator. Using that the noise is additive we have <span class="math inline">\(Y=m^*(X)+\varepsilon\)</span> with <span class="math inline">\(\mathbb E[\varepsilon]=0\)</span>.
<span class="math display">\[\begin{align*}
r(m^*)&amp;=\mathbb E[(m^*(X)-Y)^2]=\mathbb E[(X^\top\beta ^*-Y)^2]\\
&amp;=\mathbb E[\varepsilon^2]=\text{Var}(\varepsilon)-\mathbb E[\varepsilon]^2\\
&amp;=\text{Var}(\varepsilon).
\end{align*}\]</span>
(2). Take any linear estimor <span class="math inline">\(m(X)=X^\top \beta\)</span>, then we have
<span class="math display">\[\begin{align*}
r(m)&amp;=\mathbb E[(m(X)-Y)^2]\\
&amp;=\mathbb E[(m(X)-m^*(X)+m^*(X)-Y)^2]\\
&amp;=\mathbb E[(m(X)-m^*(X))^2]+\mathbb E[(m^*(X)-Y)^2]+2\mathbb E[(m(X)-m^*(X))(m^*(X)-Y)]\\
&amp;=\mathbb E[(m(X)-m^*(X))^2]+r(m^*)
\end{align*}\]</span>
Using that <span class="math inline">\(m^*(X)-Y\)</span> is orthogonal to <span class="math inline">\(m(X)-m^*(X)\)</span>. This gives us the following
<span class="math display">\[\begin{align*}
r(m)- r(m^*)&amp;=\mathbb E[(m(X)-m^*(X))^2]\\
&amp;=\mathbb E[(X^\top \beta -X^\top \beta^*)^2]\\
&amp;=\mathbb E[XX^\top(\beta-\beta^*)^2]\\
&amp;=\Sigma(\beta-\beta^*)^2=\Vert \Sigma^{1/2}(\beta - \beta^*)\Vert ^2_2
\end{align*}\]</span>
as desired. <span class="math inline">\(\blacksquare\)</span></p>
</details>
<div id="least-squares-estimator" class="section level3 hasAnchor" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> Least Squares Estimator<a href="linear-models.html#least-squares-estimator" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Moving forward we will assume <span class="math inline">\(\beta_0^*=0\)</span> since we can always translate the data and make the centered around 0. We will furthermore use the notation:</p>
<p><span class="math display">\[
\mathbf{X}=
\begin{bmatrix}
X_{11} &amp; \cdots &amp; X_{1p}\\
\vdots &amp; \ddots &amp; \vdots\\
X_{n1} &amp; \cdots &amp; X_{np}
\end{bmatrix},\hspace{10pt} \mathbf{Y}=
\begin{pmatrix}
Y_1\\
\vdots\\
Y_n
\end{pmatrix},\hspace{10pt} \varepsilon=
\begin{pmatrix}
\varepsilon_1\\
\vdots\\
\varepsilon_n
\end{pmatrix}.
\]</span></p>
<p>In this cases the empirical risk takes the form</p>
<p><span class="math display">\[
\hat{R}_n(m)=\frac{1}{n}\Vert\mathbf{Y}-\mathbf{X}\beta \Vert^2_2.
\]</span></p>
<blockquote class="lem">
<p><strong>Lemma. (Least squares estimator)</strong></p>
<ul>
<li><em>It holds that <span class="math inline">\((\mathbf{X}^\top\mathbf{X})\hat{\beta}=\mathbf{X}^\top \mathbf{Y}\)</span>,</em></li>
<li><em>If <span class="math inline">\(\mathbf{X}\)</span> has full rank, then</em>
<span class="math display">\[
  \hat{\beta}_n^{LS}=(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top \mathbf{Y}.
  \]</span></li>
</ul>
</blockquote>
<blockquote class="thm">
<p><strong>Theorem. (Excess risk Least squares estimator)</strong> <em>If <span class="math inline">\(\mathbf{X}^\top\mathbf{X}\)</span> is invertible, then</em></p>
<p><span class="math display">\[
\mathbb{E}[R(\hat{m}_n^{LS})\ \vert\ \mathbf{X}]-r(m^*)=\frac{\sigma^2}{n}\cdot \text{tr}\left(\Sigma\hat{\Sigma}^{-1}\right)
\]</span></p>
<p><em>with <span class="math inline">\(\Sigma=\mathbb{E}[\mathbf{X}^\top\mathbf{X}]\)</span> and <span class="math inline">\(\hat{\Sigma}=\frac{1}{n}\mathbf{X}^\top\mathbf{X}\)</span>.</em></p>
</blockquote>
<details>
<summary>
<strong>Proof.</strong>
</summary>
<p><span class="math display">\[
\hat{\beta}^{LS}=\left(\mathbf{X}^T \mathbf{X}\right)^{-1} \mathbf{X}^T \mathbf{Y}=\left(\mathbf{X}^T \mathbf{X}\right)^{-1} \mathbf{X}^T \mathbf{X} \beta^*+\left(\mathbf{X}^T \mathbf{X}\right)^{-1} \mathbf{X}^T \mathbf{\varepsilon}=\beta^*+\left(\mathbf{X}^T \mathbf{X}\right)^{-1} \mathbf{X}^T \mathbf{\mathbf { \varepsilon }}.
\]</span></p>
<p>Thus
<span class="math display">\[\begin{align*}
R\left(\hat{m}^{LS}\right)-r\left(m^*\right) &amp; =\left\|\Sigma^{1 / 2}\left(\hat{\beta}^{L S}-\beta^*\right)\right\|_2^2=\left\|\Sigma^{1 / 2}\left(\mathbf{X}^T \mathbf{X}\right)^{-1} \mathbf{X}^T \mathbf{\varepsilon}\right\|_2^2=n^{-1}\left\|n^{-1/2}\Sigma^{1 / 2} \hat{\Sigma}^{-1} {\mathbf{X}^T \mathbf{\varepsilon}}\right\|_2^2 \\
&amp; =n^{-1}\|A \mathbf{\varepsilon}\|_2^2,
\end{align*}\]</span>
where <span class="math inline">\(\hat \Sigma=n^{-1} \mathbf{{X^T}X}, A:=n^{-1/2}\Sigma^{1 / 2} \hat{\Sigma}^{-1} {\mathbf{X}^T}\)</span>. We calculate the excess risk conditional on <span class="math inline">\(\mathbf{X}\)</span>. Note that <span class="math inline">\(\operatorname{tr}(\cdot)\)</span> is linear and invariant under cyclic permutations. We have
<span class="math display">\[\begin{align*}
\mathbb{E}\left[R\left(\hat{m}^{LS}\right) \mid \mathbf{X}\right]-r\left(m^*\right) &amp; =n^{-1} \mathbb{E}\left[\|A \mathbf{\varepsilon}\|_2^2 \mid \mathbf{X}\right] \\
&amp; =n^{-1} \mathbb{E}\left[\operatorname{tr}\left(A \mathbf{\varepsilon \varepsilon}^T A^T\right) \mid \mathbf{X}\right]=n^{-1} \operatorname{tr}(A \underbrace{\mathbb{E}\left[\mathbf{\varepsilon \varepsilon}^T\right]}_{=\sigma^2 I_{p \times p}} A^T)=\frac{\sigma^2}{n}\|A\|_F^2 \\
&amp; =\frac{\sigma^2}{n} \cdot \operatorname{tr}\left(\Sigma^{1 / 2} \hat{\Sigma}^{-1} \hat{\Sigma} \hat{\Sigma}^{-1} \Sigma^{1 / 2}\right) \\
&amp; =\frac{\sigma^2}{n} \cdot \operatorname{tr}\left(\Sigma \hat{\Sigma}^{-1}\right) .
\end{align*}\]</span>
as desired. <span class="math inline">\(\blacksquare\)</span></p>
</details>
<p>From the above it follos that if <span class="math inline">\(\hat{\Sigma}\approx \Sigma\)</span> then</p>
<p><span class="math display">\[
\mathbb{E}[R(\hat{m}_n^{LS})\ \vert\ \mathbf{X}]-r(m^*)\approx\frac{\sigma^2p}{n}.
\]</span></p>
<p>This approximation does not take into account the variation of <span class="math inline">\(X\)</span>. Due to the inverse, it is not easily possible to derive an upper bound for the expectation of <span class="math inline">\(\hat{\Sigma}^{-1}\)</span>. Therefore, we only obtain a result for the excess Bayes risk which holds with high probability and under additional assumptions (which could be relaxed but would lead to much more complicated proofs).</p>
<blockquote class="thm">
<p><strong>Theorem. (PAC Least squares estimator)</strong> <em>We do not assume a linear model. Let <span class="math inline">\(m(x)=E[Y\ \vert\ X=x]\)</span> and assume <span class="math inline">\(m^*(x)=x\Sigma^{-1}E[YX]\)</span> is the best linear approximation. Assume that <span class="math inline">\(X\)</span> has bounded support and sub-Gaussian noise, i.e., there exists a <span class="math inline">\(\sigma\)</span> such that for all <span class="math inline">\(t\)</span>:</em></p>
<p><span class="math display">\[
E[e^{tx}\ \vert\ X=x]\le e^{t^2\sigma^2/2},
\]</span></p>
<p><em>then for <span class="math inline">\(n\)</span> big enough, and <span class="math inline">\(t&gt;\max\{0,2.6-\log p\}\)</span></em></p>
<p><span class="math display">\[
P\left(r(\hat{m}^{LS})-r(m^*)\ge \frac{2 A}{n}(1+\sqrt{8t})^2+\frac{\sigma^2(p+2\sqrt{pt}+2t)}{n} + o(1/n)\right)\le 3e^{-t}
\]</span></p>
<p><em>where <span class="math inline">\(A=\mathbb{E}\left[\Vert\Sigma^{1/2}X(m(X)-\beta^\top X) \Vert^2\right]\)</span> is an approximation error.</em></p>
</blockquote>
<p>Up until now we have assumed that <span class="math inline">\(\mathbf{X}\)</span> has full rank. This is not very realistic for very large <span class="math inline">\(p\)</span> (<span class="math inline">\(p&gt; &gt; n\)</span>). Even if <span class="math inline">\(\mathbf{X}^\top\mathbf{X}\)</span> is invertible, the variance of the estimation error might be too large. This leads us to penalized models that reduce variance by adding some bias. Other alternatives (not discussed here) are dimension reduction, say via PCA, or feature selection, say forward stepwise regression.</p>
</div>
<div id="ridge-regression" class="section level3 hasAnchor" number="9.3.2">
<h3><span class="header-section-number">9.3.2</span> Ridge Regression<a href="linear-models.html#ridge-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote class="def">
<p><strong>Definition. (Ridge regression)</strong> <em>Let <span class="math inline">\(\lambda \geq 0\)</span> and</em></p>
<p><span class="math display">\[
J_\lambda(\beta)=\lambda\|\beta\|_2^2=\lambda \sum_{j=1}^p \beta_j^2.
\]</span></p>
<p><em>The Ridge estimator is defined as </em>
<span class="math display">\[\begin{align*}
\hat{\beta}_\lambda^{\text {ridge }} &amp; =\underset{\beta \in \mathbb{R}^p}{\arg \min }\left\{\hat{R}_n(\beta)+J_\lambda(\beta)\right\} \\
&amp; =\underset{\beta \in \mathbb{R}^p}{\arg \min }\left\{\|\mathbf{Y}-\mathbf{X} \beta\|_2^2+\lambda\|\beta\|_2^2\right\} .
\end{align*}\]</span>
<em>The corresponding algorithm is</em></p>
<p><span class="math display">\[
\hat{m}_{n, \lambda}^{\text {ridge }}(x)=\sum_{j=1}^p \hat{\beta}^\text{ridge}_{\lambda, j} x_j.
\]</span></p>
</blockquote>
<blockquote class="lem">
<p><strong>Lemma. (Ridge regression solution)</strong> <em>Let <span class="math inline">\(\lambda&gt;0\)</span>. Then </em></p>
<span class="math display">\[
\hat{\beta}^\text{ridge}_\lambda=\left(\mathbf{X}^T \mathbf{X}+\lambda n I_{p \times p}\right)^{-1} \mathbf{X}^T \mathbf{Y}
\]</span>
</blockquote>
<p>In ridge regression, the matrix <span class="math inline">\(\mathbf{X}^T \mathbf{X}\)</span> is ‘made invertible’ by adding a positive multiple of the identity matrix. Therefore, the ridge estimator also can be used in the case <span class="math inline">\(p&gt;n\)</span>. The name ‘ridge’ stems from the fact that the optimization problem is equivalent to</p>
<p><span class="math display">\[
\min _{ \beta \in \mathbb{R}^p} \hat{R}_n(X\beta) \quad \text { s.t. } \quad\|\beta\|_2 \leq t
\]</span></p>
<p>for some suitable <span class="math inline">\(t&gt;0\)</span>.</p>
<blockquote class="thm">
<p><strong>Theorem. (Excess risk for ridge regression estimator)</strong> <em>Under the linear model, </em></p>
<p><span class="math display">\[
\mathbb E[ R\left(\hat{m}^{n,\text{ridge}}_\lambda \right)|X]-r\left(m^*\right)=\frac{\sigma^2}{n} \cdot \operatorname{tr}\left(\Sigma\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \hat{\Sigma}\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1}\right)+\lambda^2\left\|\Sigma^{1 / 2}\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \beta^*\right\|_2^2.
\]</span></p>
<p><em>Let <span class="math inline">\(\Sigma=U D U^T\)</span> be the spectral decomposition of <span class="math inline">\(\Sigma\)</span> with orthogonal matrix <span class="math inline">\(U\)</span> and diagonal matrix <span class="math inline">\(D=\operatorname{diag}\left(s_1, \ldots, s_p\right.\)</span> ) (entries are the eigenvalues of <span class="math inline">\(\Sigma\)</span> ). By assuming <span class="math inline">\(\hat \Sigma= \Sigma\)</span>, the excess risk simplifies to </em></p>
<span class="math display">\[
\frac{\sigma^2}{n} \sum_{j=1}^p \frac{s_j^2}{\left(s_j+\lambda\right)^2}+\lambda^2 \cdot \sum_{j=1}^p \frac{s_j\left(U^T \beta^*\right)_j^2}{\left(s_j+\lambda\right)^2}.
\]</span>
</blockquote>
<details>
<summary>
<strong>Proof.</strong>
</summary>
<p><span class="math display">\[\begin{align*}
\hat{\beta}_\lambda-\beta^* &amp; =-\lambda n\left(\mathbf{X}^T \mathbf{X}+\lambda n I_{p \times p}\right)^{-1} \beta^*+\left(\mathbf{X}^T \mathbf{X}+\lambda n I_{p\times p}\right)^{-1} \mathbf{X}^T \mathbf{\varepsilon} \\
&amp; =-\lambda\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \beta^*+\frac{1}{n}\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \mathbf{X}^T \mathbf{\varepsilon}
\end{align*}\]</span>.
thus</p>
<p><span class="math display">\[
R\left(\hat{\beta}_\lambda\right)-R\left(\beta^*\right)=\left\|B-\frac{1}{\sqrt{n}} A \mathbf{\varepsilon}\right\|_2^2=\|B\|_2^2-\frac{2}{\sqrt{n}}\langle B, A\varepsilon \rangle+\frac{1}{n}\|A \mathbb{\mathbf { \varepsilon }}\|_2^2
\]</span></p>
<p>where <span class="math inline">\(A=\Sigma^{1 / 2}\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \frac{\mathbf{X}^T}{\sqrt{n}}\)</span> and <span class="math inline">\(B:=\lambda \Sigma^{1 / 2}\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \beta^*\)</span>. Since <span class="math inline">\(\mathbb{E} \mathbf{\varepsilon}=0\)</span>, we have
<span class="math display">\[\begin{align*}
\mathbb{E}\left[R\left(\hat{\beta}_\lambda\right) \mid \mathbf{X}\right]-R\left(\beta^*\right) &amp; =\frac{\sigma^2}{n}\|A\|_F^2+\|B\|_2^2 \\
&amp; =\frac{\sigma^2}{n} \cdot \operatorname{tr}\left(\Sigma\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \hat{\Sigma}\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1}\right)\\
&amp;+\lambda^2\left\|\Sigma^{1 / 2}\left(\hat{\Sigma}+\lambda I_{p \times p}\right)^{-1} \beta^*\right\|_2^2
\end{align*}\]</span>
Furthermore, assuming <span class="math inline">\(\hat \Sigma= \Sigma\)</span> the above expression simplifies to
<span class="math display">\[\begin{align*}
&amp;\frac{\sigma^2}{n} \cdot \operatorname{tr}\left(\Sigma\left(\Sigma+\lambda I_{p \times p}\right)^{-1} \Sigma\left(\Sigma+\lambda I_{p \times p}\right)^{-1}\right)+\lambda^2\left\|\Sigma^{1 / 2}\left(\Sigma+\lambda I_{p \times p}\right)^{-1} \beta^*\right\|_2^2 \\
=&amp;\frac{\sigma^2}{n} \cdot \operatorname{tr}\left(D\left(D+\lambda I_{p \times p}\right)^{-1} D\left(D+\lambda I_{p \times p}\right)^{-1}\right)+\lambda^2\left\|D^{1 / 2}\left(D+\lambda I_{p \times p}\right)^{-1} U^T \beta^*\right\|_2^2 \\
=&amp;\frac{\sigma^2}{n} \sum_{j=1}^p \frac{s_j^2}{\left(s_j+\lambda\right)^2}+\lambda^2 \cdot \sum_{j=1}^p \frac{s_j\left(U^T \beta^*\right)_j^2}{\left(s_j+\lambda\right)^2}
\end{align*}\]</span></p>
<p>and the result follows. <span class="math inline">\(\blacksquare\)</span></p>
</details>
<p>If all eigenvalues are equal, that is, <span class="math inline">\(s_j=s\)</span> and if additionally <span class="math inline">\(\left(U^T \beta^*\right)_j=b(j=1, \ldots, p)\)</span>, then the expression of the theorem simplifies to</p>
<p><span class="math display">\[
\frac{\sigma^2 p}{n} \cdot \frac{s^2}{(s+\lambda)^2}+\lambda^2 \frac{s b^2 p}{(s+\lambda)^2} \underset{\lambda=\frac{\sigma^2/n}{b^2}}{\stackrel{\min }{\rightarrow}} \frac{\sigma^2 p}{n} \cdot \frac{b^2 s}{\frac{\sigma^2}{n}+b^2 s} \leq \frac{\sigma^2 p}{n} .
\]</span></p>
<p>We see that for a suitable choice of the penalization parameter <span class="math inline">\(\lambda\)</span>, the excess Bayes risk of the ridge estimator can be smaller than the corresponding upper bound of the LS estimator.</p>
</div>
<div id="lasso-regression" class="section level3 hasAnchor" number="9.3.3">
<h3><span class="header-section-number">9.3.3</span> Lasso Regression<a href="linear-models.html#lasso-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we believe that some covariates are pure noise, i.e., unrelated to <span class="math inline">\(Y\)</span>, the most obvious choice to penalize <span class="math inline">\(\beta\)</span> would be of the form <span class="math inline">\(\|\beta\|_0=\#\{j=\)</span> <span class="math inline">\(\left.{1, \ldots, p: \beta_j} \neq 0\right\}\)</span>. Then, one would simply penalize the number of non-zero entries of <span class="math inline">\(\beta\)</span>. However, this leads to an NP-hard optimization problems whose solutions are not accessible in practice. One therefore uses a different norm which has similar properties but leads to a convex optimization problem.</p>
<blockquote class="def">
<p><strong>Definition. (Lasso - Least absolute shrinkage and selection operator regression)</strong> <em>Let <span class="math inline">\(\lambda \geq 0\)</span> and </em></p>
<p><span class="math display">\[
J_\lambda(\beta)=\lambda \cdot\|\beta\|_1=\lambda \sum_{j=1}^p\left|\beta_j\right| .
\]</span></p>
<p><em>The LASSO estimator is given by </em>
<span class="math display">\[\begin{align*}
\hat{\beta}_\lambda^{\text {lasso }} &amp; \in \underset{\beta \in \mathbb{R}^p}{\arg \min }\left\{\hat{R}_n(X\beta)+J_\lambda(X\beta)\right\} \\
&amp; =\underset{\beta \in \mathbb{R}^p}{\arg \min }\left\{\frac{1}{n}\|\mathbf{Y}-\mathbf{X} \beta\|_2^2+\lambda \cdot\|\beta\|_1\right\}
\end{align*}\]</span>
<em>The corresponding algorithm reads </em></p>
<p><span class="math display">\[
\hat{m}_{n, \lambda}^{l a s s o}(x)=\sum_{j=1}^p \hat{\beta}^{\text{lasso}}_{\lambda, j} x_j.
\]</span></p>
</blockquote>
<p>There exists no easy closed-form solution for <span class="math inline">\(\hat \beta^{\text{lasso}}_{\lambda}\)</span> besides some special cases.</p>
<p>For <span class="math inline">\(\beta \in \mathbb{R}^p\)</span>, define</p>
<p><span class="math display">\[
S(\beta):=\left\{j \in\{1, \ldots, p\}: \beta_j \neq 0\right\}.
\]</span></p>
<p>For <span class="math inline">\(S \subset\{1, \ldots, p\}\)</span> and <span class="math inline">\(v \in \mathbb{R}^p\)</span>, put <span class="math inline">\(v_S:=\left(v_j \mathbb{1}_{\{j \in S\}}\right)_{j=1, \ldots, p}\)</span></p>
<p>If <span class="math inline">\(p \ll n\)</span>, then <span class="math inline">\(\hat{\Sigma}\)</span> would usually be invertible and the smallest eigenvalue (Rayleigh quotient) would satisfy</p>
<p><span class="math display">\[
\lambda_{\min }(\hat{\Sigma}):=\inf _{v \in \mathbb{R}^p} \frac{v^T \hat{\Sigma} v}{\|v\|_2^2}&gt;0.
\]</span></p>
<p>Then <span class="math inline">\(\hat{\Sigma}\)</span> would be one-to-one (injective) and the linear equation system <span class="math inline">\(\hat{\Sigma} \beta=\frac{1}{n} \mathbf{X}^T \mathbf{Y}\)</span> would lead to the (unique) least squares estimator.</p>
<p>For <span class="math inline">\(p \gg n\)</span>, one has <span class="math inline">\(\lambda_{\min }(\hat{\Sigma})=0\)</span>.</p>
<p>When employing LASSO, we are usually only interested in estimators <span class="math inline">\(\hat{\beta}\)</span> whith non-zero entries at the components <span class="math inline">\(S\left(\beta^*\right)\)</span>. This means that in principle we only need injectivity of <span class="math inline">\(\hat{\Sigma}\)</span> on the set</p>
<p><span class="math display">\[
\tilde{C}=\left\{\beta \in \mathbb{R}^p: S(\beta)=S\left(\beta^*\right)\right\}=\left\{\beta \in \mathbb{R}^p:\left\|\beta_{S\left(\beta^*\right)^ c}\right\|_1=0\right\},
\]</span></p>
<p>or equivalently, <span class="math inline">\(\inf _{v \in \tilde{C}} \frac{v^T \hat{\Sigma} v}{\|v\|_2^2}=\inf _{v \in \tilde{C}} \frac{v^T \hat{\Sigma} v}{\left\|v_{S\left(\beta^*\right)}\right\|_2^2}&gt;0 .\)</span></p>
<blockquote class="def">
<p><strong>Definition. (Restricted eigenvalue property (REP))</strong> <em>We say that the restricted eigenvalue property (REP) is satisfied with <span class="math inline">\(\alpha&gt;0\)</span> if for</em></p>
<p><span class="math display">\[
C:=\left\{\beta \in \mathbb{R}^p:\left\|\beta_{S\left(\beta^*\right)^c}\right\|_1 \leq \alpha \left\|\beta_{S\left(\beta^*\right)}\right\|_1\right\}
\]</span></p>
<p><em>it holds that</em></p>
<p><span class="math display">\[
\Lambda_{\min }(\Sigma):=\inf _{v \in C} \frac{v^T \Sigma v}{\left\|v_{S\left(\beta^*\right)}\right\|_2^2}&gt;0,
\]</span></p>
</blockquote>
<blockquote class="thm">
<p><strong>Theorem.</strong> <em>Let <span class="math inline">\(\varepsilon \sim N\left(0, \sigma^2\right), X \sim N(0, \Sigma)\)</span> and <span class="math inline">\(\Sigma_{j j}=1(j=1, \ldots, p)\)</span>. Define <span class="math inline">\(s:=\# S\left(\beta^*\right)\)</span>. Then there exist universal constants <span class="math inline">\(c_1, c_2&gt;0\)</span> such that the condition</em></p>
<p><span class="math display">\[
n \geq c_1 \frac{\|\Sigma\|_2}{\Lambda_{\min }(\Sigma)^2} s \log (e p / s)
\]</span></p>
<p><em>implies: For each <span class="math inline">\(t \geq 0\)</span> and </em></p>
<p><span class="math display">\[
\lambda \geq \frac{6 \sqrt{2} \sigma}{\sqrt{n}} \sqrt{\log (p)+t},
\]</span></p>
<p><em>it holds that</em></p>
<p><span class="math display">\[
\mathbb{P}\left(R\left(\hat{m}_{n,\lambda}\right)-r\left(\beta^*\right)&gt;16 \lambda^2 \frac{s}{\Lambda_{\min }(\Sigma)}\right) \leq e^{-t}+2 p e^{-c_2 n} .
\]</span></p>
</blockquote>
<p>The upper bound for the convergence rate of the excess risk of the LASSO estimator is minimized for <span class="math inline">\(\lambda=6 \sqrt{2} \cdot \frac{\sigma}{\sqrt{n}} \sqrt{\log (p)}\)</span>. With that choice,</p>
<p><span class="math display">\[
16 \lambda^2 \frac{s}{\Lambda_{\min }(\Sigma)}=\frac{\text {c }}{\Lambda_{\min }(\Sigma)} \cdot \frac{\sigma^2 s}{n} \cdot \log (p)
\]</span></p>
<p>Interpretation: <span class="math inline">\(\hat{\beta}_\lambda\)</span> behaves like the LS estimator in a model with <span class="math inline">\(s\)</span> instead of <span class="math inline">\(p\)</span> dimensions.</p>
<p>The LASSO estimator <span class="math inline">\(\hat{\beta}_\lambda\)</span> has to ‘pay’ with a factor <span class="math inline">\(\log (p)\)</span> for the missing insight which components are non-zero. This is a rather small price to pay even if <span class="math inline">\(p\)</span> is large.</p>
<p>One can prove similar theoretical statements without the conditions <span class="math inline">\(\varepsilon \sim N\left(0, \sigma^2\right)\)</span> and <span class="math inline">\(X \sim N(0, \Sigma)\)</span> and still can preserve the small <span class="math inline">\(\log (p)\)</span> term.</p>
<p>Regarding the REP: The smallest eigenvalue <span class="math inline">\(\lambda_{\min }(\Sigma)\)</span> measures how strongly the components of <span class="math inline">\(X\)</span> are correlated. Note that a strong correlation of <span class="math inline">\(X\)</span> is a problem for estimation of <span class="math inline">\(\beta^*\)</span>, but not for the excess risk itself: In the extreme case <span class="math inline">\(X_1=X_2\)</span>, it is clear that <span class="math inline">\(\hat{\beta}\)</span> cannot distinguish the values of <span class="math inline">\(\beta_1^*\)</span> and <span class="math inline">\(\beta_2^*\)</span>, but it can still provide good predictions through <span class="math inline">\(X \hat{\beta}\)</span>. Unfortunately, the proof technique underlying the theorem transfers the estimation quality of <span class="math inline">\(\beta^*\)</span> to an upper bound of the excess risk, therefore this fact is not adequately represented in the result.</p>
<p>The assumption <span class="math inline">\(\Sigma_{j j}=1\)</span> is only to provide an easier result. In practice, this normalization can be obtained by standardizing <span class="math inline">\(X_1, \ldots, X_n\)</span> before computing the LASSO estimator (that is, center <span class="math inline">\(X_i\)</span> and divide by the empirical standard deviation).</p>
<blockquote class="thm">
<p><strong>Theorem.</strong> <em>We do not assume that the linear model holds. Assume that <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> have bounded support (bounded by <span class="math inline">\(B&gt;0\)</span>). Let </em></p>
<p><span class="math display">\[
\beta_*=\underset{\|\beta\|_1 \leq \eta}{\operatorname{argmin}}\ r(X\beta)
\]</span></p>
<p><em>Then for any <span class="math inline">\(\xi&gt;0\)</span>,</em></p>
<p><span class="math display">\[
\mathbb P\left (r(\widehat{\beta})- r\left(\beta_*\right)\geq\sqrt{\frac{2(\eta+1)^4 B^2}{n} \log \left(\frac{2p^2}{\xi}\right)}\right) \leq \xi  .
\]</span></p>
</blockquote>
<details>
<summary>
<strong>Proof.</strong>
</summary>
<p>Set <span class="math inline">\(Z=(Y, X)\)</span> and <span class="math inline">\(Z_i=\left(Y_i, X_i\right)\)</span>, <span class="math inline">\(\gamma = \gamma(\beta)=(-1, \beta)\)</span>. Then</p>
<p><span class="math display">\[
r(X\beta)=\mathbb{E}\left(Y-\beta^T X\right)^2=\gamma^T \Lambda \gamma
\]</span></p>
<p>where <span class="math inline">\(\Lambda=\mathbb{E}\left[Z Z^T\right]\)</span>. Note that <span class="math inline">\(\|\gamma\|_1=\|\beta\|_1+1\)</span>. Let <span class="math inline">\(\mathcal{B}=\left\{\beta:\|\beta\|_1 \leq \gamma\right\}\)</span>.</p>
<p><span class="math display">\[
\hat{R}_n( X\beta)=\frac{1}{n} \sum_{i=1}^n\left(Y_i-X_i^T \beta\right)^2=\gamma^T \widehat{\Lambda} \gamma
\]</span></p>
<p>where <span class="math inline">\(\widehat{\Lambda}=\frac{1}{n} \sum_{i=1}^n Z_i Z_i^T\)</span>. For any <span class="math inline">\(\beta \in \mathcal{B}\)</span>
<span class="math display">\[\begin{align*}
|\hat{R}_n(\mathbf X\beta)-r(X\beta)| &amp; =\left|\gamma^T(\widehat{\Lambda}-\Lambda) \gamma\right| \\
&amp; \leq \sum_{j, k}|\gamma_j||\gamma_k||\widehat{\Lambda}_{j k}-\Lambda_{jk}| \\
&amp; \leq(\eta+1)^2 \max_{jk} |\widehat{\Lambda}_{j k}-\Lambda_{jk}|
\end{align*}\]</span>
Note that <span class="math inline">\(|\Lambda_{jk}| \leq B^2\)</span>. By Hoeffding’s inequality,</p>
<p><span class="math display">\[
\mathbb{P}\left( |\widehat{\Lambda}_{j k}-\Lambda_{jk}|\geq \epsilon\right) \leq 2 e^{-2n \epsilon^2 / B^2}
\]</span></p>
<p>and so, by the union bound,</p>
<p><span class="math display">\[
\mathbb{P}\left(\max _{j, k}|\widehat{\Lambda}_{j k}-\Lambda_{j k}| \geq \epsilon\right) \leq 2 p^2 e^{-2n \epsilon^2 / B^2}=\xi,
\]</span></p>
<p>if we choose <span class="math inline">\(\epsilon=\sqrt{\frac{B^2} {2 n} \log \left(\frac{{2} p^2}{{ \xi}}\right)}\)</span>.
Hence, with probability <span class="math inline">\(1-\xi\)</span> (see slide 14, lecture 1),</p>
<p><span class="math display">\[
r({X \hat\beta}) - r\left(X\beta^*\right)\leq 2(\eta+1)^2 \varepsilon.
\]</span></p>
<p>as desired. <span class="math inline">\(\blacksquare\)</span></p>
</details>
<blockquote class="def">
<p><strong>Definition.</strong> <em>If <span class="math inline">\(P(S(\widehat{\beta})=S(\beta)) \rightarrow 1\)</span> we call <span class="math inline">\(\hat \beta\)</span> <strong>sparsistent</strong>.</em></p>
<p><em>We call <span class="math inline">\(\hat{\beta}\)</span> weakly <strong>sparsistent</strong> if, for every <span class="math inline">\(\beta\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span> </em></p>
<p><span class="math display">\[
P_\beta\left(I\left(\widehat{\beta}_j=1\right) \leq I\left(\beta_j=1\right) \text { for all } j\right) \rightarrow 1
\]</span></p>
</blockquote>
<p>In the above <span class="math inline">\(S(\cdot)\)</span> represent the covariates with non-zero covariates. Therefore we can interpret a sparsistent estimator as an estimator which for increasing information converges to choosing the correct explanatory variables, where the weak condition only ensure that we may choose the right covariates but at least not the wrong. Suppose that <span class="math inline">\(p\)</span> is fixed. Then the least squares estimator <span class="math inline">\(\widehat{\beta}_n\)</span> is minimax and satisfies</p>
<p><span class="math display">\[
\sup _\beta E_\beta\left(n\left\|\widehat{\beta}_n-\beta\right\|^2\right)=O(1) .
\]</span></p>
<p>But sparsistent estimators have larger risk:</p>
<blockquote class="thm">
<p><strong>Theorem.</strong> <em>We don’t assume the linear model. Suppose that the following condiitons hold:</em></p>
<ul>
<li><em><span class="math inline">\(p\)</span> is fixed.</em></li>
<li><em>The covariariates are nonstochastic and <span class="math inline">\(n^{-1} \mathbf{X}^T \mathbf{X} \rightarrow \Sigma\)</span> for some positive definite matrix <span class="math inline">\(\Sigma\)</span>.</em></li>
<li><em>The errors <span class="math inline">\(\epsilon_i\)</span> are independent with mean 0, finite variance <span class="math inline">\(\sigma^2\)</span> and have a density <span class="math inline">\(f\)</span> satisfying </em>
<span class="math display">\[
  0&lt;\int\left(\frac{f^{\prime}(x)}{f(x)}\right)^2 f(x) d x&lt;\infty
  \]</span></li>
</ul>
<p><em>If <span class="math inline">\(\widehat{\beta}\)</span> is weakly sparsistent, then</em></p>
<p><span class="math display">\[
\sup _\beta \mathbb E_\beta\left(n\left\|\widehat{\beta}_n-\beta\right\|^2\right) \rightarrow \infty .
\]</span></p>
<p><em>More generally, if <span class="math inline">\(\ell\)</span> is any loss function <span class="math inline">\(\ell: \mathbb R \mapsto \mathbb R_{\geq 0}\)</span>.then </em></p>
<p><span class="math display">\[
\sup _\beta  \mathbb E_\beta\left(\ell\left(n^{1 / 2}\left(\widehat{\beta}_n-\beta\right)\right)\right) \rightarrow \sup _s \ell(s) .
\]</span></p>
</blockquote>
<details>
<summary>
<strong>Proof.</strong>
</summary>
<p>Choose any <span class="math inline">\(s \in \mathbb{R}^d\)</span> and let <span class="math inline">\(\beta_n=-s / \sqrt{n}\)</span>. Then,
<span class="math display">\[\begin{align*}
\sup _\beta \mathbb E_\beta\left(\ell\left(n^{1 / 2}(\widehat{\beta}-\beta)\right)\right. &amp; \geq \mathbb E_{\beta_n}\left(\ell\left(n^{1 / 2}(\widehat{\beta}-\beta)\right) \geq \mathbb E_{\beta_n}\left(\ell\left(n^{1 / 2}(\widehat{\beta}-\beta)\right) I(\widehat{\beta}=0)\right)\right. \\
&amp; =\ell\left(-\sqrt{n} \beta_n\right) \mathbb P_{\beta_n}(\widehat{\beta}=0)=\ell(s) P_{\beta_n}(\widehat{\beta}=0) .
\end{align*}\]</span>
Now, <span class="math inline">\(\mathbb P_0(\widehat{\beta}=0) \rightarrow 1\)</span> by assumption. It can be shown (via contiguity) that we also have <span class="math inline">\(\mathbb P_{\beta_n}(\widehat{\beta}=0) \rightarrow 1 .\)</span> Hence, with probability tending to 1,</p>
<p><span class="math display">\[
\sup _\beta E_\beta\left(\ell\left(n^{1 / 2}(\widehat{\beta}-\beta)\right) \geq \ell(s) .\right.
\]</span></p>
<p>Since <span class="math inline">\(s\)</span> was arbitrary the result follows. <span class="math inline">\(\blacksquare\)</span></p>
</details>
</div>
<div id="conclusion" class="section level3 hasAnchor" number="9.3.4">
<h3><span class="header-section-number">9.3.4</span> Conclusion<a href="linear-models.html#conclusion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Lasso and Ridge regression aim for different things. Ridge regression reduces variance of the estimator by restricting the function space. Heuristically, the smaller <span class="math inline">\(||\beta^\ast||_2\)</span> the more helpful is ridge regression. Lasso is useful in sparse setting, i.e, if one wishes to eliminate components/features.</p>
<p><strong>Example.</strong> Assume that <span class="math inline">\(\rm{corr}(X_{1},X_2)=1\)</span> and <span class="math inline">\(Y=0.5X_1+0.5X_2\)</span>. While Lasso will probably estimate <span class="math inline">\(\beta_1=1, \beta_2=0\)</span>, Ridge will probably estimate correctly <span class="math inline">\(\beta_1=0.5, \beta_2=0.5\)</span>.</p>
<blockquote class="def">
<p><strong>Definition. (Elastic net)</strong> <em>For <span class="math inline">\(\lambda&gt;0, \alpha \in (0,1)\)</span>, and <span class="math inline">\(J^{elastic.net}(\beta)= \sum_{j=1}^p \alpha |\beta_j| + (1-\alpha) \beta_j^2\)</span>, we call</em>
<span class="math display">\[\begin{align*}
\hat{\beta}_\lambda^{\text {elastic.net }} &amp; \in \underset{\beta \in \mathbb{R}^d}{\arg \min }\left\{\hat{R}_n(\beta)+J^{elastic.net}_\lambda(\beta)\right\} \\
\end{align*}\]</span>
<em><strong>elastic net</strong> estimator.</em></p>
</blockquote>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="training-validating-and-testing.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="nonparametric-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["theory.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
