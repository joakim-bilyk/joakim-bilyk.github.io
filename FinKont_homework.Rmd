---
title: "Homework (FinKont)"
author: "Joakim Bilyk"
date: "`r Sys.Date()`"
header-includes:
   - \usepackage{wrapfig}
   - \usepackage{graphics}
output:
  html_document:
    toc: no
    code_folding: hide
  pdf_document:
    toc: yes
---

```{r, setup,include=FALSE}
library(knitr)
if (knitr::is_latex_output()) {
  knit_hooks$set(wrapf = function(before, options, envir) {
  if (!before) {
    output <- vector(mode = "character", length = options$fig.num + 1)

    for (i in 1:options$fig.num) {
      output[i] <- sprintf("\\includegraphics{%s}", fig_path(number = i))
    }

    output[i+1] <- "\\end{wrapfigure}"
    output <- c("\\begin{wrapfigure}{R}{0.5\\textwidth}",output)
    if (length(output)>= 3) {
      return(paste(output, collapse = ""))
    }
  }
})
  knitr::opts_chunk$set(
    fig.show = 'hide',
    echo = FALSE
  )
} else {
  knitr::knit_hooks$set(wrapf = function(before, options, envir) {})
  knitr::opts_chunk$set(
    out.extra = 'style="float:right; padding:10px"',
    out.width= "50%"
  )
}
```

```{r, include=FALSE, results = 'hide'}
library(ggplot2)
library(dplyr)
#rmarkdown::render(input = "FinKont_homework.Rmd", output_format = "pdf_document")
```


# Introduction

# Weeks {.tabset}

## Week 1

### Table of Contents

  * [Brownian motion (Chapter 4.1)](#the-brownian-motion)
  * [Conditional expectation (Appendix B.5)](#conditional-expectation)
  * [Filtration (Appendix B.3 and Chapter 4.2)](#filtrations)
  * [Martingales (Appendix C.1 and Chapter 4.4)](#martingales)
  * [Introduction (Chapter 1)](#discrete-time-models)
  * [Discrete time models (Chapter 2 and 3)](#discrete-time-models)

  * [Exercises](#exercises-week-1)

### Theory

This week revolves around the theory of the Brownian motion and martingale processes. Other main topics are the binomial model and an introduction to financial derivatives. Financial derivatives is contingent on the outcome of a stochastic process at some future time $t=T$ and often is a function $\Phi$ of some assets price $S_t$. As such the derivative will give a stochastic payout, at time $t=T$ of the size $X_T=\Phi(S_T)$. Naturally we want to say something about the *fair* price of the derivative in the form of

$$\Pi_t(X_T)=\mathbb{E}\left[\Phi(S_T)\ \vert\ \mathcal{F}_t\right],$$

where $\mathcal{F}_t\subset\mathcal{F}$ is the available information at time $t$. We will by defualt intepret the times $t=0$ as *today* and $t=T$ as *tomorrow*. This indeed require some fundamental understanding of the behaviour of the asset price $S_t$. This lead us over to discussing the process in center of the *Black-Scholes* model: the Brownian motion.

&nbsp;

#### The Brownian motion

<blockquote class = "def">
**Definition 4.1.** *(Brownian motion)* A stochastic process $W$ is called a **Brownian motion** or **Wiener process** if the following conditions hold

 1. $W_0=0$.
 2. The process $W$ has independent increments, i.e. if $r<s\le t< u$ then $W_u-W_t$ and $W_s-W_r$ are independent random variables.
 3. For $s<t$ the random variable $W_t-W_s$ has the Gaussian distribution $\mathcal{N}(0,t-s)$.
 4. $W$ has continuous trajectories i.e. $s\mapsto W(s;\omega)$ i continuous for all $\omega \in\Omega$.
</blockquote>

```{r}
#Example of trajectory for BM
set.seed(1)
t <- 0:1000
N <- rnorm(
  n = length(t)-1, #initial value = 0
  mean = 0, #incements mean = 0
  sd = sqrt(t[2:length(t)] - t[1:(length(t)-1)]) #increment sd = sqrt(t-s)
)
W <- c(0,cumsum(N))
```
```{r,echo=FALSE,include=TRUE,wrapf = TRUE}
data.frame(t = t, W = W) %>%
  ggplot() +
  geom_line(aes(x=t,y=W)) +
  labs(title = "Realisation of a Brownian motion") +
  theme_bw() +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 12),
        title = element_text(size = 16),
        plot.caption  = element_text(size = 10))
```

As one can see from the simulated sample path on the right, the Brownian motion is rather irratic. In fact, the process varies infinitely on any interval with length greater than 0. This gives some of the characteristics of the process including that: $W$ is continuous and $W$ is non-differential everywhere. This irratic behaviour is summed up in the theorem.


<blockquote class = "thm">

**Theorem 4.2.** A Brownian motions trajectory $t\mapsto W_t$ is with probability one nowhere differential, and it has locally infinite total variation.

</blockquote>

This may seem not that horrifying since we can observe the process at any time and conclude an increment $W_{t+\Delta t}-W_t$ for any $\Delta t>0$ but any integral constructed with $W_t$ as integrator becomes nonsensible. We will be studying processes on the form

$$S_{t+\Delta t}-S_t=\mu(t,S_t)\Delta t+\sigma(t,S_t)\Delta W_t,\hspace{20pt}\Delta W_t=W_{t+\Delta t}-W_t.$$

where $W_t$ is a standard Brownian motion and $\mu(t,S_t)$ is locally deterministic (velocity), that is $\mu(t,S_t)$ is deterministic on a small time interval. One could consider the dynamics of the process $S_t$ by studying the equation below as $\Delta t\to 0_+$

$$\frac{S_{t+\Delta t}-S_t}{\Delta t}=\mu(t,S_t)+\sigma(t,S_t)\frac{W_{t+\Delta t}-W_t}{\Delta t}.$$

The limit however is impossible to determine as $W_t$ is non-differentiable and as such $dS_t$ is not well-defined. From LivStok we know that the dynamics of $S_t$ is given by letting $\Delta t$ tend to 0 without dividing by it, that is

$$
dS_t=\mu(t,S_t)\ dt+\sigma(t,S_t)\ dW_t.
$$

Giving that $S_0$ is observable we could intepret the dynamics on the integral form

$$
S_t=S_0+\int_0^t\mu(s,S_s)\ ds+\int_0^t\sigma(s,S_s)\ dW_s,
$$

where the above integrals is Riemann-Stieltjes integral. This is however still at dead-end, since from theorem 4.2 we know that $W_t$ has unbounded variation on any interval. So **we cannot define $S_t$ for each $W$-trajectory seperately** we will despite this define another integral (the Ito integral) that in some other sense give a global solution to this integral. To this we will be considering a $L^2$-definition.

&nbsp;

#### Conditional expectation

The theory of conditional expectation is well-known from courses on the bachelor. Because of this we will only summarise the most important results.

We consider a background space $(\Omega,\mathcal{F},P)$ and a sub-sigma algebra $\mathcal{G}\subseteq \mathcal{F}$. We assume that some stochastic variable is $\mathcal{F}$-measurable, that is the mapping $X : (\Omega,\mathcal{F},P) \to (\mathbb{R},\mathbb{B},m)$ is $\mathcal{F}-\mathbb{B}$-measurable i.e. $\forall B\in\mathbb{B} : \{X\in B\}\in\mathcal{F}$. For some random variable $Z$ defined on the subspace $(\Omega,\mathcal{G},P)$, we say that $Z$ is the conditional expectation of $X$ given $\mathcal{G}$ if

$$
\forall G\in\mathcal{G} : \int_G Z(\omega)\ dP(\omega)=\int_G X(\omega)\ dP(\omega).
$$

This fact is summed up in the definition below.

<blockquote class = "def">

**Definition B.27.** *(Conditional expectation)* Let $(\Omega,\mathcal{F},P)$ be a probability space and $X$ a random variable in $L^1(\Omega,\mathcal{F},P)$ ($\vert X\vert$ is integrable). Let furthermore $\mathcal{G}$ be a sigma-algebra such that $\mathcal{G}\subseteq \mathcal{F}$. If $Z$ is a random variable with the properties that:

  i. $Z$ is $\mathcal{G}$-measurable.
  ii. For every $G\in\mathcal{G}$ it holds that
  $$\int_G Z(\omega)\ dP(\omega)=\int_G X(\omega)\ dP(\omega).$$

Then we say that $Z$ is the *conditional expectation of $X$ given the sigma-algebra $\mathcal{G}$*. In that case we denote $Z$ by the symbol $E[X\ \vert\ \mathcal{G}]$.

</blockquote>

We see that from the above it always holds that $X$ satisfies (ii). It does not, however, always hold that $X$ is $\mathcal{G}$-measurable. Given this fact it is not trivial that a random variable $E[X\ \vert\ \mathcal{G}]$ even exists. This nontriviality is fortunatly resolved by the Radon-Nikodym theorem.

<blockquote class = "thm">

**Theorem B.28.** *(Existance and uniqueness of Conditional expectation)* Let $(\Omega,\mathcal{F},P)$, $X$ and $\mathcal{G}$ be given as in the definition above. Then the following holds:

  * There will always exist a random variable $Z$ satisfying conditions (i)-(ii) above.
  * The variable $Z$ is unique, i.e. if both $Y$ and $Z$ satisfy (i)-(ii) then $Y=Z$ $P$-a.s.

</blockquote>

This result ensures that we may condition on any sigma-algebra for instance $\mathcal{G}=\sigma(Y)$ in that case we (pure notation) write

$$
E[X\ \vert\ \sigma(Y)]=E[X\ \vert\ Y],\hspace{20pt}\sigma(Y)=\sigma\left(\left\{ Y\in A,\ A\in\mathbb{B}\right\}\right).
$$

In the above $\sigma(Y)$ is simply the smallest sigma-algebra containing all the pre-images of $Y$, that is the smallest sigma-algebra making $Y$ measurable! Giving this foundation there are a few properties conditional expectation have which is rather useful (for instance the tower property).

Below we assume: Let $(\Omega,\mathcal{F},P)$ be a probability space and $X,Y$ be random variables in $L^1(\Omega,\mathcal{F},P)$.

<blockquote class = "prop">

**Proposition B.29.** *(Monotinicity/Linearity of Conditional expectation)* The following holds:

$$X\le Y\ \Rightarrow\ E[X\ \vert\ \mathcal{G}]\le E[Y\ \vert\ \mathcal{G}],\hspace{20pt}P-\text{a.s.}$$
$$E[\alpha X + \beta Y\ \vert\ \mathcal{G}]=\alpha E[X\ \vert\ \mathcal{G}]+ \beta E[Y\ \vert\ \mathcal{G}],\hspace{20pt}\forall \alpha,\beta\in\mathbb{R}.$$

</blockquote>

<blockquote class = "prop">

**Proposition B.30.** *(Tower property)* Assume that it holds that $\mathcal{H}\subseteq\mathcal{G}\subseteq\mathcal{F}$. Then the following hold:

$$E[E[X\vert \mathcal{G}]\vert\mathcal{H}]=E[X\vert \mathcal{H}],$$
$$E[X]=E[E[X\vert \mathcal{G}]].$$

</blockquote>

<blockquote class = "prop">

**Proposition B.31.** Assume $X$ is $\mathcal{G}$ and that both $X,Y$ and $XY$ are in $L^1$ (only assuming $Y$ is $\mathcal{F}$-measurable), then

$$E[X\vert\mathcal{G}]=X,\hspace{20pt}P-\text{a.s.}$$
$$E[XY\vert\mathcal{G}]=XE[Y\vert\mathcal{G}],\hspace{20pt}P-\text{a.s.}$$

</blockquote>

<blockquote class = "prop">

**Proposition B.32.** *(Jensen inequality)* Let $f:\mathbb{R}\to\mathbb{R}$ be a convex (measurable) function and assume $f(X)$ is in $L^1$. Then

$$f(E[X\vert\mathcal{G}])\le E[f(X)\vert\mathcal{G}],\hspace{20pt}P-\text{a.s.}$$

</blockquote>

&nbsp;

#### Filtrations

Let $(\Omega,\mathcal{F},P)$ be a probability space. We define a filtration as an increasing famility of sub-sigma-algebras in the following definition.

<blockquote class = "def">

**Definition B.16.** *(Filtration)* Let $\mathbf{F}=(\mathcal{F}_t)_{t\ge 0}$ be an time indexed family of sub-sigma-algebras such that $F_s\subseteq F_t$ for $s\le t$ and $\mathcal{F}_t\subseteq \mathcal{F}$ for all $t\ge 0$. We may given this filtration define $\mathcal{F}_\infty$ as $\sigma\left(\bigcup_{t\ge 0}\mathcal{F}_t\right)$.

</blockquote>

Filtrations is widely used in stochastic processes, as they allow for the concept of knowledge/information. This is useful when considering mean-values of future states but in an increasing information setting. For this we introduce the term adapted processes.

<blockquote class = "def">

**Definition B.17.** *(Adapted process)* Let $(\mathcal{F}_t)_{t\ge 0}$ be a filtration on the probability space $(\mathcal{F}_t)_{t\ge 0}$. Furthermore, let $(X_t)_{t\ge 0}$ be a stochastic process on the same space. We say that $X_t$ is adapted to the filtration $\mathbf{F}$ if

$$X_t\ \text{ is }\ \mathcal{F}_t-\text{measurable},\hspace{20pt}\forall t\ge 0.$$

</blockquote>

Obviously, we may introduce the **natural filtration** $\mathcal{F}^X_t$ given by the tragetory of the process $X_t$:

$$\mathcal{F}^X_t=\sigma(\{X_s,\ s\le t\}).$$

Indeed, $X_t$ is adapted to this filtration.

&nbsp;

#### Martingales

<blockquote class = "def">

**Definition C.1.** Let $M_t$ be a stochastic process defined on a background space $(\Omega,\mathcal{F},P)$. Let $(\mathcal{F}_t)_{t\ge 0}$ be a filtration. If $M_t$ is adapted to the filtration $\mathcal{F}_t$, $E\vert M_t\vert <\infty$ and

$$E[M_t\vert \mathcal{F}_s]=M_s,\hspace{20pt}P-\text{a.s.}$$

holds for any $t>s$ we say that $M_t$ is a martingale ($\mathbf{F}$-martingale). If the above has $\ge$ or $\le$ we say that $M_t$ is either a **submartingale** or **supermartingale** respectively.

</blockquote>

Naturally, this defintions may easily be extended to discrete models and we have the trivial equality:

$$E[M_t-M_s\ \vert\ \mathcal{F}_s]=0.$$

Martingales is useful, when proofing probalistic statements as the posses tractable properties. A useful technique often include the construction of the martingale

$$M_t=E[X\ \vert\ \mathcal{F}_t].$$

&nbsp;

#### Discrete time models

#### One-period time models

The study of this course is the **European call** option (and *put* option). This financial derivative is an agreement between two parties where the holder of the option has the right to *"exercise"* the derivative, at a future time $t=T$. Exercising means buying an asset at a certain agreed opon price-strike $K$. In the case of the put-option: the holder has the right (but not obligation) to sell the asset at the strike price $K$. As such the derivative has the payoff

$$\text{Call}\ \text{option:}\hspace{10pt}\Phi(S_T)=(S_T-K)^+,\hspace{20pt}\text{Put}\ \text{option:}\hspace{10pt}\Phi(S_T)=(K-S_T)^+.$$

Our objective is to understand when an arbitrage exist and to find the fair price of these derivative. The strategy in pricing is finding a replicating portfolio with the same payoff as the option (with probability one) and then price the derivative accordingly.

##### Model description

In the one-period model we consider the simplest possible market. We have two distinct times $t=0$ (today) and $t=1$ (tomorrow) and we may buy any portfolio as a mixture of bonds and one stock. We denote the bonds price by $B_t$ and the stocks price by $S_t$ and we assume the following:

$$
B_0=1,\ B_1=1+R,\hspace{20pt}S_0=s,\ S_1=\left\{\begin{matrix}s\cdot u, & with\ probability\ p_u.\\s\cdot d, & with\ probability\ p_d.\end{matrix}\right.
$$

We may introduce $Z$ as the random variable

$$
Z=u\cdot (I)+d\cdot (1-I),
$$

for an bernoulli variable $I$ with succes probability $p_u$. Naturally, we assume $d\le (1+R)\le u$ (this is imperative to ensure no arbitrage as we will see).

##### Portfolios and arbirtage

We study any portfolio on the $(B,S)$ market as a vector $h=(x,y)$ where $x$ is the amount of bonds and $y$ is the amount of stock held in the portfolio. Notice that we allow for shorting, that is $x<0$ or $y<0$. As such, we have that $h\in \mathbb{R}^2$. In this we have made some unrealistic, but attractable assumptions included in the assumptions:

  * We allow short positions and fractional holding, i.e. $h\in \mathbb{R}^2$,
  * We assume no spread between ask and bids,
  * No transaction costs and
  * A completely liquid market i.e. we may borrow and buy as much stock and bonds as wanted.

Given that we have chosen a portfolio $h$ we may introduce the value process.

<blockquote class = "def">

**Definition 2.1.** The **value process** of the porfolio $h\in\mathbb{R}^2$ is the stochastic process

$$V^h_t=xB_t+yS_t,\ t=0,1.$$

</blockquote>

Given this notation we may define what an arbitrage is.

<blockquote class = "def">

**Definition 2.2.** An **arbitrage** is a portfolio $h$ with the properties: 1) $V^h_0=0$, 2) $P(V^h_1\ge 0)=1$ and 3) $P(V^h_1>0)>0$.

</blockquote>

That is $h$ is an deterministic money-machine where we at least never loose any money. Granted the bonds give a determinictic non-negative return, but an arbitrage does not require any money out of pocket. With the notion of an arbitrage we will show the first proposition regarding the choice of $R,u,d$ as defined above.

<blockquote class = "prop">

**Proposition 2.3.** The one-period binomial model is arbitrage free if and only if the following inequality hold:

$$d\le (1+R)\le u.\tag{2.1}$$

</blockquote>

<details>
<summary>**Proof.**</summary>

The statement is proofed by contradiction. Assume that $d>1+R$ holds. Then by definition $u>d>1+R$. Notice that any portfolio satisfying $V_0^h=0$ must satisfy

$$0=xB_0+yS_0=x+ys\iff x=-ys$$

That is for some choice $y$ the only arbitrage candidate is the portfolio $h=(-ys,y)$. Calculating the value at time $t=1$ we have

$$V_1^h=-ys\cdot(1+R)+y\cdot s\cdot Z=ys(Z-1-R)$$

However since $Z\ge d$ we have $Z-(1+R)\ge 0$ and therefore an arbitrage (for $y>0$). The other inequality $1+R>u$ follows analog steps. Simply choose some $y<0$ and the result follows. $\blacksquare$

</details>

From inequality (2.1) we see that since $1+R$ is between $u$ and $d$ we may find a pair $q_d,q_u\ge 0$ with $q_d+q_u=1$ such that

$$1+R=q_u\cdot u+q_d\cdot d.$$

This yields the important risk neutral valuation formula as summed op in the following definition

<blockquote class = "def">

**Definition 2.4.** A probability measure $Q$ is called a **martingale meausre** if the following condition holds:

$$S_0=\frac{1}{1+R}E^Q[S_1].$$

</blockquote>

The above measure $Q$ is the measure $Q(Z=d)=q_d$ and $Q(Z=u)=q_u$ for the binomial model. This does in fact yield the risk neautral valuation formula:

\begin{align*}
S_0&=\frac{1}{1+R}E^Q[S_1]=\frac{1}{1+R}(Q(Z=d)\cdot d\cdot s+Q(Z=u)\cdot u\cdot s)\\
&=s\frac{1}{1+R}(q_d\cdot d+q_u\cdot u)=s,
\end{align*}

where we simply use $1+R=q_d\cdot d+q_u\cdot u$. We call this the risk neautral valuation formula because it in some sense gives an expected discounted value of the future stock price. We end this endavour with reformulating the arbitrage proposition and determining the values of the $Q$-measure.

<blockquote class = "prop">

**Proposition 2.5.** The one-period binomial model is arbitrage free if and only if there exists a martingale measure $Q$.

</blockquote>

<blockquote class = "prop">

**Proposition 2.6.** The one-period binomial model has martingale probabilities given by:

$$\left\{\begin{matrix}q_u=\frac{(1+R)-d}{u-d},\\ q_u=\frac{u-(1+R)}{u-d}.\end{matrix}\right.$$

</blockquote>

##### Contingent Claims

This chapter revolves around the financial derivative and we start by stating the definition of the financial derivative.

<blockquote class = "def">

**Definition 2.7.** A **contingent claim** (financial derivative) is *any* stochastic variable $X$ of the form $\Phi(Z)$, where $Z$ is the stochastic varible driving the stock price process.

</blockquote>

We may also call the function $\Phi$ the **contract function** as it states how the contract is resolved once the stochastic variable $Z$ has been realised. Our objective is now to study, what a buyer of said contract would have to pay at any given time $t$. We call the fair price of $X$ at time $t$: $\Pi_t[X]$. As such it is easy to see that the fair price at the time of maturity $T$ is simply the payout $X$ i.e. $\Pi_T[X]=X$. Our strategy is to find a replicating portfolio $h$ and determine the price of said portfolio.

<blockquote class = "def">

**Definition 2.8.** A contingent claim $X$ can be **replicated**, or said to be **reachable** if there exist a portfolio $h$ such that

$$
V_1^h=X,
$$

with probability one. In that case, we say that the portfolio $h$ is a **hedging** portfolio or a **replicationg** portfolio. If all claims can be replicated we say that the market is **complete**.

</blockquote>

Our pricing strategy is then to determine the value process of the replicating portfolio and then by the first pricing principle below we say that the price is imply the value of the replicating portfolio.

**Pricing principle 1.** If a clain $X$ is reachable with replicating portfolio $h$, then the only reasonable price process for $X$ is given by

$$
\Pi_t[X]=V_t^h.
$$

Notice, that this assumes that a replicating portfolio exist and even so we have a uniqueness statement to solve. We end this section by writing two important results.

<blockquote class = "prop">

**Proposition 2.9.** Suppose that a claim $X$ is reachable with replicating portfolio $h$. Then any price at time $t\ge 0$ of the claim $X$ other than the value process of $h$ will lead to an arbitrage on the extended market $(B,S,X)$.

</blockquote>

<blockquote class = "prop">

**Proposition 2.10.** If the one-period binomial model is free of arbitrage, then it is also complete.

</blockquote>

The hedging portfolio in the one-period binomial model is given by the portfolio $(x,y)$ below

$$
x=\frac{1}{1+R}\cdot\frac{u\Phi(d)-d\Phi(u)}{u-d},\hspace{20pt}y=\frac{1}{s}\cdot\frac{\Phi(u)-\Phi(d)}{u-d}.
$$

##### Risk Neutral Valuation

We see that since the one-period model is complete we can price any contingent claim and we see that

\begin{align*}
\Pi_0[X]&=\frac{1}{1+R}\cdot\frac{u\Phi(d)-d\Phi(u)}{u-d}+s\frac{1}{s}\cdot\frac{\Phi(u)-\Phi(d)}{u-d}\\
&=\frac{1}{1+R}\left\{\frac{u\Phi(d)-d\Phi(u)}{u-d}+(1+R)\frac{\Phi(u)-\Phi(d)}{u-d}\right\}\\
&=\frac{1}{1+R}\left\{\frac{(1+R)-d}{u-d}\Phi(u)+\frac{u-(1+R)}{u-d}\Phi(d)\right\}\\
&=\frac{1}{1+R}E^Q[X].
\end{align*}

i.e. the price at time $t=0$ should simply be the expected discounted payout according to the martingale measure. This leads to the important pricing proposition:

<blockquote class = "prop">

**Proposition 2.11.** If the one-period binomial model is free of arbitrage, then the arbitrage free price of a contingent claim $X$ is given by

$$
\Pi_0[X]=\frac{1}{1+R}E^Q[X].\tag{2.4}
$$

Here the martingale measure $Q$ is uniquely determined by the relation

$$
S_0=\frac{1}{1+R}E^Q[S_1],\tag{2.5}
$$

and the explicit expressions for $q_u$ and $q_d$ are given in proposition 2.6. Furthermore the claim $X$ can be replicated using the portfolio

\begin{align*}
x&=\frac{1}{1+R}\cdot\frac{u\Phi(d)-d\Phi(u)}{u-d},\tag{2.6}\\
y&=\frac{1}{s}\cdot\frac{\Phi(u)-\Phi(d)}{u-d}.\tag{2.7}
\end{align*}

</blockquote>

#### Multi-period model

The one-period binomial model can easily be extended to a multi-period model, by assuming that the bond and stock pricess evolve by the processes:

$$
t\ge1:\ B_t=(1+R)B_{t-1}\hspace{20pt}\text{and}\hspace{20pt}B_0=1,
$$

$$
t\ge1:\ S_t=Z_{t-1}S_{t-1}\hspace{20pt}\text{and}\hspace{20pt}S_0=s,
$$

where we obviously have that $B_t=(1+R)^t$ for $t\ge 0$. In the above $Z_t$ is $u$ with probability $p_u$ and $d$ with probability $p_d$. In this context, we need to define a portfolio in terms of a strategy.

<blockquote class = "def">

**Definition 2.13.** A **portfolio strategy** is a stochastic process on $\{1,...,T\}$

$$
h=\left\{h_t=(x_t,y_t);\ t=1,...,T\right\}
$$

such that $h_t$ is a function of $S_0,S_1,...,S_{t-1}$. For a given portfolio strategy $h$ we set $h_0=h_1$ by convention. The associated **value process** corresponding to the portfolio $h$ is defined by

$$
V_t^h=x_t(1+R)+y_tS_t.
$$

</blockquote>

Given this notation we may define what an arbitrage is, but first we introduce the notion of a self-financing portfolio. A self-financing portfolio in an intuative sense is a portfolio that is not withdrawn from or deposited into.

<blockquote class = "def">

**Definition 2.14.** A portfolio strategy $h$ is said to be **self-financing** if the following condition holds for all $t=0,...,T-1$:

$$
x_t(1+R)+y_tS_t=x_{t+1}+y_{t+1}S_t.
$$

</blockquote>

The above equation says that the portfolio purchased at time $t$ and helt until $t+1$ $(x_{t+1},y_{t+1})$ can only be financed by the market value of the portfolio held from $[t-1,t)$ i.e. $(x_{t},y_{t})$. We now define an arbitrage.

<blockquote class = "def">

**Definition 2.15.** An **arbitrage** is a self-financing portfolio $h$ with the properties: 1) $V^h_0=0$, 2) $P(V^h_T\ge 0)=1$ and 3) $P(V^h_T>0)>0$.

</blockquote>

The multiperiod binomial model has an just like the oneperiod model a result regarding when an arbitrage exists.

<blockquote class = "lem">

**Lemma 2.16.** If $d\le (1+R)\le u$ then the multiperiod model is arbitrage-free.

</blockquote>

As one can see, the multiperiod model is rather similar to the one period model. We wil in the following summarise equivalent statements for the multiperiod model as the ones in the oneperiod model. 

<blockquote class = "def">

**Definition 2.17.** The martingale probabilities $q_u$ and $q_d$ are defined as the probabilities for which the relation below holds.

$$
s=\frac{1}{1+R}E^Q[S_{t+1}\ \vert\ S_t].
$$

</blockquote>

<blockquote class = "prop">

**Proposition 2.18.** The martingale probabilities $q_u$ and $q_d$ are given by

$$
\left\{\begin{matrix}q_u=\frac{(1+R)-d}{u-d},\\ q_u=\frac{u-(1+R)}{u-d}.\end{matrix}\right.
$$

</blockquote>

<blockquote class = "def">

**Definition 2.19.** A **contingent claim** is a stochastic variable $X$ of the form

$$
X=\Phi(S_T),
$$

where the **contract function** $\mathbf{\Phi}$ is some given real valued function.

</blockquote>

<blockquote class = "def">

**Definition 2.20.** A given contingent claim $X$ is said to be **reachable** if there exists a self-financing portfolio $h$ such that

$$
V_T^h=X,
$$

with probability one. In that case we say that the portfolio $h$ is a **hedging** portfolio or a **replicating** portfolio. If all claims can be replicated we say that the market is *(dynamically)* **complete**.

</blockquote>

**Pricing principle 2.** If a claim $X$ is reachable with replicating portfolio $h$, then the only reasonable price process for $X$ os given by

$$
\Pi_t[X]=V_t^h,\ t=0,1,...,T.
$$

<blockquote class = "prop">

**Proposition 2.21.** Assume $X$ is reachable by $h$, then any price other than $V_t^h$ for some $t\ge 0$ leads to an arbitrage opportunity.

</blockquote>

<blockquote class = "prop">

**Proposition 2.22.** The multiperiod model is complete, i.e. every claim can be replicated by a self-financing portfolio.

</blockquote>

<blockquote class = "prop">

**Proposition 2.24.** **(Binomial algorithm)** Consider a $T$-claim $X=\Phi(S_T)$. Then this claim can be replicated using af self-financing portfolio. If $V_t(k)$ denotes the value of the portfolio at the node $(t,k)$ ($k$ referring to $k$ amount of up-moves for the stock), then $V_t(k)$ can be computed recursively by the scheme

$$
\left\{\begin{matrix}V_t(k)=\frac{1}{1+R}\left\{q_uV_{t+1}(k+1)+q_dV_{t+1}(k)\right\},\\ V_T(k)=\Phi(su^kd^{T-k}).\end{matrix}\right.
$$

where the martingale probabilities $q_u$ and $q_d$ are given by

$$
\left\{\begin{matrix}q_u=\frac{(1+R)-d}{u-d},\\ q_u=\frac{u-(1+R)}{u-d}.\end{matrix}\right.
$$

With the notation as above, the hedging portfolio is given by

$$
\left\{\begin{matrix}x_t(k)=\frac{1}{1+R}\cdot\frac{uV_t(k)-dV_t(k+1)}{u-d},\\ y_t(k)=\frac{1}{S_{t-1}}\cdot\frac{V_t(k+1)-V_t(k)}{u-d}.\end{matrix}\right.
$$

In particular, the arbitrage free price of the claim at $t=0$ is given by $V_0(0)$.

</blockquote>

<details>
<summary>**Example.**</summary>

```{tikz,echo=FALSE}
\tikzstyle{level 1}=[level distance=4cm, sibling distance=3.5cm,->]
\tikzstyle{level 2}=[level distance=4cm, sibling distance=2cm,->]

\tikzstyle{bag} = [text width=2em, text centered]
\tikzstyle{end} = []

\begin{tikzpicture}[grow=right, sloped]
\node[bag] {100}
    child {
        node[bag] {90}        
            child {
                node[end, label=right:
                    {81}] {}
                edge from parent
                node[above] {}
                node[below]  {$p_d^2$}
            }
            child {
                node[end, label=right:
                    {99}] {}
                edge from parent
                node[above] {}
                node[below]  {$p_dp_u$}
            }
            edge from parent 
            node[above] {}
            node[below]  {$p_d$}
    }
    child {
        node[bag] {110}        
        child {
                node[end, label=right:
                    {99}] {}
                edge from parent
                node[above] {$p_dp_u$}
                node[below]  {}
            }
            child {
                node[end, label=right:
                    {121}] {}
                edge from parent
                node[above] {$p_u^2$}
                node[below]  {}
            }
        edge from parent         
            node[above] {$p_u$}
            node[below]  {}
    };
\end{tikzpicture}
```

Consider $R=0.04$, $s=100$, $u=1.1$, $d=0.9$, $p_u=0.6$ and $p_d=0.4$. We consider a model of length $T=2$ and we want to evaluate the price of the european call option with srike $K=90$ that is the contingent claim

$$
X=(S_T-K)^+,\hspace{20pt}\Phi(s)=(s-K)^+.
$$

For each time $t$ we know the replicating portfolio, if we know the payoff the following period. Therefore we start from the leaves of the tree and work towards the root. Since the strike price is $K=90$ the end result will be the following payoffs:

\begin{align*}
u^2:\hspace{20pt}&(121-90)^+=31\\
ud:\hspace{20pt}&(99-90)^+=9\\
du:\hspace{20pt}&(99-90)^+=9\\
d^2:\hspace{20pt}&(81-90)^+=0
\end{align*}

Therefore by the risk neautral valuation formula with $q_u=\frac{(1+R)-d}{u-d}=0.7$ and $q_d=\frac{u-(1+R)}{u-d}=0.3$ we have that the cost of the replicating portfolio at time $t=1$ is respectively

\begin{align*}
u:\hspace{20pt}&\frac{1}{1+R}\left\{31\cdot q_u + 9 \cdot q_d\right\}\approx 23.46\\
d:\hspace{20pt}&\frac{1}{1+R}\left\{9\cdot q_u + 0 \cdot q_d\right\}\approx 6.06
\end{align*}

To replicate this payoff at time $t=1$ we can use the risk neutral valuation formula once more to find the base cost of the replicating portfolio i.e. the price of $X$ at time $t=0$

$$
\frac{1}{1+R}\left\{23.46\cdot q_u + 6.06 \cdot q_d\right\}\approx 17.54.
$$

Working from the root to the leaves we can now calculate the hedging portfolio at time $t=0,1$ for each path. For time $t=0$ we calculate

\begin{align*}
x=&\frac{1}{1+R}\cdot \frac{u\cdot 6.06-d\cdot 23.46}{u-d}\approx -69.46,\\
y=&\frac{1}{s}\cdot\frac{23.46-6.06}{u-d}\approx0.87
\end{align*}

We see by calculations that this does indeed replicate the payoff at time $t=1$:

\begin{align*}
u:\hspace{20pt}&V_1^h=(1+R)\cdot x + 110\cdot y\approx 23.46,\\
d:\hspace{20pt}&V_1^h=(1+R)\cdot x + 90\cdot y\approx 6.06.
\end{align*}

We also see by calculation that the initial portfolio does cost the expected 17.54 as

$$
x\cdot 1+y\cdot100=87-69.46=17.54.
$$

Following these steps at time $t=1$ the portfolios $(-86.54,1)$ (for the up-scenario) and $(-38.94,0.5)$ (for the down-scenario) would arise. Notice when calculating $y$ one has to use the current price $S_1=S_0\cdot Z$ not $S_0$. One should also check by similar calculations as above, that these portfolios does indeed replicate the payoff of the contingent claim $X$. $\square$

</details>

<blockquote class = "prop">

**Proposition 2.25.** The arbitrage free price at $t=0$ of a $T$-claim $X$ is given by

$$
\Pi_0[X]=\frac{1}{(1+R)^T}E^Q[X]
$$

where $Q$ denotes the martingale measure, or more explicitly

$$
\Pi_0[X]=\frac{1}{(1+R)^T}\sum_{k=0}^T\binom{T}{k}q_u^kq_d^{T-k}\Phi(su^kd^{T-k}).
$$

</blockquote>

<details>
<summary>**Example.**</summary>

```{r}
R <- 0.04
s <- 100
u <- 1.1
d <- 0.9
p_u <- 0.6
p_d <- 0.4
q_u <- (1+R-d)/(u-d)
q_d <- (u-1-R)/(u-d)
cap_t <- 2

#Test for K=90
K <- 90
pi_0 <- (1+R)**(-cap_t)*sum(
  choose(cap_t,0:cap_t)*q_u**(0:cap_t)*q_d**(cap_t - 0:cap_t)*pmax(s*u**(0:cap_t)*d**(cap_t - 0:cap_t)-K,0)
) # = 17.53883

pi_0 <- unlist(lapply(0:ceiling(s*u**cap_t), function(K){
  (1+R)**(-cap_t)*sum(
    choose(cap_t,0:cap_t)*q_u**(0:cap_t)*q_d**(cap_t - 0:cap_t)*pmax(s*u**(0:cap_t)*d**(cap_t - 0:cap_t)-K,0)
  )
}))
```
```{r, echo = FALSE, wrapf = TRUE}
library(dplyr)
library(ggplot2)
data.frame(K = 0:ceiling(s*u**cap_t),
           Pi_0 = pi_0) %>%
  ggplot(.) + geom_line(aes(x=K,y=Pi_0)) +
  labs(title = "Price of european call option",
       x = "Strike", y = "Price") +
  theme_bw() +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 12),
        title = element_text(size = 16),
        plot.caption  = element_text(size = 10))
```

We follow an analog example as the one after proposition 2.24. Let $K=90$ and we see that

\begin{align*}
&\Pi_0[X]\\
&=\frac{1}{(1+0.04)^2}\sum_{k=0}^2\binom{2}{k}\cdot0.7^k\cdot0.3^{2-k}\cdot\Phi(100\cdot 1.1^k\cdot0.9^{2-k})\\
&=0.9245562\cdot\left(\underbrace{1\cdot 1\cdot0.09\cdot0}_{k=0}+\underbrace{2\cdot 0.7\cdot0.
3\cdot 9}_{k=1}+\underbrace{1\cdot 0.49\cdot1\cdot31}_{k=2}\right)\\
&=0.9245562\cdot\left(0+3.78+15.19\right)\\
&=17.53883
\end{align*}


Since we know that $K$ must meaningfully range in $[0,121]$ we could try to calculate the price of the contingent claim at time $t=0$ for all integers in this interval. We see that the price range between $S_0$ and 0 as expected. One can also see that the price changes slope at the prices 99 and 121 as the function is linear in $\Phi$ and som realisations loose any effect on the price when the strike is higher than the outcome. $\square$

</details>

<blockquote class = "prop">

**Proposition 2.26.** The condition $d<(1+R)<u$ is necessary and sufficient condition for absence of arbitrage.

</blockquote>

#### Generelised one-period model

In the previous we had the simpel model where we only had one stochastic asset $S$ and only one stochastic variable $Z$ determining the future stock price. Now we will generelise this model by introducing $N$ assets and introducing som stochastic behaviour to the system.

##### Model specification

We consider the market consisting of a collection of stochastic prices assets $i=1,...,N$ with $N$-dimensional price process.

$$
S_t=\begin{bmatrix} S_t^1\\
\vdots\\
S_t^N\end{bmatrix}
$$

We now assume that $S_t$ is defined on a background space with finite sample space $\Omega = \{\omega_1,...,\omega_M\}$ with associated probabilities $p_j=P(\omega_j)$, $j=1,...,M$. We can then for eact time $t=1,...,T$ define the $N\times M$ matrix $D_t$ as such

$$
D_t=\begin{bmatrix} S_t^1(\omega_1)&\cdots &S_t^1(\omega_M)\\
\vdots &\ddots & \vdots\\
S_t^N(\omega_1) &\cdots&S_t^M(\omega_M)\end{bmatrix}.
$$

We will assume that $S_0^1>0$ and $S_1^1(\omega_j)>0$, $j=1,...,M$.

##### Absence of Arbitrage

We now define a **portfolio** as an $N$-dimensional row vector

$$
h=\begin{bmatrix} h^1, \dots,h^N\end{bmatrix}
$$

representing the amount of assets held at time $t=0$ and held until $t=1$. The **value process** is then

$$
V^h_t=h\cdot S_t=\sum_{i=1}^N h^iS_t^i,\ t=0,1.
$$

For a given $\omega_j\in\Omega$ we have the realisation

$$
V_t^h=hS_t(\omega_j)=hd_j=(hD)_j.
$$

<blockquote class = "def">

**Definition 3.1.** The portfolio $h$ is an **arbitrage portfolio** fil it satisfies the conditions: $V_0^h=0$, $P(V_1^h\ge 0)=1$ and $P(V_1^h>0)>0$.

</blockquote>

<blockquote class = "lem">

**Lemma 3.2.** **(Farkas' Lemma)** Suppose that $d_0,d_1,...,d_M$ are column vectors in $\mathbb{R}^N$. Then exactly one of the following problems possesses a solution.

  * **Problem 1**: There exist $\lambda_1,...,\lambda_M\ge0$ such that $d_0=\sum_{j=1}^M\lambda_jd_j$.
  * **Problem 2**: There exist $h\in\mathbb{R}^N$ such that $h^\top d_0<0$ and $h^\top d_j\ge 0$ for $j=1,...,M$.

</blockquote>

We now investegate this system for any possible arbitrage portfolios. However first we acknowledge that there exist a nominal price system $S_t$ and a normalised price system $Z_t$. The latter we define as the nominel pricess under the numeraire $S_t^1$ that is

$$
Z_t=\begin{bmatrix} S_t^1/S_t^1\\
S_t^2/S_t^1\\
\vdots\\
S_t^N/S_t^1\end{bmatrix}=\begin{bmatrix} 1\\
S_t^2/S_t^1\\
\vdots\\
S_t^N/S_t^1\end{bmatrix}.
$$

The reason for introducing the normalized price system is that we can without much effort translate results in this system to the nominal system and the normalised system is easier to analize. For this, however, we need af few results.

<blockquote class = "lem">

**Lemma 3.3.** With notation as above, the following hold.

  1. The $Z_t$ value process i related to the $S_t$ value process by
  $$
  V_t^{h,Z}=hZ_t=\frac{1}{S_t^1}V_t^h.
  $$
  2. A portfolio is an arbitrage in the $S_t$ system if and only if there is an arbitrage in the $Z_t$ system.
  3. In the $Z_t$ price system, the numeraie asset $Z^1$ has unit constant prices i.e. $Z_t^1=1$ for all $t\ge 0$.

</blockquote>

One of the reason that the normalised system is attractable is that the numeraire asset is constant i.e. risk free in the normalised system. Let us formulate our first main result.

<blockquote class = "prop">

**Proposition 3.4.** The market is arbitrage free if and only iff there exists strictly positive real numbers $q_1,...,q_M\ge 0$ with $q_1+\cdots + q_M=1$ (probability vector) such that the following vector equality holds

$$
\begin{bmatrix} Z_0^1\\
\vdots\\
Z_N^1\end{bmatrix}=\begin{bmatrix} Z_1^1(\omega_1)\\
\vdots\\
Z_1^N(\omega_1)\end{bmatrix}q_1+\cdots +\begin{bmatrix} Z_1^1(\omega_M)\\
\vdots\\
Z_1^N(\omega_M)\end{bmatrix}q_M.\tag{3.3}
$$

</blockquote>

<details>
<summary>**Proof.**</summary>

</details>

##### Martingale Measures

<blockquote class = "def">

**Definition 3.5.** Given the objective probability measure $P$ on $(\Omega,\mathcal{F},P)$, we say that another probability measure $Q$ defined on $\Omega$ is  **equivalent** to $P$ if

$$
\forall A\in\mathcal{F}:P(A)=0\iff Q(A)=0,
$$

or equivalently

$$
\forall A\in\mathcal{F}:P(A)=1\iff Q(A)=1.
$$

</blockquote>

<blockquote class = "def">

**Definition 3.7.** Consider the market model above and set $S^1$ as the numeraire asset. We say that a probability measure $Q$ defined on $\Omega$ is a **martingale measure** if it satisfies the following conditions:

  1. $Q$ is equivalent to $P$, i.e. $Q\sim P$.
  2. For every $i=1,...,N$, the normalized asset price process
  $$
  Z_t^i=\frac{S_t^i}{S_t^1},
  $$
  is martingale under the measure $Q$.

</blockquote>

<blockquote class = "thm">

**Theorem 3.8.** **(First Fundamental Theorem)** Given a fixed numeraire, ther market is free of arbitrage possibilities if and only if there exists a martingale measure $Q$.

</blockquote>

By assuming that the numeraire asset is risk free (i.e. does not depend on $\omega$) then by scaling we can derive the short interest rate as

$$
1+R=\frac{S_1^1}{S_0^1}.
$$

With this in mind we can formulate theorem 3.8 in its more widely used form.

<blockquote class = "thm">

**Theorem 3.9.** **(First Fundamental Theorem)** Assume that there exist a risk free asset, and denote the corresponding risk free interest rate by $R$. Then the market is arbitrage free if and only if there exist a measure $Q\sim P$ such that

$$
S_0^i=\frac{1}{1+R}E^Q[S_1^i],\hspace{20pt}\text{for all}\ i=1,...,N.\tag{3.9}
$$

</blockquote>

##### Martingale Pricing

Moving forward we will assume that there exist a risk free asset and we will denote it by $B_t$ ($B_t=S^1_t/S^1_0$).

<blockquote class = "def">

**Definition 3.10.** A **contingent claim** is any random variable $X$, defined on the sample space $\Omega$.

</blockquote>

To ensure no arbitrage in the extended market containing the $N$ assets and the contingent claim we can apply the first fundamental pricing theorem on the extended market.

<blockquote class = "prop">

**Proposition 3.11.** Consider a given claim $X$. In order to avoid arbitrage, $X$ must then be priced according to the formula

$$
\Pi_0[X]=\frac{1}{1+R}E^Q[X],\tag{3.10}
$$

where $Q$ is a martingale measure for the underlying market $(\Pi,S^1,...,S^N)$.

</blockquote>

##### Completeness

Given that a market is arbitrage-free we may run into a uniqueness issue when determining the price of a contingent claim. If a martingale measure exist we will very much like it to be unique as this will ensure that the price from the risk neutral valuation formula is unique. To this we need the market to be complete.

<blockquote class = "def">

**Definition 3.12.** Consider a contingent claim $X$. If there exists a portfolio $h$, based on the underlying assets, such that

$$
V_1^h=X,\ \text{with probability 1}\tag{3.11}
$$

i.e.

$$
V_1^h(\omega_j)=X(\omega_j),\ j=1,...,M,\tag{3.12}
$$

then we say that $X$ is **replicated**, or **hedged** by $h$. Such a portfolio $h$ is called a replicating, or hedging portfolio. If every contingent claim can be replicated, we say that the market is **complete**.

</blockquote>

We can now formulate a proposition on when the market is complete in terms of the matrix $D$.

<blockquote class = "prop">

**Proposition 3.13.** The market is complete if and only if the rows of the matrix $D$ span $\mathbb{R}^M$, i.e. if and only if $D$ has rank $M$.

</blockquote>

Now we formulate the second fundamental pricing theorem in terms of the martingale measure $Q$.

<blockquote class = "prop">

**Proposition 3.14.** **(Second Fundamental Theorem)** Assume that the model is arbitrage free i.e. $Q$ exist. Then the market is unique if and only if the martingale measure is unique.

</blockquote>

##### Stochastic Discount Factors

<blockquote class = "def">

**Definition 3.16.** The random variable $L$ on $\Omega$ is defined by

$$
L(\omega_i)=\frac{q_i}{p_i},\hspace{20pt} i=1,...,M.
$$

</blockquote>

<blockquote class = "def">

**Definition 3.17.** Assume the absence of arbitrage, and fix a martingale measure $Q$. With notation as above, the **stochastic discount factor** (or "state price deflator") is the random variable $\Lambda$ on $\Omega$ by

$$
\mathbf{M}(\omega)=\frac{1}{1+R}\cdot L(\omega).\tag{3.19}
$$

</blockquote>

<blockquote class = "prop">

**Proposition 3.18.** The arbitrage free price of any claim $X$ is given by the formula

$$
\Pi_0[X]=E^P[\mathbf{M}\cdot X]
$$

where $\mathbf{M}$ is a stochastic discount factor.

</blockquote>

&nbsp;

### Exercises Week 1

**Probability exercises**

Let $(W(t))_{t\ge}$ be a Brownian motion (Bjork, Definition 4.1).

**Exercise 1.** Show that the following processes also are Brownian motions.

 i. $(-W(t))_{t\ge 0}$ (symmetry)
 ii. For any $s\ge 0$, $(W(t+s)-W(s))_{t\ge 0}$ (time-homogeneity).
 iii. For every $c>0$, $(cW(t/c^2))_{t\ge 0}$ (scaling).

<details>
<summary>**Solution (i).**</summary>

By assumption $W$ is a Brownian motion and so it follows that

$$-W_0=-1\cdot0=0$$

Furthermore, for $r<s\le t< u$ it holds that $W_u-W_t$ and $W_s-W_r$ is independent. By seperate transformations the independence property is preserved and $-(W_u-W_t)$ and $-(W_s-W_r)$ is independent. Next, for a normal distributed random variable $N\sim\mathcal{N}(\mu,\sigma^2)$ it holds, that for a scaler $c\in\mathbb{R}$ we have $c N\sim\mathcal{N}(c\mu,c^2\sigma ^2)$. Then obviously;

$$-(W_t)=(-1)W_t\stackrel{d}{=}\mathcal{N}((-1)\cdot0,(-1)^2(t-s))\stackrel{d}{=}\mathcal{N}( 0,t-s).$$

Lastly, let $\omega \in \Omega$ and consider the sample path $s\mapsto (-W_s)(\omega)$. Clearly for two continuous functions $f$ and $g$ it holds that $(g\circ f)$ is continuous. Then with $g(f)=-f$ and $f(t)=W_t(\omega)"/>$ it follows that $(-W_t)=(g\circ W)(t)$ is also continuous.

</details>
<details>
<summary>**Solution (ii).**</summary>

Much like the previous exercise we define a new process and show the properties hold. Let $s\ge 0$ be chosen arbitrary. Now define $X_t=W(t+s)-W(s)$.

First, we let $t=0$ and see

$$X_0=W(0+s)-W(s)=W(s)-W(s)=0.$$

Secondly, we have that for $r<u$:

$$X_u-X_r=W(u+s)-W(s)-(W(r+s)-W(s))=W(u+s)-W(r+s)\sim \mathcal{N}(0,u+s-(r+s))=\mathcal{N}(0,u-r).$$

and since for $r<u\le k<l$ the translation $r+s<u+s\le k+s<l+s$ still holds and $X_l-X_k=W(l+s)-W(k+s)$ and $X_u-X_r=W(u+s)-W(k+s)$ are independent. Finally since $W_t(\omega)$ is continuous in $t$ hence the translation $W_{t+s}$ is continouos. Adding a constant yields a function that is also continuous, hence $X_t$ is continuous.

</details>
<details>
<summary>**Solution (iii).**</summary>

Let $c>0$ be given. We show that

$$X_t=cW\left(\frac{t}{c^2}\right)$$

is a Brownian motion. We simply show the four properties. Let $t=0$ and notice

$$X_0=cW\left(\frac{0}{c^2}\right)=cW(0)=0.$$

The second property follows from seperate transformation and that for $r<u\le s<t$ we consider

$$X_u-X_r=c\left(W\left(\frac{u}{c^2}\right)-W\left(\frac{r}{c^2}\right)\right)\hspace{20pt}\text{and}\hspace{20pt}X_t-X_s=c\left(W\left(\frac{t}{c^2}\right)-W\left(\frac{s}{c^2}\right)\right)$$

and since $c,r,u,t,s>0$ we have the same order for the scaled version of $r,u,t,s$ and hence we have two independent RV scaled by $c$. Then by seperate transformations the variables is still independent. Next for the third property:

$$X_t-X_s=c\left(W\left(\frac{t}{c^2}\right)-W\left(\frac{s}{c^2}\right)\right)\sim\mathcal{N}\left(c\cdot 0,c^2\left(\frac{t}{c^2}-\frac{s}{c^2}\right)\right)=\mathcal{N}(0,t-s).$$

Where we use the properties of scaling a normal distributed random variable i.e. for $c>0$ and $N\sim\mathcal{N}(\mu,\sigma ^2)$ it follows that $c N\sim\mathcal{N}(c\mu,c^2\sigma ^2)$. Finally, the forth property follows since $g(f)=cf$ is continuous and $h(t)=t/c^2$ is continuous, then for any continuous function $f(s)$ it follows that $(g \circ f\circ h)=g(f(h(t)))$ is continuous.

</details>

&nbsp;

<blockquote class = "prop">
**Proposition B.37.** Let $(\Omega,\mathcal{F},P)$ be a given probability space, let $\mathcal{G}$ be a sub-sigma-algebra of $\mathcal{F}$, and let $X$ be a square integrable random variable.
Consider the problem of minimizing
$$E\left[(X-Z)^2\right]$$
where $Z$ is allowed to vary over the class of all square integrable $\mathcal{G}$ measurable random variables. The optimal solution $\hat{Z}$ is then given by.
$$\hat{Z}=E[X\vert\mathcal{G}].$$
</blockquote>

**Exercise 2.** *(Bjork, exercise B.11.)* Prove proposition B.37 by going along the following lines.

  a. Prove that the "estimation error" $X-E[X\vert\mathcal{G}]$ is orthogonal to $L^2(\Omega,\mathcal{G},P)$ in the sence that for any $Z\in L^2(\Omega,\mathcal{G},P)$ we have
  $$E[Z\cdot(X-E[X\vert\mathcal{G}])]=0$$
  b. Now prove the proposition by writing
  $$X-Z=(X-E[X\vert\mathcal{G}])+(E[X\vert\mathcal{G}]-Z)$$
  and use the result just proved.

<details>
<summary>**Solution (a).**</summary>

Let $X\in L^2(\Omega,\mathcal{F},P)$ be a random variable. Now consider an arbitrary $Z\in L^2(\Omega,\mathcal{G},P)$. Recall that $\mathcal{G}\subset \mathcal{F}$ and so $X$ is also in $Z\in L^2(\Omega,\mathcal{G},P)$, as it is bothe square integrable and $\mathcal{G}$-measurable. Then

$$E\left[Z\cdot(X-E[X\vert\mathcal{G}])\right]=E\left[Z\cdot X\right]-E\left[Z\cdot E[X\vert\mathcal{G}]\right].$$

Then by using the law of total expectation and secondly that $Z$ is $\mathcal{G}$-measurable we have that

$$E\left[Z\cdot X\right]=E\left[E[Z\cdot X\vert\mathcal{G}]\right]=E\left[Z\cdot E[ X\vert\mathcal{G}]\right].$$

Combining the two equations gives the desired result.

</details>
<details>
<summary>**Solution (b).**</summary>

Obviously, we have that

$$X-Z=X-Z+E[X\vert\mathcal{G}]-E[X\vert\mathcal{G}]=(X-E[X\vert\mathcal{G}])+(E[X\vert\mathcal{G}]-Z).$$

Then squaring the terms gives

$$(X-Z)^2=(X-E[X\vert\mathcal{G}])^2+(E[X\vert\mathcal{G}]-Z)^2+2(X-E[X\vert\mathcal{G}])(E[X\vert\mathcal{G}]-Z)$$

Taking expectation on each side and using linearity of the expectation we have that

$$E[(X-Z)^2]=E\left[(X-E[X\vert\mathcal{G}])^2\right]+E\left[(E[X\vert\mathcal{G}]-Z)^2\right]+2E\left[(X-E[X\vert\mathcal{G}])(E[X\vert\mathcal{G}]-Z)\right].$$

We can now use that $E[X\vert\mathcal{G}]-Z$ is $\mathcal{G}$-measurable with the above result on the last term.

$$E[(X-Z)^2]=E\left[(X-E[X\vert\mathcal{G}])^2\right]+E\left[(E[X\vert\mathcal{G}]-Z)^2\right].$$

Now since $X$ is given the term $E\left[(X-E[X\vert\mathcal{G}])^2\right]$ is simply a constant not depending on the choice og $Z$. The optimal choice of $Z$ is then $E[X\vert\mathcal{G}]$ since this minimizes the second term. The statement is then proved.

</details>

&nbsp;

**Exercise 3.** Discuss the following theory/results of Moment generating functions (Laplace transform).

Let $X$ be a random variable with distribution function $F(x)=P(X\le x)$ and $Y$ be a random variable with distribution function $G(y)=P(Y\le y)$.

<blockquote class = "def">
**Definition.** The moment generating function or Laplace transform of $X$ is

$$\psi_X(\lambda)=E\left[e^{\lambda X}\right]=\int_{-\infty}^\infty e^{\lambda x}dF(x)$$

provided the expectation is finite for $\vert\lambda\vert<h$ for some $h>0$.
</blockquote>

The MGF uniquely determine the distribution of a random variable, due to the following result.

<blockquote class = "thm">
**Theorem 1.** *(Uniqueness)* If $\psi_X(\lambda)=\psi_Y(\lambda)$ when $\vert\lambda\vert<h$ for some $h>0$, then $X$ and $Y$ has the same distribution, that is, $F=G$.
</blockquote>

There is also the following result of independence for Moment generating functions.

<blockquote class = "thm">
**Theorem 1.** *(Independence)* If 

$$E\left[e^{\lambda_1X+\lambda_2Y}\right]=\psi_X(\lambda_1)\psi_Y(\lambda_2)$$

for $\vert\lambda_i\vert<h$ for $i=1,2$ for some $h>0$, then $X$ and $Y$ are independent random variables.
</blockquote>

**Example.** Recall that the Moment generating function of a normal (Gaussian) distribution is given by

$$\psi_X(\lambda)=E\left[e^{\lambda X}\right]=\exp\left(\lambda \mu + \frac{\lambda^2}{2}\sigma^2\right)$$

where $X$ is normally distributed with mean $\mu$ and variance $\sigma^2$ and $\lambda\in\mathbb{R}$ is a constant. Since a Brownian motion $W(t)$ is normally distributed with zero mean and variance $t$, we have that

$$E[\exp(\lambda W(t))]=\exp\left(\frac{\lambda^2}{2}t\right).$$

<details>
<summary>**Discussion.**</summary>



</details>

&nbsp;

**Exercise 4.** *(Bjork, exercise C.8.(a-c))* Let $W$ be a Brownian motion. Notice that for the natural filtration $\mathcal{F}_s=\sigma(W_t\vert t\le s)$ $W_t-W_s$ is independent of $\mathcal{F}_s$

  a. Show that $W_t$ is a martingale.
  b. Show that $W^2_t-t$ is a martingale.
  c. Show that $\exp(\lambda W_t-\frac{\lambda^2}{2}t)$ is a martingale.

<details>
<summary>**Solution (a).**</summary>

We show that for the natural filtration that $W_t$ is a martingale. This include showing integrability and the martingale property. For the first we note that for a normal distributed random variable with mean 0 we have

$$E[\vert N\vert]=\int_{-\infty}^\infty \vert x\vert dF_N(x)=2\int_{0}^\infty xdF_N(x)$$

since the distribution is symmetric. Substituting the distribution function $\Phi(x)=P(N\le x)$ in we see that

$$E[\vert N\vert]=2\int_{0}^\infty xd\Phi(x)=2\int_{0}^\infty x\frac{1}{\sqrt{2\pi\sigma^2}}e^{-x^2/(2\sigma^2)}dx=(*)$$

by substituting $u=x^2/(2\sigma^2)$ ($x=\sqrt{2\sigma^2u}$) we have that

$$\frac{dx}{du}=\frac{1}{2}\sqrt{2\sigma^2u}2\sigma^2=(\sigma^2)^{3/2}\sqrt{2}u\iff dx=(\sigma^2)^{3/2}\sqrt{2}u\ du$$

hence

$$(*)=\frac{2}{\sqrt{2\pi\sigma^2}}\int_0^{\infty}\sqrt{2\sigma^2u}e^{-u}(\sigma^2)^{3/2}\sqrt{2}u\ du=\frac{2\sqrt{2\sigma^2}(\sigma^2)^{3/2}\sqrt{2}}{\sqrt{2\pi\sigma^2}}\int_0^{\infty}\sqrt{u}e^{-u}u\ du.$$

This then simplify to

$$(*)=\frac{(2\sigma^2)^{3/2}}{\sqrt{\pi}}\int_0^{\infty}u^{3/2}e^{-u}\ du=(2\sigma^2)^{1/2}\sqrt{\frac{2\sigma^2}{\pi}}\int_0^{\infty}u^{3/2}e^{-u}\ du=\sqrt{\frac{2\sigma^2}{\pi}}<\infty.$$

(Obviously the above is not derived correctly, but the end expression is valid, source: [link](https://arxiv.org/pdf/1402.3559.pdf)) However since

$$W_t=W_t-0=W_t-W_0\sim\mathcal{N}(0,t)$$

we have that $E\vert W_t\vert<\infty$ as desired.

Next, we have that

$$E[W_t\vert \mathcal{F}_s]=E[W_t-W_s\vert\mathcal{F}_s]+W_s=0+W_s=W_s.$$

In the above we used that $W_t-W_s$ is $\mathcal{F}_s$-measurable with mean 0. Then it follows that $W_t$ is a martingale.

</details>
<details>
<summary>**Solution (b).**</summary>

Let $M_t=W_t^2-t$. First, we observe that two measurable functions composed is still a measurable function. Hence we know that $M_t$ is measurable wrt. the filtration since $W_t$ is measurable and $w\mapsto w^2+t$ is measurable. Secondly, we have that

$$E[\vert W_t^2-t\vert]\le E\vert W_t^2\vert +E\vert t\vert=t+t=2t<\infty$$

where we use the triangle inequality. Thirdly, for the martingale property we have that for $t>s$:

$$E[M_t\vert \mathcal{F}_s]=E[W_t^2-t\vert \mathcal{F}_s]=E[W_t^2+W_s^2-2W_tW_s-W_s^2+2W_tW_s-t\vert \mathcal{F}_s]$$

which by linearity and independence of increments to the filtration gives

$$E[M_t\vert \mathcal{F}_s]=E[(W_t-W_s)^2-W_s^2+2W_tW_s-t\vert \mathcal{F}_s]=t-s-t+E[2W_tW_s-W_s^2\vert \mathcal{F}_s]$$

However since $W_s$ is measurable wrt. the filtration at time $s$ the above is

$$E[M_t\vert \mathcal{F}_s]=2W_sE[W_t\vert \mathcal{F}_s]-W_s^2-s=2W_s^2-W_s^2-s=W_s^2-s=M_s.$$

Since from (a) we know that $W_t$ is a martingale. Then we arrive at the desired result.

</details>
<details>
<summary>**Solution (c).**</summary>

Let $M_t=\exp\left(\lambda W_t-\frac{\lambda^2}{2}t\right)$. First, by composition of measurable functions $M_t$ is $\mathcal{F}_t$-measurable. Secondly, we have using the MGF for a normal distributed random variable:

$$E\vert M_t=E\left(\exp\left(\lambda W_t-\frac{\lambda^2}{2}t\right)\right)\le E\left(\exp\left(\lambda W_t\right)\right)=\exp\left(\frac{\lambda^2}{2}t\right)<\infty.$$

Thirdly, we consider

$$E[M_t\vert\mathcal{F}_s]=E\left.\left[\left(\exp\left(\lambda W_t-\frac{\lambda^2}{2}t\right)\right)\right\vert\mathcal{F}_s\right]=\exp\left(-\frac{\lambda^2}{2}t\right)E\left.\left[\left(\exp\left(\lambda W_t\right)\right)\right\vert\mathcal{F}_s\right].$$

By adding and subtracting $W_s$ in the exponent we get

\begin{align*}
E[M_t\vert\mathcal{F}_s]&=\exp\left(-\frac{\lambda^2}{2}t\right)E\left.\left[\left(\exp\left(\lambda (W_t-W_s)+\lambda W_s\right)\right)\right\vert\mathcal{F}_s\right]\\
&=\exp\left(-\frac{\lambda^2}{2}t\right)\exp\left(\frac{\lambda^2}{2}(t-s)\right)E\left.\left[\left(\exp\left(\lambda W_s\right)\right)\right\vert\mathcal{F}_s\right].
\end{align*}

Using that $E\left.\left[\left(\exp\left(\lambda W_s\right)\right)\right\vert\mathcal{F}_s\right]=\exp\left(\lambda W_s\right)$ and combining the exponents gives the desired:

$$E[M_t\vert\mathcal{F}_s]=\exp\left(\lambda W_s-\frac{\lambda^2}{2}s\right)=M_s.$$

</details>

## Week 2 

### Table of Contents

  * [Stochastic integrals and Ito formula (Chapter 4 and Appendix C.2)](#stochastic-integrals)
  * [Stochastic differential equations (Chapter 5.1-4)](#stochastic-differential-equations)

  * [Exercises](#exercises-week-2)

### Theory

#### Stochastic Integrals

We want to formulate financial markets in continuous time and the most elegant theory is obtained from processes that can be defined in terms of **stochastic differential equations** or in other words by their dynamics. We may call them **diffusion processes**, as they may be approximated by a stochastic difference equation:

$$
X_{t+\Delta t}-X_t=\mu(t,X_t)\Delta t+\sigma(t,X_t)Z_t.\tag{4.1}
$$

Above $Z_t$ is a normally distributed random variable (a disturbance). In this formulation we say that $S_t$ is driven by two forces: on one hand a locally deterministic velocity or drift $\mu(t,X_t)$ and on the other hand a Gaussian term amplified by the deterministic factor $\sigma(t,X_t)$.

##### Information

We consider a primary process $X_t$ and we introduce the notion of information generated by $X_t$ in terms of the natural filtration. The idea can be summed up in the following definition.

<blockquote class = "def">

**Definition 4.3.** The symbol $\mathcal{F}^X_t\subseteq\mathcal{F}$ denotes "the information generated by $X_t$ on the interval $[0,t]$", or alternatively "what has happened to $X_t$ over ther interval $[0,t]$".

  1. If, based upon observations of the trajectory $\{X_s;\ 0\le s\le t\}$, it is possible to decide whether a given event $A$ has occurred or not, then we write this as
  $$
  A\in\mathcal{F}^X_t
  $$
  or say that "$A$ is $\mathcal{F}^X_t$-measurable".
  2. If the value of a given random variable $Z$ can be completely determined given observations of the tragectory $\{X_s;\ 0\le s\le t\}$, then we also write
  $$
  Z\in\mathcal{F}^X_t.\ \text{(}Z\text{ is }\mathcal{F}^X_t\text{-measurable)}
  $$
  3. If $Y$ is a stochastic process such that we have
  $$
  Y_t\in\mathcal{F}^X_t
  $$
  for all $t\ge0$ then we say that $Y_t$ is **adapted** to the **filtration** $\{\mathcal{F}^X_t\}_{t\ge 0}$. For brevity of notation, we will sometimes write the filtration as $\{\mathcal{F}^X_t\}_{t\ge 0}=\mathbf{F}$.

</blockquote>

##### Stochastic Integrals

We will now formulate the theory of stochastic integrals, that is, processes written in terms of stochastic processes with stochastic integrator and/or stochastic integrant. We will consider some given standard Brownian motion $W_t$ and another stochastic process $X_t$. We need som integrability condition on $X_t$ in order to do the calculations. We therefore determine a selection of suitable stochastic processes $X$ must be contained in.

<blockquote class = "def">

**Definition 4.4.** Let $X_t$ be a stochastic process, then

  i. We say that $X_t$ belongs to the class $\mathcal{L}^2[a,b]$ if $X_t$ is adapted to the filtration $\mathcal{F}^X_t$ and the following holds
  $$\int_a^bE[X_s^2]\ ds<\infty$$
  ii. We say that $X_t$ belongs to the class $\mathcal{L}^2$ if $X_t\in\mathcal{L}^2[0,t]$ for all $t>0$.

</blockquote>

We now want to define what we mean by 

$$
\int_a^bX_t\ dW_s
$$

for some process $X_t\in\mathcal{L}^2$. We see that a way to go about this problem is to start by defining the concept for a simple stochastic process $X_t$. By *simple* we mean a process $X_t$ that is constant on between some deterministic points in time $a=t_0<t_1<\cdots<t_n=b$. In that case we may define the integral as

$$
\int_a^bX_s\ dW_s = \sum_{k=0}^{n-1}X_{t_k}[W_{t_{k+1}}-W_{t_k}].
$$

In the more general setting we may follow the following approach:

  1. Approximate $X$ with a sequence $\{X^n\}_{n\in\mathbb{N}}$ of simple processes such that the following convergence criteria hold
  
  $$
  \int_a^bE[(X_s^n-X_s)^2]\ ds\to 0,\ n\to\infty
  $$
  
  2. For each $n$ the integral $\int_a^b X_s^n\ dW_s:=Z^n$ is well defined and it is possible to prove, using DCT, that a variable $Z$ exists such that $Z^n\to Z$ that is in $L^2$.
  3. We now define the stochastic integral by the limit
  
  $$
  \int_a^b X_s\ dW_s=\lim_{n\to \infty}\int_a^b X_s^n\ dW_s.
  $$

Obviously the hardest step is finding the processes $X^n$. This stochastic har some properties we will use.

<blockquote class = "prop">

**Proposition 4.5.** Let $X_t\in\mathcal{L}^2$, then

\begin{align*}
&E\left[\int_a^b X_s\ dW_s\right]=0.\tag{4.11}\\
&E\left[\left(\int_a^b X_s\ dW_s\right)^2\right]=\int_a^b E[ X_s^2]\ dW_s.\tag{4.13}\\
&\int_a^b X_s\ dW_s\ \text{ is }\mathcal{F}_b^W\text{-measurable.}\tag{4.14}
\end{align*}

</blockquote>

##### Martingales

<blockquote class = "def">

**Definition 4.7.** Let $M_t$ be a stochastic process defined on a background space $(\Omega,\mathcal{F},P)$. Let $(\mathcal{F}_t)_{t\ge 0}$ be a filtration. If $M_t$ is adapted to the filtration $\mathcal{F}_t$, $E\vert M_t\vert <\infty$ and

$$E[M_t\vert \mathcal{F}_s]=M_s,\hspace{20pt}P-\text{a.s.}$$

holds for any $t>s$ we say that $M_t$ is a martingale ($\mathbf{F}$-martingale). If the above has $\ge$ or $\le$ we say that $M_t$ is either a **submartingale** or **supermartingale** respectively.

</blockquote>

<blockquote class = "prop">

**Proposition 4.8.** For any process $X_t\in\mathcal{L}^2[s,t]$ the following hold:

$$
E\left[\left.\int_s^t X_s\ dW_s\right\vert\mathcal{F}_s^W\right]=0
$$

</blockquote>

<blockquote class = "prop">

**Corollary 4.9.** For any process $X_t\in\mathcal{L}^2$ the process

$$
M_t=\int_s^t X_s\ dW_s,
$$

is an $(\mathcal{F}_t^W)$-martingale. In other words, modulo an integrability condition, *every stochastic integral is a martingale*.

</blockquote>

<blockquote class = "lem">

**Lemma 4.10.** Let $M_t$ be a stochastic process with stochastic differential, then $M_t$ is a martingale if and only if the stochastic differential has the form $dM_t=X_t\ dW_t$ i.e. $M_t$ as no $dt$-term.

</blockquote>

##### Stochastic Calculus and the Ito Formula

Given this breif introduction to stochastic integrals we may formulate som simple calculus revolving around Ito's formula. We consider the stochastic process $X_t$ and we suppose that there exist a real number $X_0$ and adapted processes $\mu$ and $\sigma$ wrt. $\mathcal{F}_t^W$ such that for all $t\ge0$ we have

$$
X_t=X_0+\int_0^t\mu_s\ ds+\int_0^t\sigma_s\ dW_s,\tag{4.16}
$$

where $W_t$ is a standard Brownian motion. We know from earlier courses that the above may be written in terms of the dynamics (pure notation):

$$
\left\{\begin{matrix}dX_t=\mu_t\ dt+\sigma_t\ dW_t,\\ X_0=X_0.\end{matrix}\right.
$$

Here we intepret the above as $X_t$ has boundary condition $X_0$ and evolves with a drift $\mu_t\ dt$ amplified and distorted by the drift $\sigma_t\ dW_t$. We say that $X_t$ has **stochastic differential** $dX_t$ and initial condition $X_0$.

We want to understand how transformation of such an integral behaves and therefore we introduce some calculus which will tell how for instance $f(t,X_t)$ (for some $C^{1,2}$-function) behaves. This insight is given by the important Ito's formula.

<blockquote class = "thm">

**Thoerem 4.11.** **(Ito's formula, one-dimensional)** Assume that the process $X$ has a stochastic differential form given by

$$
dX_t=\mu_t\ dt + \sigma_t\ dW_t,\tag{4.28}
$$

where $\mu$ and $\sigma$ are adapted processes, and let $f:\mathbb{R}_+\times\mathbb{R}\to\mathbb{R}$ be a $C^{1,2}$-function. Define the process $Z$ by $Z_t=f(t,X_t)$. Then $Z$ has stochastic differential given by

$$
df(t,X_t)=\left(\frac{\partial f}{\partial t}(t,X_t) + \mu_t\frac{\partial f}{\partial x}(t,X_t) + \frac{1}{2}\sigma^2_t\frac{\partial^2 f}{\partial x^2}(t,X_t)\right)\ dt+\sigma_t\frac{\partial f}{\partial x}(t,X_t)\ dW_t.\tag{4.29}
$$

</blockquote>

<blockquote class = "prop">

**Proposition 4.12.** **(Ito's formula, one-dimensional)** With assumptions as in theorem 4.11, $df$ is given by

$$
df=\frac{\partial f}{\partial t}\ dt + \frac{\partial f}{\partial x}\ dX_t + \frac{1}{2}\frac{\partial^2 f}{\partial x^2}\ (dX_t)^2,\tag{4.31}
$$

where we use the following table

$$
\left\{\begin{matrix}(dt)^2=0,\\ dt\cdot dW_t=0,\\ (dW_t)^2=dt.\end{matrix}\right.
$$

</blockquote>

<blockquote class = "lem">

**Lemma 4.18.** Let $\sigma(t)$ be deterministic function of time and define the process $X$ by

$$
X_t=\int_0^t \sigma(s)\ dW_s.\tag{4.37}
$$

Then

$$
X_t\sim\mathcal{N}\left(0,\int_0^t\sigma^2(s)\ ds\right).
$$

</blockquote>

##### The multidimensional Ito Formula

Consider a vector process $X=(X^1,...,X^n)^\top$ where each component $X^i$ has stochastic differential

$$
d X_t^i=\mu_t^i\ dt+\sum_{j=1}^d\sigma^{ij}_t\ dW_t^j
$$

where $W^1,...,W^d$ is independent Brownian motions. Then we have respectively the drift vector process $\mu_t$ in $n$ dimensions, the vector Brownian motion in $d$ dimensions and a $n\times d$-dimensional **diffusion matrix** $\sigma_t$ given as below

$$
\mu_t=\begin{bmatrix}\mu^1_t\\ \vdots\\ \mu^n_t\end{bmatrix},\hspace{10pt}W_t=\begin{bmatrix}W^1_t\\ \vdots\\ W^d_t\end{bmatrix},\hspace{10pt}\sigma_t=\begin{bmatrix}\sigma^{11}_t & \cdots & \sigma^{1d}_t \\ \vdots & \ddots & \vdots\\ \sigma^{n1}_t &\cdots& \sigma^{nd}_t\end{bmatrix}.
$$

Given this we may write the dynamics of $X$ as

$$
d X_t=\mu_t\ dt+\sigma_t\ dW_t\in\mathbb{R}^n.
$$

Consider now a function $f:\mathbb{R}_+\times \mathbb{R}^n\to\mathbb{R}$ which is a $C^{1,2}$-mapping. We want to study the dynamics of the process

$$
Z_t=f(t,X_t).
$$

The dynamics is given in the multidimensional version of Ito's formula.

<blockquote class = "thm">

**Thoerem 4.19.** **(Ito's formula, multi-dimensional)** Let $X$ be given as above. Then the following holds:

  * The process $f(t,X_t)$ has the stochastisc differential given by
  $$
  df(t,X_t)=\left(\frac{\partial f}{\partial t}(t,X_t) + \sum_{i=1}^n\mu^i_t\frac{\partial f}{\partial x^i}(t,X_t) + \frac{1}{2}\sum_{i,j=1}^nC_t^{ij}\frac{\partial^2 f}{\partial x^i\partial x^j}(t,X_t)\right)\ dt+\sum_{i=1}^n\sigma^i_t\frac{\partial f}{\partial x^i}(t,X_t)\ dW_t.
  $$
  Here the row vector $\sigma^i_t$ is the $i$'th row of the matrix $\sigma_t$ and the matrix $C$ is defined by $C=\sigma\sigma^\top$.
  * Alternatively, the differential is given by the formula
  $$
  df(t,X_t)=\frac{\partial f}{\partial t}(t,X_t)\ dt + \sum_{i=1}^n\frac{\partial f}{\partial x^i}(t,X_t)\ dX^i_t + \frac{1}{2}\sum_{i,j=1}^n\frac{\partial^2 f}{\partial x^i\partial x^j}(t,X_t)\ dX^i_tdX^j_t,
  $$
  with the formal multiplication table
  $$
  \left\{\begin{matrix}(dt)^2=0,\\  dt\cdot dW_t^i=0, & i = 1,...,d,\\ (dW_t^i)^2=dt, & i=1,...,d, \\ dW_t^i\cdot dW_t^i =0, & i\ne j.\end{matrix}\right.
  $$

</blockquote>

Obviously, one can write the differential in Ito's formula in many other ways including a matrix-wise version using the Hessian matrix $H_{ij}=\frac{\partial^2 f}{\partial x^i\partial x^j}$.

##### Correlated Brownian motions

In the previous section the $d$-dimensional Brownian was assumed to have independent Brownian motions. However we may instead consider a variation where we have some dependence between the Brownian motions.

This section has not been finished.

#### Discrete Stochastic Integrals

This section has not been finished.

#### Stochastic Differential Equations

We start the chapter by formalising some used objects. We consider the following objects.

  * $M(n,d)$ denotes the class of $n\times d$-matrices.
  * $W$ is a $d$-dimensional Brownian motion
  * $\mu$ is a $\mathbb{R}^n$-valued function with arguments $(t,X_t)$ with $X_t$ being a $n$-dimensional stochastic process.
  * $\sigma$ a $M(n,d)$-valued function with arguments as in $\mu$.
  * $x_0$ a $\mathbb{R}^n$-valued vector.

We want then to understand when the following has a solution

$$
dX_t=\mu(t,X_t)\ dt + \sigma(t,X_t)\ dW_t,\ \ X_0=x_0.
$$

We call such an equation the **stochastic differential equation** or simply SDE. We know that the above is loosely notation for the integral form as

$$
X_t=x_0+\int_0^t\mu(s,X_s)\ ds +\int_0^t\sigma(s,X_s)\ dW_s,
$$

for all $t\ge 0$. The following proposition tells us when an solution exist to the problem above. In the below $\Vert \cdot \Vert$ is usual euclidian norm

$$
\Vert x\Vert=\sqrt{\sum_{i=1}^nx_i^2}.
$$

<blockquote class = "prop">

**Proposition 5.1.** Suppose that there existis a constant $K$ such that the following conditions are satisfied for all $x,y$ and $t$.

\begin{align*}
\Vert \mu(t,x) - \mu(t,y) \Vert &\le K\Vert x-y\Vert,\\
\Vert \sigma(t,x) - \sigma(t,y) \Vert &\le K\Vert x-y\Vert,\\
\Vert \mu(t,x) \Vert +\Vert \sigma(t,x) \Vert&\le K(1+\Vert x\Vert).
\end{align*}

Then there exists a unique solution to the SDE above. Furthermore, the solution has the properties

  1. $X$ is $\mathcal{F}_t^W$-adapted.
  2. $X$ has continuous trajectories.
  3. $X$ is a Markov process.
  4. There exists a constant $C$ such that
  $$
  E[\Vert X_t\Vert^2]\le Ce^{Ct}(1+\Vert x_0\Vert^2).
  $$

</blockquote>
  
In genereal the solution to an SDE is so complicated, that it in practical terms is unsolvable and may only be approximated on a finely subdividet grid as jumps. There does however exist som nontrivial cases where we may infer a analytical solution. One is the rather important **Geometric Brownian motion**.

<blockquote class = "prop">

**Proposition 5.2.** Consider the SDE

$$
dX_t=\alpha X_t\ dt+\sigma X_t\ dW_t,
$$

with $X_0=x_0$. Then the solution is given as

$$
X_t=x_0\cdot \exp\left\{\left(\alpha- \frac{\sigma^2}{2}\right)t+\sigma W_t\right\}.
$$

The expected value of $X$ is given as $E[X_t]=x_0e^{\alpha t}$.

</blockquote>

One other generalisation that is analytically solvable is the Linear SDE.

<blockquote class = "prop">

**Proposition 5.3.** Consider the SDE

$$
dX_t=(A X_t + b_t)\ dt+ \sigma_t\ dW_t,
$$

with $X_0=x_0$ and $A\in M(n,n)$ and $b_t$ being a real-valued function. Then the solution is given as

$$
X_t=e^{At}x_0+\int_0^te^{A(t-s)}b_s\ ds+\int_0^te^{A(t-s)}\sigma_s\ dW_s.
$$

Where we define the exponential of a matrix as below

$$
e^{At}=\sum_{k=0}^\infty A^k\frac{1}{k!}t^k.
$$

</blockquote>

In general with the SDE we have a partial differential operator $\mathcal{A}$ called the **infinitesimal operator** of $X$ which has some interesting analytical properties regarding $X$.

<blockquote class = "def">

**Definition 5.4.** Consider the SDE

$$
dX_t=\mu(t,X_t)\ dt+\sigma(t,X_t)\ dW_t.
$$

The partial differential operator $\mathcal{A}$ is defined, for any function $h\in C^2(\mathbb{R}^n)$, by

$$
\mathcal{A}h(t,x)=\sum_{i=1}^n\mu_i(t,x)\frac{\partial h}{\partial x_i}(x) + \frac{1}{2}\sum_{i,j=1}^n (\sigma(t,x)\sigma(t,x)^\top)_{ij}\frac{\partial^2h}{\partial x_i\partial x_j}(x).
$$

</blockquote>

We see that in terms of Ito's formula the operator is included as such

$$
df(t,X_t)=\left\{\frac{\partial f}{\partial t}(t,X_t)+\mathcal{A}f(t,x)\right\}\ dt+[\nabla_xf](t,X_t)\sigma(t,X_t)\ dW_t,
$$

where $\nabla_x$ is the gradient for function $h\in C^1(\mathbb{R}^n)$ as

$$
\nabla_xh(x)=\left[\frac{\partial h}{\partial x_1}(x),...,\frac{\partial h}{\partial x_n}(x)\right].
$$

### Exercises Week 2

**Exercise 1** *(Bjork 4.1)* Compute the stochastic differential $dZ_t$ when

  a. $Z_t=e^{\alpha t}$.
  b. $Z_t=\int_0^t g_s\ dW_s$, where $g$ is an adapted stochastic process.
  c. $Z_t=e^{\alpha W_t}$.
  d. $Z_t=e^{\alpha X_t}$, where $X$ has stochastic differential $dX_t=\mu\ dt + \sigma\ dW_t$ and $\mu,\sigma$ is constants.
  e. $Z_t=X_t^2$, where $X$ has stochastic differential $dX_t=\alpha X_t\ dt+\sigma X_t\ dW_t$.

<details>
<summary>**Solution (a).**</summary>

Let $Z_t=e^{\alpha t}$, then we see that $f(t,x)=e^{\alpha t}$ and the the following relevant derivatives is

$$
\frac{\partial f}{\partial t}(t,x)=\alpha e^{\alpha t},\hspace{10pt}\frac{\partial f}{\partial x}(t,x) =0,\hspace{10pt}\frac{\partial f}{\partial x^2}(t,x) =0.
$$

Since $Z$ does not depend on any stochastic process, we will content with $X_t=0$, that is $\mu_t=\sigma_t=0$. Then by theorem 4.11 (Ito's formula) we have

$$
dZ_t=\left(\alpha e^{\alpha t} +0+0\right)\ dt + 0=\alpha e^{\alpha t}\ dt,
$$

as expected. $\square$

</details>

<details>
<summary>**Solution (b).**</summary>

Let $Z_t=\int_0^t g_s\ dW_s$, where $g$ is an adapted stochastic process. We see that if we set $X_t=\int_0^t g_s\ dW_s$ then

$$
dX_t=0\ dt+g_t\ dW_t.
$$

Then we have the function $f(t,x)=x$ and the relevant derivatives are:

$$
\frac{\partial f}{\partial t}(t,x)=0,\hspace{10pt}\frac{\partial f}{\partial x}(t,x) =1,\hspace{10pt}\frac{\partial f}{\partial x^2}(t,x) =0.
$$

This then gives 

$$
dZ_t=\left(0+0+\frac{1}{2}g_t\cdot 0\right)\ dt + g_t\cdot 1\ dW_t=g_t\ dW_t,
$$

as expected. $\square$

</details>

<details>
<summary>**Solution (c).**</summary>

Let $Z_t=e^{\alpha W_t}$. Then we may set $X_t=W_t$ and we then have $\mu_t=0$ and $\sigma_t=1$. The function $f(t,x)=e^{\alpha x}$ and the relevant derivatives are:

$$
\frac{\partial f}{\partial t}(t,x)=0,\hspace{10pt}\frac{\partial f}{\partial x}(t,x) =\alpha e^{\alpha x},\hspace{10pt}\frac{\partial f}{\partial x^2}(t,x) =\alpha^2 e^{\alpha x}.
$$

Then the dynamics of $Z_t$ is as follows

\begin{align*}
dZ_t&=\left(0+0+\frac{1}{2}1^2\alpha^2e^{\alpha X_t}\right)\ dt + 1\alpha e^{\alpha X_t}\ dW_t\\
&=\frac{\alpha^2}{2}e^{\alpha X_t}\ dt +\alpha e^{\alpha X_t}\ dW_t\\
&=\frac{\alpha^2}{2}Z_t\ dt +\alpha Z_t\ dW_t.
\end{align*}

As desired. $\square$.

</details>

<details>
<summary>**Solution (d).**</summary>

Let $Z_t=e^{\alpha X_t}$, where $X$ has stochastic differential $dX_t=\mu\ dt + \sigma\ dW_t$ and $\mu,\sigma$ is constants. Then we have been given the definition of $X_t$ and we set $f(t,x)=e^{\alpha x}$. The relevant derivatives are then:

$$
\frac{\partial f}{\partial t}(t,x)=0,\hspace{10pt}\frac{\partial f}{\partial x}(t,x) =\alpha e^{\alpha x},\hspace{10pt}\frac{\partial f}{\partial x^2}(t,x) =\alpha^2 e^{\alpha x}.
$$

We may now derive the dynamics of $Z_t$:

\begin{align*}
dZ_t&=\left(0+\mu \alpha e^{\alpha X_t}+\frac{1}{2} \sigma^2\alpha^2 e^{\alpha X_t}\right)\ dt+\sigma \alpha e^{\alpha X_t}\ dW_t\\
&=\left(\mu+\frac{1}{2}\sigma^2\alpha\right)\alpha e^{\alpha X_t}\ dt+\sigma \alpha e^{\alpha X_t}\ dW_t\\
&=\left(\mu+\frac{1}{2}\sigma^2\alpha\right)\alpha Z_t\ dt+\sigma \alpha Z_t\ dW_t.
\end{align*}


As desired. $\square$.

</details>

<details>
<summary>**Solution (e).**</summary>

Let $Z_t=X_t^2$, where $X$ has stochastic differential $dX_t=\alpha X_t\ dt+\sigma X_t\ dW_t$. Then we set $f(t,x)=x^2$ and the relevant derivatives are:

$$
\frac{\partial f}{\partial t}(t,x)=0,\hspace{10pt}\frac{\partial f}{\partial x}(t,x) =2x,\hspace{10pt}\frac{\partial f}{\partial x^2}(t,x) =2.
$$

Given this we have the dynamics of $Z_t$ as follows

\begin{align*}
dZ_t&=\left(0 + \alpha X_t2X_t+\frac{1}{2}(\sigma X_t)^22\right)\ dt+\sigma X_t 2 X_t\ dW_t\\
&=\left(2\alpha +\sigma^2\right) X_t^2\ dt + 2\sigma X_t^2\ dW_t\\
&=\left(2\alpha +\sigma^2\right) Z_t\ dt + 2\sigma Z_t\ dW_t.
\end{align*}

As desired. $\square$.

</details>

**Exercise 2** *(Bjork 4.2)* Compute the stochastic differential for $Z$ when $Z_t=(X_t)^{-1}$ and $X$ has the stochastic differential

$$
dX_t=\alpha X_t\ dt + \sigma X_t\ dW_t.
$$

Furthermore, by using the definition $Z=X^{-1}$ you can in fact express the right-hand side of $dZ$ entirely in terms of $Z$ itself (rather then in terms of $X$). Thus $Z$ satisfies a stochastic differential equation. Which one?

<details>
<summary>**Solution.**</summary>

We see that $f(t,x)=1/x$ and so the relevant derivatives is

$$
\frac{\partial f}{\partial t}(t,x)=0,\hspace{10pt}\frac{\partial f}{\partial x}(t,x) =-\frac{1}{x^2},\hspace{10pt}\frac{\partial f}{\partial x^2}(t,x) =\frac{2}{x^3}.
$$

Then we by Ito's formula we have

\begin{align*}
dZ_t&=\left(0-\alpha X_t\frac{1}{X_t^2}+\frac{1}{2} \sigma^2 X_t^2\frac{2}{X_t^3}\right)\ dt-\sigma X_t\frac{1}{X_t^2}\ dW_t\\
&=\left(-\alpha \frac{1}{X_t}+ \sigma^2 \frac{1}{X_t}\right)\ dt-\sigma \frac{1}{X_t}\ dW_t\\
&=(\sigma^2-\alpha)Z_t\ dt-\sigma Z_t\ dW_t.
\end{align*}

We also notice that

$$
Z_t=\frac{1}{X_t}\Rightarrow dZ_t=d\left(\frac{1}{X_t}\right)=-\left(\frac{1}{X_t}\right)^2\ dX_t=-Z_t^2(\alpha X_t\ dt+\sigma X_t\ dW_t)
$$

Hence we may insert $X_t=Z_t^{-1}$ and optain

$$
dZ_t=-Z_t^2\left(\alpha\frac{1}{Z_t}\ dt + \sigma \frac{1}{Z_t}\ dW_t\right)=-\alpha Z_t\ dt-\sigma Z_t\ dW_t.
$$

Which clearly is faulty.. $\square$

</details>

**Exercise 3.** *(Bjork 4.3)* Let $\sigma(t)$ be a given deterministic function of time and define the process $X$ by

$$
X_t=\int_0^t\sigma(s)\ dW_s.
$$

Use the technique discribed in example 4.17 in order to show that the characteristic function of $X_t$ (for a fixed $t$) is given by

$$
E[e^{iuX_t}]=\exp\left\{-\frac{u^2}{2}\int_0^t\sigma^2(s)\ ds\right\},\ \ u\in\mathbb{R},
$$

thus showing that $X_t$ is normally distributed with zero mean and a variance given by

$$
Var[X_t]=\int_0^t\sigma^2(s)\ ds.
$$

<details>
<summary>**Solution.**</summary>

We follow along the lines of

  1. Determine the dynamics of $Z_t=e^{iuX_t}$ (for fixed $u$).
  2. Write the integral form of $Z_t$.
  3. Take expectation.
  4. Solve ODE.

"1)" Set $f(t,x)=e^{iuX_t}$ then the relevant derivatives are

$$
\frac{\partial f}{\partial t}(t,x)=0,\hspace{10pt}\frac{\partial f}{\partial x}(t,x) =iue^{iuX_t}=iuZ_t,\hspace{10pt}\frac{\partial f}{\partial x^2}(t,x) =i^2u^2e^{iuX_t}=-u^2Z_t.
$$

Recall that $dX_t=\sigma(t)\ dW_t$, then by Ito's formula we have

$$
dZ_t=\left(-\sigma(t)^2\frac{1}{2}u^2Z_t\right)\ dt+\sigma(t)iuZ_t\ dW_t.\tag{*}
$$

"2)" We can now write (*) on integral form as below

$$
Z_t=Z_0-\frac{u^2}{2}\int_0^t\sigma^2(s)Z_s\ ds+iu\int_0^t\sigma (s)Z_s\ dW_s,
$$

where $Z_0=e^{iuX_0}=1$.

"3)" Taking expectation now yields

$$
E[Z_t]=1-\frac{u^2}{2}\int_0^t\sigma^2(s)E[Z_s]\ ds+iuE\left[\int_0^t \sigma(s)Z_s\ dW_s\right]=1-\frac{u^2}{2}\int_0^t\sigma^2(s)E[Z_s]\ ds,
$$

since any expectaion of an integral wrt. a Brownian motion is 0 (proposition 4.5).

"4)" Now we see that the $t$-derivative gives

$$
dE[Z_t]=-\frac{u^2}{2}\sigma^2(t)E[Z_t]\ dt,\ \ E[Z_0]=1.
$$

This is a ordinary differential equation with solution $y(t)=\exp\{-u^2/2\int_0^t\sigma^2(s)\ ds\}$ (check by differentiating) hence

$$
E[e^{iuX_t}]=E[Z_t]=\exp\left\{-\frac{u^2}{2}\int_0^t\sigma^2(s)\ ds\right\}.
$$

We recognize this as the characteristic function of a normally distributed random variable with variance $\int_0^t\sigma^2(s)\ ds$ as desired. ($X_t$ follows this distributions since characteristic functions determine the distribution) $\square$

</details>

**Exercise 4** *(Bjork 4.4)* Suppose that $X$ has the stochastic differential

$$
dX_t=\alpha X_t\ dt+\sigma_t\ dW_t,
$$

where $\alpha$ is a real number and $\sigma_t$ is a integrable adapted stochastic process. Use the technique in example 4.17 in order to determine the function $m(t)=E[X_t]$.

<details>
<summary>**Solution.**</summary>

We follow the same steps as the previous exercise. We have been given the dynamics of $X$ hence we may write it on integral form.

$$
X_t=X_0+\alpha\int_0^tX_s\ ds+\int_0^t\sigma(s)\ dW_s.
$$

Then taking expectation now gives

$$
E[X_t]=X_0+\alpha\int_0^tE[X_s]\ ds.
$$

Hence $E[X_t]$ follows from the solution to the ODE below

$$
dE[X_t]=\alpha E[X_t]\Rightarrow E[X_t]=C\cdot\exp\{\alpha t\}.
$$

Then obviously $C=X_0$ and we arrive at the solution $E[X_t]=X_0e^{\alpha t}$, where $X_0$ is some deterministic value. $\square$

</details>

**Exercise 5** *(Bjork 4.5)* Suppose that the process $X$ has a stochastic differential

$$
dX_t=\mu_t\ dt+\sigma_t\ dW_t,
$$

and that $\mu_t\ge 0$ with probability one for all $t\ge 0$. Show that this implies that $X$ is a sub-martingale.

<details>
<summary>**Solution.**</summary>

Note that we are (strictly speaking) supposed to show adaptation and integrability, we will however only fokus on the submartingale property.

"$E[X_t\vert \mathcal{F}_s]\ge X_s$" Intuitively speaking, the statement is obvious since we have with probability one a positive upwards drift with Brownian distortion (i.e. martingale). Formally, we will show the statement by first writing $X_t$ on integral form

$$
X_t=x_0+\int_0^t\mu_s\ ds+\int_0^t\sigma_s\ dW_s.
$$

And so

$$
X_t-X_s=\int_s^t\mu_u\ du+\int_s^t\sigma_u\ dW_u.
$$

We then have

\begin{align*}
E[X_t\ \vert\ \mathcal{F}_s]-X_s&=E[X_t-X_s\ \vert\ \mathcal{F}_s]\\
&=E\left[\left.\int_s^t\mu_u\ du+\int_s^t\sigma_u\ dW_u\ \right\vert\ \mathcal{F}_s\right]\\
&=E\left[\left.\int_s^t\mu_u\ du\ \right\vert\ \mathcal{F}_s\right]+E\left[\left.\int_s^t\sigma_u\ dW_u\ \right\vert\ \mathcal{F}_s\right]\\
&=E\left[\left.\int_s^t\mu_u\ du\ \right\vert\ \mathcal{F}_s\right]\ge 0.
\end{align*}

Then adding $X_s$ to the above inequality yields the result. $\square$

</details>

**Exercise 6** *(Bjork 4.7)* The objective of this exercise is to give an argument for the formal identity

$$
dW_1(t)\cdot dW_2(t)=0,
$$

when $W_1$ and $W_2$ are independent Brownian motions. Let us therefore fix a time $t$, and divide the inerval $[0,t]$ into equidistant points $0=t_0<t_1<\cdots < t_n=t$, where $t_i=\frac{i}{n}\cdot t$. We use the notation

$$
\Delta W_i(t_k)=W_i(t_k)-W_i(t_{k-1}),\ i=1,2.
$$

Now define $Q_n$ by

$$
Q_n=\sum_{k=1}^n \Delta W_1(t_k)\cdot \Delta W_2(t_k).
$$

Show that $Q_n\to 0$ in $L^2$, i.e. show that

$$
E[Q_n]=0,\\
Var[Q_n]\to 0.
$$

<details>
<summary>**Solution.**</summary>

We wish to show the statement

$$
E[(Q_n-0)^2]=E[Q_n^2]\to 0,
$$

as $n\to \infty$. Recall that 

$$
Var[Q_n]=E[Q_n^2]-E[Q_n]^2,
$$

hence if $Q_n$ has mean 0, then showing convergence in $L^2$ is equivalent to showing variance going to 0. Let us start by showing the mean is 0.

We have that

\begin{align*}
Q_n&=\sum_{k=1}^n \Delta W_1(t_k)\cdot \Delta W_2(t_k)\\
&=\sum_{k=1}^n(W_1(t_k)-W_1(t_{k-1}))\cdot (W_2(t_k)-W_2(t_{k-1}))\\
&\stackrel{\mathcal{D}}{=}\sum_{k=1}^nXY,
\end{align*}

where $X,Y\sim\mathcal{N}(0,t_k-t_{k-1})=\mathcal{N}(0,1/n)$ and independent random variable. This is justified since the increments of the Brownian motion has mean 0 and variance equal to the increment size. Now this implies, that we need to show that $E[XY]=0$ and that $Var[XY]$ is sufficiently small in terms of $n$ such that it is summable. We see that

$$
E[XY]=E[X]E[Y]=0^2=0.
$$

Here we use independence. We now know that the mean is

$$
E[Q_n]=\sum_{k=1}^nE[XY]=0.
$$

We know from basic properties of variance that

\begin{align*}
Var(Q_n)&=\sum_{k=1}^n Var(XY)=\sum_{k=1}^n E[(XY)^2]\\
&=\sum_{k=1}^n\frac{1}{n^2}=\frac{1}{n^2}n\\
&=\frac{1}{n}\to0,\ n\to\infty.
\end{align*}

And so the result follows. $\square$

</details>

**Exercise 7** *(Bjork 4.8)* Let $X$ and $Y$ be given as the solutions to the following system of stochastic differential equations.

\begin{align*}
&dX_t=\alpha X_t\ dt-Y_t\ dW_t,\ &X_0=x_0,\\
&dY_t=\alpha Y_t\ dt + X_t\ dW_t,\ &Y_0=y_0.
\end{align*}

Note that the initial values $x_0$ and $y_0$ are deterministic constants.

  a. Prove that the process $R$ defined by $R_t=X_t^2+Y_t^2$ is deterministic.
  b. Compute $E[X_t]$.

<details>
<summary>**Solution (a).**</summary>

We see that

$$
dR_t=d(X_t^2+Y_t^2)=d(X_t^2)+d(Y_t^2)
$$

Hence we may start by considering de dynamics of the processes $X_t^2$ and $Y_t^2$. We see that for the process $Z_t=X_t^2$ we may set $f(t,x)=x^2$ and the relevant derivatives are

$$
\frac{\partial f}{\partial t}(t,x)=0,\ \frac{\partial f}{\partial x}(t,x)=2x,\ \frac{\partial^2 f}{\partial x^2}(t,x)=2.
$$

By Ito's formula we have

$$
d(X_t^2)=\left(\alpha X_t2X_t+Y_t^22\right)\ dt-Y_t2X_t\ dW_t=2(\alpha X_t^2+Y_t^2)\ dt-2X_tY_t\ dW_t.
$$

By the same concept we have

$$
d(Y_t^2)=\left(\alpha Y_t2Y_t+X_t^22\right)\ dt+X_t2Y_t\ dW_t=2(\alpha Y_t^2+X_t^2)\ dt+2X_tY_t\ dW_t.
$$

Combining we get the dynamics

\begin{align*}
dR_t&=2(\alpha X_t^2+Y_t^2)\ dt-2X_tY_t\ dW_t\\
&+2(\alpha Y_t^2+X_t^2)\ dt+2X_tY_t\ dW_t\\
&=(2\alpha +1)(X_t^2 + Y_t^2)\ dt\\
&=(2\alpha +1)R_t\ dt
\end{align*}

Hence $R_t$ has deterministic derivative and therefore a deterministic process. In fact, the solution to above is

$$
R_t=R_0\exp\left\{(2\alpha + 1)t\right\}=(x_0^2+y_0^2)e^{(2\alpha + 1)t},
$$

which is clearly deterministic. $\square$

</details>

<details>
<summary>**Solution (b).**</summary>

We start by acknowledging that the differential form of $X$ may be written on integral form:

$$
X_t=x_0+\alpha\int_0^tX_s\ ds-\int_0^tY_s\ dW_s.
$$

Taking expectation we see that

$$
E[X_t]=x_0+\int_0^tE[X_s]\ ds
$$

as the last term has mean 0 according to proposition 4.5. Then the above may be written on the differential form

$$
dE[X_t]=E[X_t]\ dt
$$

Hence we have that

$$
E[X_t]=x_0e^{t}.
$$

Hence $X_t$ has mean not depending on the tragetory of the sister-process $Y_t$. $\square$

</details>

## Week 3

### Table of Contents

  * [Partial differential equations (Chapter 5.5)](#partial-differential-equations)
  * [Self-financing portfolios (Chapter 6)](#self-financing-portfolios)
  * [Black-Scholes PDE (classic approach) and risk neutral valuation (Chapter 7.1-5)](#black-scholes-pde)

  * [Exercises](#exercises-week-3)

### Theory

#### Partial differential equations

<blockquote class = "prop">

**Proposition 5.5.** **(Feynmann-Kac)** Assume that $F$ is a solution to the boundary value problem

$$
\frac{\partial F}{\partial t}(t,x)+\mu(t,x)\frac{\partial F}{\partial x}(x,t)+\frac{1}{2}\sigma^2(t,x)\frac{\partial^2 F}{\partial x^2}(t,x)=0,
$$

with boundary condition $F(T,x)=\Phi(x)$. Assume furthermore that the process

$$
\sigma(s,X_s)\frac{\partial F}{\partial x}(s,X_s) \in \mathcal{L}^2
$$

as per definition 4.4, where $X$ is defined below. Then $F$ has the representation

$$
F(t,x)=E_{t,x}[\Phi(X_T)]=E[\Phi(X_T)\ \vert\ X_t=x],
$$

where $X$ satisfies the SDE

$$
dX_s=\mu(s,X_s)\ ds+\sigma(s,X_s)\ dW_s,
$$

with boundary condition $X_t=x$.

</blockquote>

<blockquote class = "prop">

**Proposition 5.6.** **(Feynmann-Kac)** Assume that $F$ is a solution to the boundary value problem

$$
\frac{\partial F}{\partial t}(t,x)+\mu(t,x)\frac{\partial F}{\partial x}(x,t)+\frac{1}{2}\sigma^2(t,x)\frac{\partial^2 F}{\partial x^2}(t,x)-rF(t,x)=0,
$$

with boundary condition $F(T,x)=\Phi(x)$. Assume furthermore that the process

$$
e^{-rs}\sigma(s,X_s)\frac{\partial F}{\partial x}(s,X_s) \in \mathcal{L}^2
$$

as per definition 4.4, where $X$ is defined below. Then $F$ has the representation

$$
F(t,x)=e^{-r(T-t)}E_{t,x}[\Phi(X_T)]=e^{-r(T-t)}E[\Phi(X_T)\ \vert\ X_t=x],
$$

where $X$ satisfies the SDE

$$
dX_s=\mu(s,X_s)\ ds+\sigma(s,X_s)\ dW_s,
$$

with boundary condition $X_t=x$.

</blockquote>

<blockquote class = "prop">

**Proposition 5.8.** **(Feynmann-Kac)** Assume that $F$ is a solution to the boundary value problem

$$
\frac{\partial F}{\partial t}(t,x)+\sum_{i=1}^n\mu_i(t,x)\frac{\partial F}{\partial x}(x,t)+\frac{1}{2}\sum_{i,j=1}^n C_{ij}(t,x)\frac{\partial^2 F}{\partial x^2}(t,x)-rF(t,x)=0,
$$

with boundary condition $F(T,x)=\Phi(x)$ and $C_{ij}=\sigma \sigma^\top$. Assume furthermore that the process

$$
e^{-rs}\sum_{i=1}^n\sigma_i(s,X_s)\frac{\partial F}{\partial x}(s,X_s) \in \mathcal{L}^2
$$

as per definition 4.4, where $X$ is defined below. Then $F$ has the representation

$$
F(t,x)=e^{-r(T-t)}E_{t,x}[\Phi(X_T)],
$$

where $X$ satisfies the SDE

$$
dX_s=\mu(s,X_s)\ ds+\sigma(s,X_s)\ dW_s,
$$

with boundary condition $X_t=x$.

</blockquote>

<blockquote class = "prop">

**Proposition 5.9.** Consider as given a vector process $X$ with generator $\mathcal{A}$, and a function $F(t,x)$. Then, modulo some integrability condition, the following hold:

  * The process $F(t,X_t)$ is a martingale relative to the filtration $\mathcal{F}^X$ if and only if $F$ satisfies the PDE
  $$
  \frac{\partial F}{\partial t}+\mathcal{A}F=0.
  $$
  * The process $F(t,X_t)$ is a martingale relative to the filtration $\mathcal{F}^X$ if and only if, for every $(t,x)$ and $T\ge t$, we have
  $$
  F(t,x)=E_{t,x}[F(T,X_T)].
  $$

</blockquote>

#### Self-financing portfolios

We move forward in this chapter by first defining a self-financing portfolio in discrete time and then by letting the step length tend to zero obtain the continuous time analogue.

##### Discrete time SF portfolio

We consider $N$ different adapted price processes $S^1,...,S^N$. We use the following definition.

<blockquote class = "def">

**Definition 6.1.** We use the following definitions.

  * $S_n^i$ is th price of asset $i$ at time $n$,
  * $h_n^i$ is the number of units of asset $i$ held during $[n,n+1)$, that is bought at time $n$,
  * $d_n^i$ is the dividends from asset $i$ in the time-interval $[n-1,n)$, that is recieved at time $n$,
  * $h_n$ is the portfolio $(h_n^1,...,h_n^N)$ held during $[n,n+1)$,
  * $c_n$ is the consumption i.e. withdrawel at time $n$ (negative being deposits/saving),
  * $V_n$ is the value of the portfolio just before time $n$ i.e. of the portfolio $h_{n-1}$ at time $n$.

</blockquote>

We are now ready to define the self-financing portfolio

<blockquote class = "def">

**Definition 6.2.** A **self-financing portfolio supporting the consumption stream** $\mathbf{c}$ is a portfolio adhering to the **budget constraint** given as

$$
h_{n+1}S_{n+1}+c_{n+1}=h_nS_{n+1}+h_nd_{n+1.}
$$

The interpretation being, that we may only use funds obtained from selling the old portfolio $h_n$ and recieved in dividends to buy the new portfolio $h_{n+1}$ and consume the amount $c_{n+1}$.

</blockquote>

Before studying the self-financing portfolio we define the operator $\Delta$ (in definition 6.3) as the increment $\Delta x_n=x_{n+1}-x_n$ of a countable sequence $(x_n)_{n\in\mathbb{N}_0}$. Notice that we define the increment forward so the increment $n$ is the increment over the time period $[n,n+1)$ with the first increment being $[0,1)$. Using this notation we can derive the lemma below.

<blockquote class = "lem">

**Lemma 6.4.** For any pair of sequences of real numbers $(x_n)_{n\in\mathbb{N}_0}$ and $(y_n)_{n\in\mathbb{N}_0}$ we have the relations

\begin{align*}
\Delta(xy)_n&=x_n\Delta y_n+y_{n+1}\Delta x_n,\\
\Delta(xy)_n&=y_n\Delta x_n+x_{n+1}\Delta y_n,\\
\Delta(xy)_n&=x_n\Delta y_n+y_n\Delta x_n+\Delta x_n\Delta y_n.
\end{align*}

This is also valid if the sequances are $N$-dimensional, where we interpret the products above as scalar products ($xy^\top$).

</blockquote>

Using these definitions and the lemma above we see that the dynamics of the self-financing portfolio is given below.

<blockquote class = "prop">

**Proposition 6.6.** The dynamics of any self-financing portfolio supporting the consumption stream $c$ are given by

$$
\Delta V_n=h_n \Delta S_n+h_nd_{n+1}-c_{n+1},
$$

or, in more detail

$$
\Delta V_n=\sum_{i=1}^Nh_n^i(\Delta S_n^i+d^i_{n+1})-c_{n+1}.
$$

</blockquote>

We may rewrite the dividends as accumulating dividends $D^i_n=\sum_{k=1}^nd^i_k$ and see that $d_{n+1}^i=\Delta D^i_n$ and so the above condition is equivalent with.

<blockquote class = "prop">

**Proposition 6.8.** The dynamics of any self-financing portfolio supporting the consumption stream $c$ are given by

$$
\Delta V_n=h_n \Delta S_n+h_n\Delta D_n-c_{n+1},
$$

or, in more detail

$$
\Delta V_n=\sum_{i=1}^Nh_n^i(\Delta S_n^i+\Delta D^i_n)-c_{n+1}.
$$

</blockquote>

##### Continuous time SF portfolio

Formulating the dynamics of the self-financing portfolio in continuous time is easy work given the discrete setup above. However since we now are in continuous time we will change the $n$ with a $t$ and cosider the behavour $V_{t+dt}-V_t$ as we let $dt\to 0$. First we formulate some basic notation.

<blockquote class = "def">

**Definition 6.9.** We use the following definitions.

  * $S_t^i$ is th price of asset $i$ at time $t$,
  * $h_t^i$ is the number of units of asset $i$ held at time $t$,
  * $D_t^i$ is the cumulative dividend processs for asset $i$,
  * $h_t$ is the portfolio $(h_t^1,...,h_t^N)$ held at time $t$,
  * $c_t$ is the consumption rate at time $n$ (negative being deposits/saving),
  * $V_t$ is the value of the portfolio at time $t$ i.e. of the portfolio $h_t$ at time $t$.

</blockquote>

Given these definitions we may define a portfolio strategy that is self-financing.

<blockquote class = "def">

**Definition 6.10.** Let $S$ be and adapted $N$-dimensional price process. We define the following

  1. A **portfolio strategy** is any adapted $N$-dimensional process $h$.
  2. The **value process** $V^h$ corresponding to the portfolio $h$ is given by
  $$
  V_t^h=\sum_{i=1}^N h_t^iS_t^i.
  $$
  3. A **consumption process** is any adapted one-dimensional process $c$.
  4. A portfolio-consumption pair $(h,c)$ is called **self-financing** if the value process $V^h$ satisfies the condition
  $$
  dV_t^h=\sum_{i=1}^N h_t^i(dS_t^i+d D^i_t)-c_t\ dt,
  $$
  i.e. if
  $$
  dV_t^h=h_t\ dS_t + h_t\ dD_t -c_t\ dt.
  $$
  5. The **gain process** $G$ is defined by
  $$
  G_t=S_t+D_t
  $$
  so we can write the self-financing condition as
  $$
  dV_t=h_t\ dG_t-c_t\ dt.
  $$
  6. The portfolio $h$ is said to be **Markovian** if it is of the form
  $$
  h_t=h(t,S_t),
  $$
  for some function $h : \mathbb{R}_+\times \mathbb{R}^N\to\mathbb{R}^N$.

</blockquote>

##### Portfolio weights

<blockquote class = "def">

**Definition 6.11.** For a given portfolio $h$ the corresponding **relative portfolio** or **portfolio weights** $w$ are defined by

$$
w_t^i=\frac{h_t^iS_t^i}{V_t^h},\ i=1,...,N,
$$

so, in particular, we have $\sum_{i=1}^N w_i=1$.

</blockquote>

<blockquote class = "lem">

**Lemma 6.12.** A portfolio-consumption par $(h,c)$ is self-financing if and only if

$$
dV_t^h=V_t^h\sum_{i=1}^N w_t^i\frac{dS_t^i+dD_t^i}{S_t^i}-c_t\ dt.
$$

</blockquote>

<blockquote class = "lem">

**Lemma 6.13.** Consider the case with no dividends. Let $c$ be a consumption process, and assume that there exist a scalar process $Z$ and a vector process $q=(q^1,...,q^N)$ such that

$$
dZ_t=Z_t\sum_{i=1}^N q_t^i\frac{dS_t^i}{S_t^i}-c_t\ dt,
$$

and $\sum_{i=1}^Nqq^i=1$. Now define a portfolio $h$ by

$$
h_t^i=\frac{q_t^iZ_t}{S_t^i}.
$$

Then the value process $V^h$ is given by $V^h=Z$, the pair $(h,c)$ is self-financing, and the corresponding relative portfolio $w$ is given by $w=q$.

</blockquote>

#### Black-Scholes PDE

The Black-Scholes model revolves arround SDE's as seen above. In this model we have two assets a risk free asset $B$ and a stochastic priced asset $S$. We therefore start by defining what we mean by a quote-on-qoute *risk free* asset.

<blockquote class = "def">

**Definition 7.1.** The price process $B$ is the price of a **risk free** asset if it has the dynamics

$$
dB_t=r_t B_t\ dt,
$$

where $r$ is any $\mathcal{F}_t$ adapted process.

</blockquote>

We see from this definition that the meaning of "risk free" is the property, that $B$ is priced locally deterministic in the sence that $r$ is adapted and therefore known at time $t$ and we therefore know the yield on a short term basis. This is also why we may call $r$ the **short interest rate**. Given the dynamics above, we know that $B$ in fact is represented by the process

$$
B_t=B_0e^{\int_0^tr_s\ ds},
$$

for some $B_0$ initial value. We will moving forward assume that $B_0=1$. The stochastic asset $S$ has dynamics.

$$
dS_t=\mu(t,S_t)\ dt + \sigma(t,S_t)\ dW_t,
$$

where as usual $\mu$ and $\sigma$ are deterministic functions and $W_t$ is a standard Brownian motion. Note that the risk free asset has a similarly process with $\sigma = 0$. We may now include this in the definition of the Black-Scholes model.

<blockquote class = "def">

**Definition 7.2.** The **Black-Scholes model** consists of two assets with dynamics given by

\begin{align*}
dB_t&=rB_t\ dt,\\
dS_t&=\mu S_t\ dt+\sigma S_t\ dW_t,
\end{align*}

where $r,\mu,\sigma$ are deterministic constants.

</blockquote>

<blockquote class = "def">

**Definition 7.3.** A **zero coupon bond** with maturity $T$ (henceforth "$T$-bond") is an asset which pays the holder the face value 1 dollar at time $T$. The price at time $n$ of a $T$-bond is denoted by $p(n,T)$.

</blockquote>

<blockquote class = "def">

**Definition 7.4.** The (possible stochastic) discrete **short rate** $r_n$, for the period $[n,n+1]$, is defined as

$$
p(n,n+1)=\frac{1}{1+ r_n}.
$$

</blockquote>

From this short rate we may derive the dynamics of the bank account recieving zero-coupon rates for each distinct time interval.

<blockquote class = "def">

**Definition 7.5.** The dynamics of the bank account are given by

$$
\Delta B_n=r_n B_n.
$$

</blockquote>

##### Contingent Claims and Arbitrage

<blockquote class = "def">

**Definition 7.6.** A **European call option** with **exercise price** (or strike price) $K$ and **time of maturity** (exercise date) $T$ on the **underlying asset** $S$ is a contract defined by the following clauses:

  * The holder of the option has, at time $T$, the right to buy one share of the underlying stock at the price $K$ dollars from the underwriter of the option.
  * The holder of the option is in no way obliged to buy the underlying stock.
  * The right to buy the underlying stock at the price $K$ can only be exercised at the precise time $T$.

</blockquote>

Obviously, we also have the **european put** option which gives the owner the right to sell an asset at price $K$ at time $T$. Let os formally define a contingent claim.

<blockquote class = "def">

**Definition 7.7.** Consider a financial market with vector price process $S$. A **contingent claim** with **date of maturity** $T$, also called a $T$-claim, is any random variable $\mathcal{X}\in\mathcal{F}_T^S$. A contingent claim $\mathcal{X}$ is called a **simple** claim if it is of the form $\mathcal{X} = \Phi(S_t)$. The function $\Phi$ is called the **contract function**.

</blockquote>

<blockquote class = "def">

**Definition 7.8.** An **arbitrage** possibility on a financial market is a self-financed portfolio $h$ such that

\begin{align*}
V^h(0)&=0,\\
P(V_T^h\ge0)&=1,\\
P(V_T^h>0)&>0.
\end{align*}

We say that the market is **arbitrage free** if there are no arbitrage possibilities.

</blockquote>

<blockquote class = "def">

**Definition 7.9.** Suppose that there exists a self-financing portfolio $h$, such that the value process $V^h$ has the dynamics

$$
d V_t^h=k_tV_t^h\ dt,
$$

where $k$ is an adapted process. Then it must hold that $k_t=r_t$ for all $t$, ore there exists an arbitrage possibility.

</blockquote>

<blockquote class = "thm">

**Theorem 7.10.** **(Black-Scholes equation)** Assume that the market is specified by the equations

\begin{align*}
dB_t&=rB_t\ dt,\\
dS_t&=\mu(t,S_t) S_t\ dt+\sigma(t,S_t)S_t\ dW_t,
\end{align*}

and that we want to price a contingent claim of the form $\mathcal{X}=\Phi(S_t)$. Then the only pricing function of the form $\Pi_t[\Phi(S_t)]=F(t,S_t)$ which is consistent with the absence of arbitrage in the market $[B_t,S_t,\Pi_t]$ is when $F$ is the solution of the following boundary value problem in the domain $[0,T]\times\mathbb{R}_+$:

\begin{align*}
F_t(t,s)+rsF_s(t,s)+\frac{1}{2}s^2\sigma^2(t,s)F_ss(t,s)-rF(t,s)&=0,\\
F(T,s)&=\Phi(s).
\end{align*}

</blockquote>

##### Risk Neutral Valuation

<blockquote class = "thm">

**Theorem 7.11.** **(Risk Neutral Valuation)** The arbitrage free price of the claim $\Phi(S_t)$ is given by $\Pi_t[\Phi]=F(t,S_t)$, where $F$ is given by the formula

$$
F(t,s)=e^{-r(T-t)}E^Q_{t,s}[\Phi(S_T)],
$$

where the $Q$-dynamics of $S$ are those of

$$
dS_t=rS_t\ dt+S_t\sigma(t,S_t)\ dW_t^Q.
$$

</blockquote>

<blockquote class = "prop">

**Property 7.12.** **(The Martingale Property)** In the Black-Scholes model, the price process $\Pi_t$ for every traded asset, be it the underlying or derivate asset, has the property the the normalized price process

$$
Z_t=\frac{\Pi_t}{B_t},
$$

(including $S_t/B_t$) is a martingale under the measure $Q$.

</blockquote>

### Exercises Week 3

**Exercise 1** *(Bjork 5.1)* Show that the scalar SDE

$$
\left\{
\begin{matrix}
dX_t=\alpha X_t\ dt + \sigma\ dW_t,\\
X_0 = x_0,
\end{matrix}\right.
$$

has the solution

$$
X(t)=e^{\alpha t}x_0+ \sigma\int_0^te^{\alpha(t-s)}\ dW_s,
$$

by differentiating $X$ as defined by the equation above and showing that $X$ so defined satisfies the SDE.

<details>
<summary>**Solution.**</summary>

We move forward by rewriting the solution in terms of three processes $Z$, $Y$ and $R$ as

$$
X_t=\underbrace{x_0e^{\alpha t}}_{:=Y_t}+\underbrace{\sigma e^{\alpha t}}_{:=Z_t} \underbrace{\int_0^t e^{-\alpha s}\ dW_s}_{R_t}=Y_t+Z_t\cdot R_t.
$$

We furthermore see easily that the dynamics of the processes individually has dynamics

\begin{align*}
d Y_t&=\alpha x_0e^{\alpha t}\ dt=\alpha Y_t\ dt,\ &Y_0=x_0,\\
d Z_t&=\alpha \sigma^{\alpha t}\ dt=\alpha Z_t\ dt,\ &Z_0=\sigma,\\
d R_t&=e^{-\alpha t}\ dW_s,\ &R_0=0.
\end{align*}

We then have the following function

$$
f\left(t,y,z,r\right)=y+zr.
$$

With the following multi-dimensional process

$$
dM_t=\begin{bmatrix}\alpha Y_t\\ \alpha Z_t\\ 0\end{bmatrix}dt+\begin{bmatrix}0 &0  &0 \\ 0 & 0 &0 \\ 0 & 0 & e^{-\alpha t}\end{bmatrix}\begin{bmatrix}dW_t\\ dW_t\\ dW_t\end{bmatrix},
$$

with 

$$
C=\sigma \sigma^\top =\begin{bmatrix}0 &0  &0 \\ 0 & 0 &0 \\ 0 & 0 & e^{-\alpha t}\end{bmatrix}^2=\begin{bmatrix}0 &0  &0 \\ 0 & 0 &0 \\ 0 & 0 & e^{-2\alpha t}\end{bmatrix}.
$$

That is $X_t=f(t,M_t)$. We can then use the multidimensional version of Ito's formula.

\begin{align*}
dX_t&=df(t,M_t)\\
&=\left(\frac{\partial f}{\partial t}(t,M_t)+\sum_{i=1}^3\mu_i \frac{\partial f}{\partial x^i}(t,M_t)+\frac{1}{2}\sum_{i,j=1}^3 C^{ij}_t\frac{\partial^2 f}{\partial x^i\partial x^j}(t,M_t)\right)\ dt + \sum_{i=1}^3 \frac{\partial f}{\partial x^i}(t,M_t) \sigma^i_t\ dW_t\\
&=\left(0+\alpha Y_t+\alpha Z_t R_t\right)\ dt + Z_te^{-\alpha t}\ dW_t\\
&=\left(\alpha x_0e^{\alpha t}+\alpha \sigma e^{\alpha t} \int_0^t e^{-\alpha \sigma}\ dW_s\right)\ dt + \sigma e^{\alpha t}e^{-\alpha t}\ dW_t\\
&=\left(\alpha x_0e^{\alpha t}+\alpha \sigma  \int_0^t e^{(t-s)\alpha }\ dW_s\right)\ dt + \sigma \ dW_t\\
&=\alpha X_t\ dt + \sigma \ dW_t.
\end{align*}

Then this solution does in fact satisfies the differential form. We furthermore have that $X_0=x_0$ and the desired result follows. $\square$

</details>

**Exercise 2** *(Bjork 5.5)* Suppose that $X$ satisfies the SDE

$$
dX_t = \alpha X_t\ dt + \sigma X_t\ dW_t.
$$

Now define $Y$ by $Y_t = X^\beta_t$, where $\beta$ is a real number. Then $Y$ is also a GBM process. Compute $dY_t$ and find out which SDE $Y$ satisfies.

<details>
<summary>**Solution.**</summary>

If we set $f(t,x)=x^\beta$, we have the relevant derivatives as follows

$$
\frac{\partial f}{\partial t}(t,x)=0,\ \frac{\partial f}{\partial x}(t,x)=\beta x^{\beta -1},\ \frac{\partial^2 f}{\partial x^2}(t,x)=\beta (\beta -1) x^{\beta -2}.
$$

Then by applying Ito's formula we have

\begin{align*}
dY_t&=df(t,X_t)\\
&=\left(0 + \beta X_t^{\beta -1}\alpha X_t+\frac{1}{2}\sigma ^2X_t^2\beta (\beta -1) X_t^{\beta -2}\right)\ dt+\sigma X_t\beta X_t^{\beta -1} \ dW_t\\
&=\left(\alpha \beta+\frac{1}{2}\sigma ^2\beta (\beta -1)\right) X_t^{\beta}\ dt+\sigma \beta X_t^{\beta } \ dW_t\\
&=\left(\alpha \beta+\frac{1}{2}\sigma ^2\beta (\beta -1)\right) Y_t\ dt+\sigma \beta Y_t \ dW_t\\
&= \alpha^Y Y_t\ dt + \sigma^Y Y_t\ dW_t,
\end{align*}

where $\alpha^Y=\left(\alpha \beta+\frac{1}{2}\sigma ^2\beta (\beta -1)\right)$ and $\sigma^Y =\sigma \beta$. Futhermore $Y_0=y_0=x_0^\beta$. Then by definition of GBM we have that $Y_t$ is a GBM as desired. $\square$

</details>

**Exercise 3** *(Bjork 5.6)* Suppose that $X$ satisfies the SDE

$$
dX_t = \alpha X_t\ dt + \sigma X_t\ dW_t,
$$

and $Y$ satisfies

$$
dY_t = \gamma Y_t\ dt+\delta Y_t\ dV_t,
$$

where $V$ is a Brownian motion which is independent of $W$. Define $Z=X/Y$ and derive an SDE for $Z$ by computing $dZ$. If $X$ is nominal income and $Y$ describe inflation then $Z$ describes real income.

<details>
<summary>**Solution.**</summary>

We have that for the function $f(t,x,y)=x/y$ and wish to determine the derivative of the stochastic process $Z_t=f(t,X_t,Y_t)$. We do this by applying Ito's formula in the multidimensional case. That is

\begin{align*}
df(t,X_t,Y_t)&=\frac{\partial f}{\partial t}(t,X_t,Y_t)\ dt + \frac{\partial f}{\partial x}(t,X_t,Y_t)\ dX_t + \frac{\partial f}{\partial y}(t,X_t,Y_t)\ dY_t\\
&+\frac{1}{2}\frac{\partial^2 f}{\partial x^2}(t,X_t,Y_t)(dX_t)^2 + \frac{1}{2}\frac{\partial^2 f}{\partial y^2}(t,X_t,Y_t)(dY_t)^2\\
&+\frac{1}{2}\frac{\partial^2 f}{\partial x\partial y}(t,X_t,Y_t)(dX_t)(dY_t)\\
&=\frac{1}{Y_t}(\alpha X_t\ dt + \sigma X_t\ dW_t)-\frac{X_t}{Y_t^2}(\gamma Y_t\ dt+\delta Y_t\ dV_t)+\frac{1}{2}2\frac{X_t}{Y_t^3}(\gamma Y_t\ dt+\delta Y_t\ dV_t)^2\\
&-\frac{1}{2}\frac{1}{Y_t^2}(\gamma Y_t\ dt+\delta Y_t\ dV_t)(\alpha X_t\ dt + \sigma X_t\ dW_t)
\end{align*}

Calculating further gives

\begin{align*}
(dY_t)^2&=\gamma^2 Y_t^2 (dt)^2+\delta^2Y_t^2 (dV_t)^2+2\gamma Y_t\delta Y_t\ dt\cdot dV_t\\
&=0 +\delta^2Y_t^2 dt + 0=\delta^2Y_t^2 dt\\
(dX_t)(dY_t)&=(\gamma Y_t\ dt+\delta Y_t\ dV_t)(\alpha X_t\ dt + \sigma X_t\ dW_t)\\
&=\gamma Y_t \alpha X_t\ (dt)^2 +\gamma Y_t\sigma X_t\ dt\cdot dW_t\\
&+\delta Y_t \alpha X_t\ dt\cdot dV_t+\gamma Y_t\sigma X_t\ (dW_t)(dV_t)\\
&=0+0+0+0=0
\end{align*}

Hence we conclude that

\begin{align*}
df(t,X_t,Y_t)&=\alpha\frac{X_t}{Y_t}\ dt + \sigma \frac{X_t}{Y_t}\ dW_t-\gamma \frac{X_tY_t}{Y_t^2}\ dt+\delta \frac{X_tY_t}{Y_t^2}\ dV_t\\
&+\frac{1}{2}2\frac{X_t}{Y_t^3}\delta^2Y_t^2 dt\\
&=\left(\alpha Z_t-\gamma Z_t+Z_t\delta^2\right)\ dt+ \sigma Z_t\ dW_t+\delta Z_t\ dV_t\\
&=\left(\alpha -\gamma +\delta^2\right)Z_t\ dt+ \sigma Z_t\ dW_t+\delta Z_t\ dV_t.
\end{align*}

As desired the above is the SDE for the process $Z_t$. $\square$

</details>

**Exercise 4** *(Bjork 5.9)* Use a stochastic representation result in order to solve the following boundary value problem in the domain $[0,T]\times\mathbb{R}$.

$$
\frac{\partial F}{\partial t}+\mu x\frac{\partial F}{\partial x}+\frac{1}{2}\sigma^2x^2\frac{\partial^2F}{\partial x^2}=0,
$$

with $F(T,x)=\log(x^2)$. Here $\mu$ and $\sigma$ are assumed to be know constants.

<details>
<summary>**Solution.**</summary>

We use proposition 5.5 Feymann-Kac with $\mu(t,x)=\mu x$ and $\sigma(t,x)=\sigma x$. We know that, given that the process

$$
\sigma X_t \frac{\partial F}{\partial x}(x,X_t)\in \mathcal{L}^2,
$$

Then $F$ has stochastic representation

$$
F(t,x)=E[\log(X_T^2)\ \vert\ X_t=x],
$$

with stochastic process $X_t$ satisfying the SDE

$$
dX_t=\mu X_t\ dt+\sigma X_t\ dW_t,\hspace{20pt} X_t=x.
$$

Now, since $X_t$ satisfies the above SDE, we see that $X_t$ is a GBM. Then by proposition 5.2 we have

$$
X_T=x\exp\left\{\left(\mu - \frac{1}{2}\sigma^2\right)(T-t)+\sigma(W_T-W_t)\right\}.
$$

Inserting this we find that

\begin{align*}
F(t,x)&=E\left.\left[\log(x^2\exp\left\{\left(2\mu - \sigma^2\right)(T-t)+2\sigma(W_T-W_t)\right\})\ \right\vert\ X_t=x\right]\\
&=E\left.\left[\log(x^2)+\left(2\mu - \sigma^2\right)(T-t)+2\sigma(W_T-W_t)\ \right\vert\ X_t=x\right]\\
&=2\log(x)+\left(2\mu - \sigma^2\right)(T-t)+2\sigma E\left.\left[W_T-W_t\ \right\vert\ X_t=x\right]\\
&=2\log(x)+\left(2\mu - \sigma^2\right)(T-t).
\end{align*}

Using that the Brownian motion has increments with mean 0. $\square$

</details>

**Exercise 5** *(Bjork 5.13)* Solve the boundary value problem

$$
\frac{\partial F}{\partial t}+\frac{1}{2}\sigma^2 \frac{\partial^2F}{\partial x^2}++\frac{1}{2}\delta^2\frac{\partial^2F}{\partial y^2}=0,
$$

with $F(T,x,y)=xy$.

<details>
<summary>**Solution.**</summary>



</details>

**Exercise 6** *(Exam 2017/18, problem 1, question (a)-(b))*

<details>
<summary>**Solution.**</summary>



</details>

**Exercise 7** *(Exam 2019/20, problem 1, question (a))*

<details>
<summary>**Solution.**</summary>



</details>

**Exercise 8** *(Exam 2020/21, problem 1, question (a)-(b))*

<details>
<summary>**Solution.**</summary>



</details>

## Week 4

### Table of Contents

  * [Black-Scholes formula (Chapter 7.6, see also Remark to Black-Scholes formula)](#black-scholes-formula)
  * [Completeness and hedging (Chapter 8)](#completeness-and-hedging)
  * [Put-call parity (Chapter 10.1)](#put-call-parity)
  * [The Greeks (Chapter 10.2)](#the-greeks)
  * [Risk neutral valuation formula (Chapter 11.6)](#risk-neutral-valuation-formula)
  * [Equivalent probability measures (Appendix A.11, B.6 and C.3)](#equivalent-probability-measures)

  * [Exercises](#exercises-week-4)
  
### Theory

#### Black-Scholes formula

```{r,echo=FALSE,include=TRUE,wrapF = TRUE}
set.seed(10)
mu <- 0.15
sigma <- 0.35
r <- 0.04
N <- 1000 #Observations pr. year
T <- 10
t <- (0:(T*N))/N
deltaW <- rnorm(length(t)-1,mean =0, sd = sqrt(1/N))
S_0 <- 1
K <- 1.2
d_1 <- (log(S_0/K)+(r+0.5*sigma**2)*(T-0))/(sigma*sqrt(T-0))
d_2 <- d_1 - sigma*sqrt(T-0)
Pi_0 <- S_0 * pnorm(d_1)-exp(-r*(T-0))*K*pnorm(d_2)
W_B_0 <- (Pi_0-S_0*pnorm(d_1))/Pi_0
W_S_0 <- 1 - W_B_0
Prices <- data.frame(t = t,
                     S = S_0,
                     B = exp(r*t),
                     Pi = Pi_0,
                     W_B = W_B_0,
                     Value = Pi_0,
                     Phi = max(S_0-K,0))
for (i in 2:length(t)){
  S_t <- Prices[i-1,"S"]
  S_t <- S_t+S_t*mu/N+S_t*sigma*deltaW[i-1]
  Prices[i,"S"] <- S_t
  Prices[i,"Value"] <- Prices[i-1,"Value"]*(1+((S_t/Prices[i-1,"S"]-1)*(1-Prices[i-1,"W_B"])+(Prices[i,"B"]/Prices[i-1,"B"]-1)*Prices[i-1,"W_B"]))
  d_1 <- (log(S_t/K)+(r+0.5*sigma**2)*(T-Prices[i,"t"]))/(sigma*sqrt(T-Prices[i,"t"]))
  d_2 <- d_1 - sigma*sqrt(T-Prices[i,"t"])
  Pi <- S_t * pnorm(d_1)-exp(-r*(T-Prices[i,"t"]))*K*pnorm(d_2)
  Prices[i,"Pi"] <- Pi
  W_B <- (Pi-S_t*pnorm(d_1))/Pi
  Prices[i,"W_B"] <- W_B
  Prices[i,"Phi"] <- max(S_t-K,0)
}
p1 <- ggplot2::ggplot(data = Prices) + geom_line(aes(x=t,y=S), col = "black") + geom_line(aes(x=t,y=B),col = "blue") + geom_hline(yintercept = K, col = "red") +
  labs(title = "Realisation of a Black-Scholes model",
       y="S (black), B (blue), K (red)",
       caption = "mu = 0.15, sigma = 0.35, T= 10 (N=10*1000)") +
  theme_bw() +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 12),
        title = element_text(size = 16),
        plot.caption  = element_text(size = 10))
p2 <- ggplot2::ggplot(data = Prices)+ geom_line(aes(x=t,y=Pi), col = "red") +geom_line(aes(x=t,y=Value), col = "black") + geom_line(aes(x=t,y=Phi), col = "blue") +
  labs(title = "Pricing and profit in Black-Scholes",
       y="Pi (red), V^h (black), (S-K)^+ (blue)",
       caption = "Price in red behind the value process of the replicating portfolio.") +
  theme_bw() +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 12),
        title = element_text(size = 16),
        plot.caption  = element_text(size = 10))
ggpubr::ggarrange(p1,p2,nrow = 2)
```

This chapter will center on deriving the famous Black-Scholes formula. We start by laying out the assumptions of the model. We have a market consiting of two assets: a stochastic prices asset $S$ and a risk free asset $B$. The prices processes have dynamics:

\begin{align*}
dS_t&=\mu S_t\ dt+\sigma S_t\ dW_t,\\
dB_t&=r B_t\ dt,
\end{align*}

where $S_0=s$ and $B_0=1$ (by assumption). Now from Feymann-Kac and the definition of arbitrage we know that a simple claim $\Phi(S_t)$ has the arbitrage free price given by the risk neutral valueation formula.

$$
F(t,s)=e^{-r(T-t)}E^Q_{t,s}[\Phi(S_T)],
$$

where $Q$ is a probability measure, namely a Martingale measure, such that the dynamics of $S$ under this measure is

$$
dS_t=r S_t\ dt+\sigma S_t\ dW^Q_t,
$$

with $W_t^Q$ being a Brownian motion wrt. to the probability measure $Q$ (not $P$). The above still has the initial condition $S_0=s$. Given these assumptions we may formulate the Black-Scholes formula.

<blockquote class = "thm">

**Theorem 7.13.** **(Black-Scholes formula)** The price of the european call option with strikeprice $K$ and maturity $T$ (contract function $\Phi(S_t)=\left( S_t - K\right)^+$) takes the form $\Pi_t=F(t,s)$, where

$$
F(t,s)=s N(d_1(t,s))-e^{-r(T-t)}KN(d_2(t,s)),\tag{7.52}
$$

where $N$ is the distribution-function for an $\mathcal{N}(0,1)$-distributed random variable and

\begin{align*}
d_1(t,s)&=\frac{1}{\sigma \sqrt{T-t}}\left(\log\left(\frac{s}{K}\right)+\left(r+\frac{1}{2}\sigma^2\right)(T-t)\right),\tag{7.53}\\
d_2(t,s)&=d_1(t,s)-\sigma\sqrt{T-t}.\tag{7.54}
\end{align*}

</blockquote>

<details>
<summary>**Proof.**</summary>

We let the market be given in terms of the price processes $S$ and $B$ with dynamics.

\begin{align*}
dS_t&=\mu S_t\ dt+\sigma S_t\ dW_t,\\
dB_t&=r B_t\ dt,
\end{align*}

with $B_t=1$ and $S_t=s$. We assume that $\mu,\sigma, r$ are deterministic real numbers. Consider the contingent claim 

$$
\Phi(S_t)=\left( S_t - K\right)^+,
$$

that is the European call option. Let $Q$ be a martingale measure such that the dynamics of $S$ may be written as

$$
dS_t=r S_t\ dt+\sigma S_t\ dW^Q_t,
$$

then $S_t$ is clearly a GBM wrt. the measure $Q$. Therefore we know the solution given in terms of the increment of the Brownian motion $W^Q$ as follows

$$
S_u=s\cdot \exp\left\{\left(r-\frac{1}{2}\sigma^2\right)(u-t)+\sigma\left(W_u^Q-W_t^Q\right)\right\},
$$

for some initial condition $S_t=s$. From theorem 7.10 we know that the only pricing function which takes the form

$$
\Pi_t[\Phi(S_T)]=F(t,S_t),
$$

can only be consistent with the absence of arbitrage if $F$ is the solution the the boundary value problem

\begin{align*}
F_t(t,s)+rsF_s(t,s)+\frac{1}{2}s^2\sigma^2F_{ss}(t,s)-rF(t,s)&=0,\\
F(T,s)&=\Phi(s).
\end{align*}

From Feymann-Kac we then know that the stochastic representation of such a solution take the form

$$
F(t,s)=e^{-r(T-t)}E_{t,s}^Q[\Phi(S_T)].
$$

Here the superscript refers to taking mean value with respect to the measure $Q$. This gives the solution to the pricing function

$$
F(t,s)=e^{-r(T-t)}\int \Phi(S_T)\ dQ.
$$

Under the measure $Q$ we have that for $u\ge t$:

$$
Z_u=\log (S_u/s)\sim \mathcal{N}\left(\left(r-\frac{1}{2}\sigma^2\right)(u-t),\sigma\sqrt{u-t}\right)
$$

Hence we may set $u=T$ and observe that

\begin{align*}
F(t,s)&=e^{-r(T-t)}\int_{-\infty}^\infty \Phi(se^z) f(z)\ dz\\
&=e^{-r(T-t)}\int_{-\infty}^\infty (se^z-K)^+ f(z)\ dz\\
&=e^{-r(T-t)}\int_{\log\left(\frac{K}{s}\right)}^{\infty} (se^z-K) f(z)\ dz\\
&=e^{-r(T-t)}\left(s\int_{\log\left(\frac{K}{s}\right)}^{\infty} e^z f(z)\ dz-K\int_{\log\left(\frac{K}{s}\right)}^{\infty} f(z)\ dz\right),
\end{align*}

where we used that $f$ is the distribution function of a normal distributed random variable with mean $(r-\sigma^2/2)(T-t)$ and variance $\sigma\sqrt{T-t}$ and that

$$
(se^z-K)^+ \ge 0\iff se^z\ge K\iff z\ge \log\left(\frac{K}{s}\right)
$$

Using that the MGF of a $X\sim\mathcal{N}(\alpha, \beta^2)$ variable is

$$
E[e^{tX}]=e^{\alpha t+\frac{1}{2}\beta ^2t^2},
$$

and the shorthand $N(t)$ for the distribution function of the standard normal distribution, we have

\begin{align*}
F(t,s)&=e^{-r(T-t)}\left(sE\left[e^{Z_T}1_{Z_T\ge \log\left(\frac{K}{s}\right)}\right]-K P\left(Z_T\ge \log\left(\frac{K}{s}\right)\right)\right)\\
&=e^{-r(T-t)}s\exp\left\{\left(r-\frac{1}{2}\sigma^2\right)(T-t)+\frac{1}{2}\sigma^2(T-t)\right\}E\left[1_{Z_T\ge \log\left(\frac{K}{s}\right)}\right]\\
&-e^{-r(T-t)}K P\left(X\ge\frac{1}{\sigma\sqrt{T-t}}\left( \log\left(\frac{K}{s}\right)-(r-\sigma^2/2)(T-t)\right)\right)\\
&=sE\left[1_{Z_T\ge \log\left(\frac{K}{s}\right)}\right]-e^{-r(T-t)}K P\left(X\le\frac{1}{\sigma\sqrt{T-t}}\left(\log\left(\frac{s}{K}\right)+(r-\sigma^2/2)(T-t)\right)\right)\\
&=sN(d_1(s,t))-e^{-r(T-t)}K N\left(d_2(s,t)\right),
\end{align*}

as desired. $\blacksquare$

</details>

#### Completeness and Hedging

We derived the pricing function of the european call option above and introduced the theory around boundary value problems and Feymann-Kac solution to the partial differential stochastic equation. Now we want to see if a portfolio exists such that it gives the payout $\Phi(S_T)$ with probability one.

In order to do this, we return to the concept of hedge and replication.

<blockquote class = "def">

**Definition 8.1.** We say that a $T$-claim $\mathcal{X}$ can be **replicated**, alternatively the it is **reachable** or **hedgeable**, if there exists a self-financing portfolio $h$ such that

$$
V_T^h=\mathcal{X},\ P-\text{a.s.}\tag{8.1}
$$

In this case we say that $h$ is a **hedge** against $\mathcal{X}$. Alternatively, $h$ is called a **replicating** or **hedging** portfolio. If every contingent claim is reachable we say that the market is **complete**.

</blockquote>

If we can find a portfolio $h$ that reaches $\mathcal{X}$ in value over the time period $[t,T]$ it must mean, that holding the portfolio is equivalent with holding the contract itself. We therefore have the natural assumption that the price process must satisfie $\Pi_t[\mathcal{X}]=V_t^h$ for all $t\ge 0$. How this relates to the absence of arbitrage is given below.

<blockquote class = "prop">

**Proposition 8.2.** Suppose $\mathcal{X}$ is hedged using the portfolio $h$. Then the only price process $\Pi_t[\mathcal{X}]$ which is consistent with no arbitrage is given by $\Pi_t[\mathcal{X}]=V_t^h$. Furthermore, if $\mathcal{X}$ can be hedged by both $h$ and $g$ then $V_t^g=V_t^h$ for all $t$ with probability one.

</blockquote>

##### Completeness in Black-Scholes

The Black-Scholes model will be investegated in the following. We start by stating the important theorem.

<blockquote class = "thm">

**Theorem 8.3.** Consider the Black-Scholes model given by

\begin{align*}
dS_t&=\mu(t,S_t) S_t\ dt+\sigma(t,S_t) S_t\ dW_t,\tag{8.2}\\
dB_t&=r B_t\ dt,\tag{8.3}
\end{align*}

The model above is complete.

</blockquote>

The following lemma gives us replicability of a **simple** claim (which we will restrict ud to).

<blockquote class = "lem">

**Lemma 8.4.** Suppose that there exist an adapted process $V$ and an adapted process $w=[w^B,w^S]$ with $w^B_t+w^S_t=1$ for all $t\ge 0$, such that

\begin{align*}
dV_t&=V_t(w_t^Br+w_t^S\mu(t,S_t))\ dt+V_tw_t^S\sigma(t,S_t)\ dW_t,\\
V_t&=\Phi(S_t).
\end{align*}

Then the claim $\mathcal{X}=\Phi(S_t)$ can be replicated using $w$ as the relative portfolio. The corresponding value process is given by the process $V$ and the absolute portfolio $h$ is given by

$$
h_t^B=\frac{w_t^B V_t}{B_t},\hspace{10pt} h_t^S=\frac{w_t^S V_t}{S_y}.
$$

</blockquote>

Doing some heuristics we come up with some clever weights, which turns on to adhere to the boundary value problem formulated in the Black-Scholes equation. Given that the weights gives rise to the desired value process, we have succesfully found the portfolio weight (see lemma above).

<blockquote class = "thm">

**Theorem 8.5.** Consider the Black-Scholes model given in (8.3)-(8.4), and a simple contingent claim $\mathcal{X}=\Phi(S_t)$. Define $F$ as the solution to the boundary value problem

\begin{align*}
F_t(t,s)+rsF_s(t,s)+\frac{1}{2}s^2\sigma^2F_{ss}(t,s)-rF(t,s)&=0,\\
F(T,s)&=\Phi(s).
\end{align*}

Then $\mathcal{X}$ can be replicated by the relative portfolio

\begin{align*}
w_t^B&=\frac{F(t,S_t)-S_tF_s(t,S_t)}{F(t,S_t)},\\
w_t^S&=\frac{S_tF_s(t,S_t)}{F(t,S_t)}.
\end{align*}

The corresponding absolute portfolio is given by

\begin{align*}
h_t^B&=\frac{F(t,S_t)-S_tF_s(t,S_t)}{B_t},\\
h_t^S&=F_s(t,S_t),
\end{align*}

and the value process $V^h$ is given by

$$
V^h_t=F(t,S_t).
$$

</blockquote>

<blockquote class = "prop">

**Proposition 8.6.** Consider the Black-Scholes model given in (8.3)-(8.4), and a contingent claim on the form $\mathcal{X}=\Phi(S_T,Z_T)$. We define the process $Z_t$ as

$$
Z_t=\int_0^tg(u,S_u)\ du,
$$

for some choice of the deterministic function $g$. Then $\mathcal{X}$ can be replicated using a relative portfolio given by

\begin{align*}
w_t^B&=\frac{F(t,S_t,Z_t)-S_tF_s(t,S_t,Z_t)}{F(t,S_t,Z_t)},\\
w_t^S&=\frac{S_tF_s(t,S_t,Z_t)}{F(t,S_t,Z_t)}.
\end{align*}

where $F$ is the solution to the boundary value problem

\begin{align*}
F_t(t,s,z)+rsF_s(t,s,z)+\frac{1}{2}s^2\sigma^2F_{ss}(t,s,z)-rF(t,s,z)&=0,\\
F(T,s,z)&=\Phi(s,z).
\end{align*}

The corresponding value process is given by $V_t=F(t,S_t,Z_t)$, and $F$ has the stochastic representation

$$
F(t,s,z)=e^{-r(T-t)}E^Q_{t,s,z}[\Phi(S_T,Z_T)],
$$

where the $Q$-dynamics are given by

\begin{align*}
dS_u&=rS_u\ du + S_u\sigma(u,S_u)\ dW^Q_u,\\
S_t&=s,\\
dZ_u&=g(u,S_u)\ du,\\
Z_t&=z.
\end{align*}

</blockquote>

##### Absence of Arbitrage

In general we have conflicting forces when evaluating when a certain market is arbitrage free and/or complete. We have in simple terms the non-rigorous theorem below.

<blockquote class = "thm">

**Meta-theorem 8.3.1.** Let $N$ denote the number of underlying **traded** assets in the model **excluding** the risk free asset, and let $R$ denote the number of random sources driving the price system. Genericallly we then have the following statements.

  * The model is arbitrage free if and only if $N\le R$.
  * The model is complete if and only if $N\ge R$.
  * The model is arbitrage free and complete if and only if $N=R$.

</blockquote>

#### Put-call Parity

The notion of continuous rebalancing the replicating portfolio require leads to problems in the real world. Trading does cost some money (typical in fractions) and so contiuous balancing would make the portfolio go to 0 rather quickly. Why? The Brownian motion has unbounded variation and so we would have to sell and buy the portfolio uncountable many time in any interval and the shift in weight is not neglible. Because of this we would like to see which claims we can replicate by buying and holding a combination of assets and derivatives.

<blockquote class = "prop">

**Proposition 10.1.** Let $\Phi$ and $\Psi$ be contract functions for the $T$-claims $\mathcal{X}=\Phi(S_T)$ and $\mathcal{Y}=\Psi(S_T)$. Then for any real numbers $\alpha$ and $\beta$ we have the following price relation:

$$
\Pi_t[\alpha \Phi + \beta\Psi]=\alpha \Pi_t[\Phi]+\beta\Pi_t[\Psi].
$$

</blockquote>

If we consider the basic contract functions

\begin{align*}
\Phi_S(x)=x,&\ \Phi_B(x)=1,\\
\Phi_{C,K}(x)=(x-K)^+,&\ \Phi_{P,K}(x)=(K-x)^+.
\end{align*}

That is a contract paying (respectively): the price of one stock, 1 dollar, one european call and one european put both with strike $K$. It is clear that the following prices are

\begin{align*}
\Pi_t[\Phi_S]=S_t,&\ \Pi_t[\Phi_B]=e^{-r(T-t)},\\
\Pi_t[\Phi_{C,K}]=c(t,S_t;K,T),&\ \Pi_t[\Phi_{P,K}]=p(t,S_t;K,T).
\end{align*}

Where $c(t,s,K,T,r,\sigma)$ and $p(t,s,K,T,r,\sigma)$ are the pricing function of the european call and put option. We see that we can replicate these payouts by: buying the stock today and selling at time $T$, buying a zero coupon $T$-bond with face value 1, buying the call and put option.

Then we can by choosing $\alpha,\beta,\gamma_1,...,\gamma_n$ form a portfolio consisting of $\alpha$ stocks, $\beta$ $T$-bonds and $\gamma_i$ call options with maturity $T$ and strike $K_i$. The price is then a linear combination given the choice (se proposition 10.1).

The put option is not includet in the above portfolio as we have the put-call parity below

<blockquote class = "prop">

**Proposition 10.2.** **(Put-call parity)** Consider a European call and a European put, both with strike $K$ and time of maturity $T$. Then we have the relation.

$$
p(t,s) = Ke^{-r(T-t)}+c(t,s)-s.
$$

In particular the put option can be replicated by a constant portfolio consisting of $K$ zero coupon $T$-bonds, a European call option and a single short position in the underlying stock.

</blockquote>

We now have the pleasing proposition given the class of claims we can reach with the buy-and-hold portfolio with $T$-bonds, stock and call options

<blockquote class = "prop">

**Proposition 10.3.** Fix an arbitrary continuous contract function $\Phi$ with compact support. Then the corresponding contract can be replicated with arbitrary precision (in sup-norm) using a constant portfolio consisting only of bonds, call options and the underlying stock.

</blockquote>

#### The Greeks

When holding a portfolio we may denote the pricing function by $P(t,s)$. Here we only have one **underlying** asset with price process $S_t$. We now have two types of risk:

  * Price changes in the underlying asset.
  * Misspecifications in the model parameters.

These two risk give rise to "the greeks" as defined below.

<blockquote class = "def">

**Definition 10.4.** The greeks of a portfolio is given by

$$
\Delta=\frac{\partial P}{\partial s},\ \Gamma=\frac{\partial^2 P}{\partial s^2},\ \rho=\frac{\partial P}{\partial r},\ \Theta=\frac{\partial P}{\partial t},\ \mathcal{V}=\frac{\partial P}{\partial s}.
$$

</blockquote>

For the call option in particular we have the following derivatives.

<blockquote class = "prop">

**Proposition 10.5.** The greeks of a portfolio consisting of a single European call option with maturity $T$ and strike price $K$ have the following greeks ($\varphi$ denoting the density function of a $\mathcal{N}(0,1)$-variable):

\begin{align*}
\Delta&=N(d_1),\\
\Gamma&=\frac{\varphi(d_1)}{s\sigma\sqrt{T-t}},\\
\rho&=K(T-t)e^{-r(T-t)}N(d_2),\\
\Theta&=-\frac{s\varphi(d_1)\sigma}{2\sqrt{T-t}}-rKe^{-r(T-t)}N(d_2),\\
\mathcal{V}&=s\varphi(d_1)\sqrt{T-t}.
\end{align*}

</blockquote>

#### Risk Neutral Valuation Formula

We have the setting of a market consisting of the assets $S^0,...,S^N$ of $N+1$ assets. We consider the numeraire $S^0$ being a risk free asset. We introduce a price of contingent claim $X$, such that the extended market consisting of the price process of $X$ and the $N+1$ assets is arbitrage free. Alternatively, we can, equivalently, find a replicating portfolio $h$ such that $V^h_T=X$ with probability one.

<blockquote class = "thm">

**Theorem 11.18.** **(General Pricing Equation)** The arbitrage free price process for the $T$-claim $X$ is given by

$$
\Pi_t[X]=S_t^0E^Q\left[\left.\frac{X}{S^0_T}\right\vert \mathcal{F}_t\right],
$$

where $Q$ is the (not necessarily unique) martingale measure for the a priori given market $S^0,S^1,...,S^N$, with $S^0$ as the numeraire.

</blockquote>

If if we assume that the bank account takes the form

$$
S_t^0=S_0^0e^{-\int_0^tr(s)\ ds},
$$

where $r$ is the short rate, then we have the familier *risk neutral valuation formula*.

<blockquote class = "thm">

**Theorem 11.19.** **(Risk Neutral Valuation Formula)** Assuming the existance of a short rate, the pricing formula takes the form

$$
\Pi_t[X]=E^Q\left[\left.e^{-\int_0^Tr(s)\ ds}X\right\vert \mathcal{F}_t\right],
$$

where $Q$ is the (not necessarily unique) martingale measure with the bank account as the numeraire.

</blockquote>

<blockquote class = "def">

**Definition 11.20.** A **zero coupon bond** with **maturity date** $T$, also called a $T$-bond, is a contract which guarantees the holder one dollar to be paid on the date $T$. The price at time $t$ of a bond with maturity date $T$ is denoted by $p(t,T)$.

</blockquote>

<blockquote class = "prop">

**Proposition 11.21.** The price of a zero coupon $T$-bond is given by

$$
p(t,T)=E^Q\left[\left.e^{-\int_t^Tr(s)\ ds}\right\vert \mathcal{F}_t\right],
$$

and in particular we have $p(T,T)=1$ for all $T\ge 0$.

</blockquote>

#### Equivalent Probability Measures

##### The Radon-Nikodym Theorem

<blockquote class = "def">

**Definition A.50.** Consider a measurable space $(X,\mathcal{F})$ on which there are defined two seperate measures $\mu$ and $\nu$:

  * If, for all $A\in \mathcal{F}$, it holds that
  $$
  \mu(A)=0\ \Rightarrow\ \nu(A)=0,
  $$
  then $\nu$ is said to be **absolutely continuous** with respect to $\mu$ on $\mathcal{F}$ and we write this as $\nu < < \mu$.
  * If we have both $\mu << \nu$ and $\nu << \mu$, then $\mu$ and $\nu$ said to be **equivalent** and we write $\mu\sim \nu$.
  * If there exists two events, $A$ and $B$ such that:
    
    * $A\cup B=X$,
    * $A\cap B=\emptyset$,
    * $\mu(B)=0$, and $\nu(A)=0$,
    
    then $\nu$ and $\mu$ are said to be mutually **singular**, and we write $\mu\ \bot\ \nu$.

</blockquote>

<blockquote class = "thm">

**Theorem A.52.** **(The Radon-Nikodym Theorem)** Consider the measure space $(X,\mathcal{F},\mu)$, where we assume that $\mu$ is finite, i.e. that $\mu(X)<\infty$. Let $\nu$ be a measure on $(X,\mathcal{F})$ such that $\nu <<\mu$ on $\mathcal{F}$. Then there exists a non-negative function $f : X\to \mathbb{R}$ such that:

\begin{align*}
&f\ \text{is}\ \mathcal{F}\text{-measurable}\\
&\int_X f(x)\ d\mu(x)<\infty,\\
&\nu(A)=\int_Af(x)\ d\mu(x),\ \text{for all}\ A\in \mathcal{F}.
\end{align*}

The function $f$ is called the **Radon-Nikodym derivative** of $\nu$ w.r.t. $\mu$. It is uniquely determined $\mu$-a.e. and we write

$$
f(x)=\frac{d\nu(x)}{d\mu(x)},
$$

or alternatively

$$
d\nu(x)=f(x)\ d\mu(x).
$$

</blockquote>

##### EPM

<blockquote class = "lem">

**Lemma B.38.** For two probability measures $P$ and $Q$, the relation $P\sim Q$ on $\mathcal{F}$ holds if and only if $P(A)=1$ if and only if $Q(A)=1$ for all $A\in\mathcal{F}$.

</blockquote>

<blockquote class = "prop">

**Proposition B.39.** Assume that $Q << P$ on $\mathcal{F}$ and that $\mathcal{G}\subseteq \mathcal{F}$. Then the Radon-Nikodym derivatives $L^\mathcal{F}$ and $L^\mathcal{G}$ are related by

$$
L^\mathcal{G}=E^P[L^\mathcal{F}\ \vert\ \mathcal{G}].
$$

</blockquote>

<blockquote class = "prop">

**Proposition B.41.** **(Bayes' Theorem)** Assume that $X$ is a random variable on $(\Omega, \mathcal{F},P)$, and let $Q$ be another probability measure on $(\Omega,\mathcal{F})$ the Radon-Nikodym derivative

$$
L=\frac{d Q}{dP}
$$

on $\mathcal{F}$. Assume that $X\in L^1(\Omega,\mathcal{F},Q)$ and $\mathcal{G}$ is a sigma-algebra with $\mathcal{G}\subseteq \mathcal{F}$. Then

$$
E^Q[X\ \vert\ \mathcal{G}]=\frac{E^P[L\cdot X\ \vert\ \mathcal{G}]}{E^P[L\ \vert\ \mathcal{G}]},\ Q-a.s.
$$

</blockquote>

##### Likelihood processes

<blockquote class = "prop">

**Proposition C.12.** Consider a filtered probability space $(\Omega, \mathcal{F},P,\mathcal{F}_t)$ on a compact interval $[0,T]$. Suppose $L_T$ is some non-negative integrable random variable in $\mathcal{F}_T$. We can then define a new measure $Q$ on $\mathcal{F}_T$ by setting

$$
dQ=L_T\ dP
$$

on $\mathcal{F}_T$ and if $E^P[L_T]=1$ the measure $Q$ will also be a probability measure. The likelihood process $L$, defined by

$$
L_t=\frac{dQ}{dP},\ on\ \mathcal{F}_t,
$$

is a $(P,\mathcal{F}_t)$-martingale.

</blockquote>

<blockquote class = "prop">

**Proposition C.13.** A process $M$ is a $Q$-martingale if and only if the process $L\cdot M$ is a $P$-martingale.

</blockquote>

### Exercises week 4

## Week 5

### Table of Contents

  * [Martingale representation theorem (Chapter 12)](#martingale-representation-theorem)
  * [Girsanov theorem (Chapter 12, see also Levy characterization of Brownian motion and proof of Girsanov)](#girsanov-theorem)

  * [Exercises](#exercises-week-5)

### Theory


#### Martingale representation theorem

<blockquote class = "thm">

**Theorem 12.1.** **(Representation of Brownian Functionals)** Let $W$ be a $d$ dimensional Brownian motions, and let $X$ be a random variable such that

  * $X\in\mathcal{F}^W_T$,
  * $E[\vert X\vert]<\infty$.

Then there exist uniquely determined $\mathcal{F}^W_t$-adapted processes $h^1,...,h^d$, such that $X$ has the representation

$$
X=E[X]+\sum_{i=1}^d\int_0^Th^i_s\ dW_s^i.
$$

Under the additional assumption

$$
E[X^2]<\infty,
$$

then $h^1,...,h^d$ are in $\mathcal{L}^2$.

</blockquote>

<blockquote class = "thm">

**Theorem 12.2.** **(The Martingale Representation Theorem)** Let $W$ be a $d$ dimensional Brownian motions, and assume that the filtration $\mathbf{F}$ is defined as

$$
\mathcal{F}_t=\mathcal{F}^W_t,\hspace{20pt}t\in[0,T].
$$

Let $M$ be any $\mathcal{F}_t$-adapted martingale. Then there exist uniquely determined $\mathcal{F}_t$-adapted processes $h^1,...,h^d$ such that $M$ has the representation

$$
M_t=M_0+\sum_{i=1}^d\int_0^t h_s^i\ dW_s^i,\hspace{20pt}t\in[0,T].
$$

If the martingale $M$ is square integrable, then $h^1,...,h^d$ are in $\mathcal{L}^2$.

</blockquote>

#### Girsanov theorem

<blockquote class = "thm">

**Theorem 12.3.** **(The Girsanoc Theorem)** Let $W$ be a $d$ dimensional $P$-Brownian motion on $(\Omega,\mathcal{F},P,\mathbf{F})$ and let $\varphi$ be any $d$-dimensional adapted column vector process. Choose a fixed $T$ and define the process $L$ on $[0,T]$ by

\begin{align*}
dL_t&=\varphi^\top_t L_t\ dW_t,\\
L_0&=1,
\end{align*}

i.e.

$$
L_t = \exp\left\{\int_0^t \varphi^\top_s\ dW_s - \frac{1}{2}\int_0^t \Vert\varphi_s\Vert ^2\ ds\right\}.
$$

Assume that

$$
E^P[L_T]=1,
$$

and define the new probability measure $Q$ on $\mathcal{F}_T$ by

$$
L_T=\frac{dQ}{dP},\hspace{15pt}on\ \mathcal{F}_T.
$$

Then

$$
dW_t=\varphi\ dt+dW_t^Q,
$$

where $W^Q$ is a $d$ dimensional $Q$-Brownian motion or equivalently

$$
W_t^Q=W_t-\int_0^t\varphi_s\ ds
$$

is a standard $Q$-Brownian motion.

</blockquote>

We will often refere to $\varphi$ as the **Girsanov kernel** of the measure transformation. Furthermore, we have written on component form above and the $L$ dynamics will have the form

$$
dL_t=L_t\sum_{i=1}^d\varphi^i_t\ dW_t^i,
$$

and $L$ will have the explicit form

$$
L_t=\exp\left\{\sum_{i=1}^d\int_0^t\varphi^i_s\ dW_s^i - \frac{1}{2}\int_0^d\sum_{i=1}^d(\varphi^i_s)^2\ ds\right\}.
$$


The conclusion of the Girsanov Theorem is thwn that we can write

$$
dW_t^i=\varphi_t^i\ dt+dW_t^{Q,i},
$$

for $i=1,...,d$ where $W_t^{Q,1},...,W_t^{Q,d}$ are independent standard Brownian motions under $Q$.

<blockquote class = "def">

**Definition 12.4.** For any Brownian motion $W$ and any kernel process $\varphi$, the **Doleans exponintial** process $\mathcal{E}$ is defined by

$$
\mathcal{E}(\varphi\bullet W)_t=\exp\left\{\int_0^t\varphi^\top_s\ dW_s -\frac{1}{2}\int_0^t\Vert \varphi\Vert^2_s\ ds\right\}.
$$

</blockquote>

<blockquote class = "lem">

**Lemma 12.5.** **(The Novikov Condition)** Assume that the Girsanov kernel $\varphi$ is such that

$$
E^P\left[e^{\frac{1}{2}\int_0^T\Vert \varphi_t\Vert^2\ dt}\right]<\infty.
$$

Then $L$ is a martingale and in particular $E^P[L_T]=1$.

</blockquote>

<blockquote class = "thm">

**Theorem 12.5.** **(The Converse of the Girsanov Theorem)** Let $W$ be a $d$-dimensional standard $P$-Brownian motion on $(\Omega,\mathcal{F},P,\mathbf{F})$ and assume that

$$
\mathcal{F}_t=\mathcal{F}^W_t,\ \forall t.
$$

Assume that there exists a probability measure $Q$ such that $Q<<P$ on $\mathcal{F}_T$. Then there exists an adapted process $\varphi$ such that the likelihood process $L$ has the dynamics

\begin{align*}
dL_t&=L_t\varphi^\top_t\ dW_t,\\
L_0&=1.
\end{align*}

</blockquote>

This gives us a recipe to tranform dynamics of Ito processes under the measure $Q$ as we may rewrite the dynamics of the Brownian motion. We therefore have for an Ito process $X$ with dynamics

$$
dX_t=\mu(t,X_t)X_t\ dt+\sigma(t,X_t) X_t\ dW_t,
$$

may be transformed under $Q$ as

\begin{align*}
dX_t&=\mu(t,X_t)X_t\ dt+\sigma(t,X_t) X_t\ dW_t\\
&=\mu(t,X_t)X_t\ dt+\sigma(t,X_t) X_t\ (\varphi_t\ dt+dW_t^Q)\\
&=\left(\mu(t,X_t) + \varphi_t\right) X_t\ dt + \sigma(t,X_t)X_t\ dW_t^Q.
\end{align*}

This may lead us into deducing that

$$
\mu(t,X_t)+\sigma(t,X_t)\varphi_t=r_t\iff\varphi_t=\frac{r_t-\mu(t,X_t)}{\sigma(t,X_t)}.
$$

### Exercises Week 5

## Week 6

### Table of Contents

  * [Black-Scholes model, martingale approach (Chapter 13)](#black-scholes-model-martingale-approach)
  * [Multidimensional models (Chapter 14)](#multidimensional-models)

  * [Exercises](#exercises-week-6)

### Theory

#### Black-Scholes model - martingale approach

#### Multidimensional models

### Exercises Week 6

## Week 7

### Table of Contents

  * [Pricing and proof of fundamental pricing theorem I and II (Chapter 11)](#fundamental-pricing-theorem-i-and-ii)
  * [Incomplete Markets (Chapter 9)](#incomplete-markets)

  * [Exercises](#exercises-week-7)

### Theory

#### Fundamental pricing theorem I and II

We start by stating the following theorem.

<blockquote class = "thm">

**Theorem 11.1.** If at least on of the assets $S^1,...,S^N$ has diffusion term which is non-zero at all times, and if naive portfolio strategies are admitted, then the model admits arbitrage.

</blockquote>

We will go as follows. Derive the fundamental pricing theorem 1 and 2 in a setting with zero interest rate. Then we will extend the result in general by choosing a simple numeraire. We start by defining some basic notation.

<blockquote class = "def">

**Definition 11.2.** Define the process $h$ as

$$
h=[h^0,h^S]:=[h^0,h^1,...,h^N]
$$

We define the following.

  * For a process $h$, its **value process** $V_t^h$ is defined by
  $$
  V_t^h=h^0_t\cdot 1+\sum_{i=1}^Nh_t^iS_t^i,
  $$
  or in compact form
  $$
  V_t^h=h_t^0\cdot 1 + h_t^S S_t
  $$
  * An adapted process $h^S$ is called **admissible** if there exists a non-negative real number $\alpha$ (which may depend on the choice of $h^S$) such that
  $$
  \int_0^th_u^SdS_u\ge -\alpha,
  $$
  for all $t\in[0,T]$. A process $h$, is called an **admissible portfolio** process if $h^S$ is admissible.
  * An admissible portfolio is said to be **self-financing**, if
  $$
  V_t^h=V_0^h+\int_0^th_u^S\ dS_u,
  $$
  i.e. if
  $$
  dV_t^h=h_t^S\ dS_t.
  $$

</blockquote>

<blockquote class = "lem">

**Lemma 11.3.** For any adapted process $h^S$ satisfying the admissibility condition above, and for any real number $x$, there exists a unique adapted process $h^0$, such that:

  * The process $h$ defined by $h=[h^0,h^S]$ is self-financing.
  * The value process is given by
  $$
  V_t^h=x+\int_0^th_u^S\ dS_u.
  $$

In particular, the space $\mathcal{K}_0$ of portfolio values, reachable at time $T$ by means of a self-financing portfolio with zero initial cost is given by

$$
\mathcal{K}_0=\left\{\int_0^Th_t^S\ dS_u :\ h^S\ \text{is admissible}\right\}.
$$

</blockquote>

<blockquote class = "def">

**Definition 11.4.** A probability measure $Q$ on $\mathcal{F}_T$ is called **equivalent martingale measure** for the market model, the numeraire $S^0$, and the time interval $[0,T]$, if it has the following properties:

  * $Q\sim P$ on $\mathcal{F}_T$, so $P$ and $Q$ are equivalent.
  * All price processes $S^0,S^1,...,S^N$ are martingales under $Q$ on the time interval $[0,T]$.

An equivalent martingale measure will often be referred to as just "a martingale measure" or as "an EMM". If $Q\sim P$ has the property that $S^0,S^1,...,S^N$ are local martingales, then $Q$ is called a **local martingale measure**.

</blockquote>

<blockquote class = "thm">

**Theorem 11.5.** **(The First Fundamental Theorem)** The model is arbitrage free "essentially" if and only if there existis a (local) martingale measure $Q$.

</blockquote>

<blockquote class = "def">

**Definition 11.6.** With the notation above, we say that the model admits

  * **No Arbitrage** (NA) if
  $$
  \mathcal{C}\cap L_+^\infty=\{0\},
  $$
  * **No Free Lunch with Vanishing Risk** (NFLVR) if
  $$
  \tilde{\mathcal{C}}\cap L_+^\infty=\{0\},
  $$
  where $\tilde{\mathcal{C}}$ denotes the closure of $\mathcal{C}$ in $L^\infty$.

</blockquote>

<blockquote class = "thm">

**Theorem 11.7.** **(Kreps-Yan Separation Theorem)** If $\mathcal{C}$ is weak* closed, and if

$$
\mathcal{C}\cap L_+^\infty=\{0\},
$$

then there exists a random variable $L\in L^1$ such that $L$ is $P$ almost surely strictly positive, and 
$$
E^P[L\cdot X]\le 0,
$$

for all $X\in\mathcal{C}$.

</blockquote>

<blockquote class = "prop">

**Proposition 11.8.** If the asset price processes are uniformly bounded, then the condition NFLVR implies that $\mathcal{C}$ is weak* closed.

</blockquote>

<blockquote class = "thm">

**Theorem 11.9.** **(First Fundamental Theorem)** Assume that the asset price process $S$ is bounded. Then there exists an equivalent martingale measure if and only if the model satisfies NFLVR.

</blockquote>

<blockquote class = "thm">

**Theorem 11.10.** **(First Fundamental Theorem)** Assume that the asset price process $S$ is locally bounded. Then there exists an equivalent martingale measure if and only if the model satisfies NFLVR.

</blockquote>

**Assumption 11.4.1.** *We assume that *$S_t^0>0$ $P$*-a.s. for all *$t\ge 0$.

<blockquote class = "def">

**Definition 11.11.** The **normalized economy** (also referred to as the "Z-economy") is defined by the price vector process $Z$, where

$$
Z_t=\frac{S_t}{S_t^0}.
$$

</blockquote>

<blockquote class = "def">

**Definition 11.12.**

  * A **portfolio stragegy** is any adapted $(N+1)$-dimensional process
  $$
  h_t=[h_t^0,h_t^1,...,h_t^N].
  $$
  * The **S-value process** $V_t^S$ corresponding to the portfolio $h$ is $h_tS_t$.
  * The **Z-value process** $V_t^Z$ corresponding to the portfolio $h$ is $h_tZ_t$.
  * A portfolio is said to be **admissible** if it is admissible as an $Z$ portfolio.
  * An admissible portfolio is **S-self-balancing** if
  $$
  dV_t^S=\sum_{i=0}^Nh_t^i\ dS_t^i
  $$
  * An admissible portfolio is **Z-self-balancing** if
  $$
  dV_t^Z=\sum_{i=0}^Nh_t^i\ dZ_t^i.
  $$

</blockquote>

<blockquote class = "lem">

**Lemma 11.13.** **(Invariance Lemma)** With assumptions as above, the following hold.

  i. A portfolio $h$ is S-self-financing if and only if it is Z-self-financing.
  ii. The value processes $V^S$ and $V^Z$ are connected by
  $$
  V_t^Z=\frac{1}{S_t^0}\cdot V_t^S.
  $$
  iii. A claim $\mathcal{Y}$ is S-replical if and only if the claim
  $$
  \frac{\mathcal{Y}}{S_T^0}
  $$
  is Z-replicable.
  iv. The model is S arbitrage free if and only if it is Z arbitrage free.

</blockquote>

<blockquote class = "thm">

**Theorem 11.14.** **(The First Fundamental Theorem)** Consider the market model $S^0,S^1,...,S^N$ where we assume that $S^0_t>0$, $P$-a.s. for all $t\ge 0$. Assume furthermore that $S^0,S^1,...,S^N$ are locally bounded. Then the followin conditions are equivalent:

  * The model satisfies NFLVR.
  * There exists a measure $Q\sim P$ such that the processes
  $$
  Z^0,Z^1,...,Z^N,
  $$
  are local martingales under $Q$.

</blockquote>

##### Completeness

<blockquote class = "lem">

**Lemma 11.15.** Consider a given $T$-claim $X$. Fix a martingale measure $Q$ and assume that the normalized claim $X/S^0_T$ is integrable. If the $Q$-martingale $M$, defined by

$$
M_t=E^Q\left[\left. \frac{X}{S^0_T}\right\vert \mathcal{F}_t\right],
$$

admits an integral representation of the form

$$
M_t=x+\sum_{i=1}^N\int_0^th_s^i\ dZ_s^i,
$$

then $X$ can be hedged in the S-economy. Furthermore, the replicating portfolio $(h^0,h^1,...,h^N)$ is given by the above for $h^i$, $i=1,...,N$ and $h_t^0=M_t-\sum_{i=1}^Nh_t^iZ_t^i$.

</blockquote>

<blockquote class = "thm">

**Theorem 11.16.** **(Jacod)** Let $\mathcal{M}$ denote the convex set of equivalent martingale measures. Then, for any fixed $Q\in\mathcal{M}$, the following statements are equivalent:

  * Every $Q$ local martingale $M$ has dynamics of the form
  $$
  dM_t=\sum_{i=1}^Nh_s^i\ dZ_s^i.
  $$
  * $Q$ is an extremal point of $\mathcal{M}$.

</blockquote>

<blockquote class = "thm">

**Theorem 11.17.** **(The Second Fundamental Theorem)** Assume that the market is arbitrage free and consider a fixed numeraire asset $S^0$. Then the market is complete if and onlt if the martingale measure $Q$, corresponding to the numeraire $S^0$, is unique.

</blockquote>

##### Stochastic Discount Factors

<blockquote class = "def">

**Definition 11.22.** Assume the existance of a short rate $r$. For any fixed martingale measure $Q$, let the likelihood process $L$ be defined by

$$
L_t=\frac{dQ}{dP},\ on\ \mathcal{F}_t.
$$

The **stochastic discount factor** (SDF) process $\mathbf{M}$, corresponding to $Q$, is defined as

$$
\mathbf{M}_t=e^{-\int_0^tr(s)\ ds}L_t\ \ \left(=\frac{1}{B_t}\cdot L_t\right).
$$

</blockquote>

<blockquote class = "prop">

**Proposition 11.23.** Assume absence of arbitrage. With notation as above, the following hold:

  * For any sufficiently integrable $T$-claim $X$, the arbitrage free price is given by
  $$
  \Pi_t[X]=E^P\left[\left. \frac{\mathbf{M}_T}{\mathbf{M}_t} X \ \right\vert\ \mathcal{F}_t\right].
  $$
  * For any arbitrage free asset price process $S$ (derivative or underlying) the process $\mathbf{M}_tS_t$ is a (local) $P$-martingale.
  * The $P$-dynamics of $\mathbf{M}$ are given by
  $$
  d\mathbf{M}_t=-r_t\mathbf{M}_t\ dt+\frac{1}{B_t}\ dL_t.
  $$

</blockquote>

##### Summary

<blockquote class = "thm">

**Theorem 11.24.**

</blockquote>

<blockquote class = "prop">

**Proposition 11.25.**

</blockquote>

<blockquote class = "thm">

**Theorem 11.26.**

</blockquote>

<blockquote class = "prop">

**Proposition 11.27.**

</blockquote>

#### Incomplete Markets

We assume a market with a risk free asset and one risky assets with dynamics

$$
dX_t=\mu(t,X_t)\ dt+\sigma(t,X_t)\ dW_t.
$$

We want to find a unique price of a derivative on a functional form of the risky asset. We assume that we cannot invest in the asset representing the process $X_t$ and so we can solely write contracts based on the observation $X_T$. The problem here is that we can only short or long the risk free asset and so no derivative is replicable.

The way we solve this problem is by having the market set the price of risk and universally price derivatives based on this given price process. We then have the assumptions

**Assumption 9.2.1** We have the market given with the only investable asset $B$ with dynamics

$$
dB_t=rB_t\ dt.
$$

We furthermore, have an empirically observable stochastic process $X$ which is **not** the price process of any traded asset. The $P$-dynamics of $X$ is given by

$$
dX_t=\mu(t,X_t)\ dt+\sigma(t,X_t)\ dW_t.
$$

**Assumption 9.2.2** There is a liquid market for every contingent claim.

**Assumption 9.2.3** We assume that

  * There is a liquid, frictionless market for each of the contingent claims $\mathcal{Y}$ and $\mathcal{Z}$.
  * The market prices of the claims are of the form
  $$ \Pi_t[\mathcal{Y}] = F(t,X_t),$$
  $$ \Pi_t[\mathcal{Z}] = G(t,X_t),$$
  where $F$ and $G$ are smooth real valued function.

From Ito's formula we have the dynamics

\begin{align*}
dF=\mu_F F\ dt+\sigma_F F\ dW,\\
dG=\mu_G G\ dt+\sigma_G G\ dW.
\end{align*}

Where the processes $\mu_F$ and $\sigma_F$ are given by

\begin{align*}
\mu_F&=\frac{F_t+\mu F_x+\frac{1}{2}\sigma^2 F_{xx}}{F},\\
\sigma_F&=\frac{\sigma F_x}{F}.
\end{align*}

By forming a portfolio of the two contracts we lead to the relation.

$$
\frac{\mu_F-r}{\sigma_F}=\frac{\mu_G-r}{\sigma_G}.
$$

This gives the important insight.

<blockquote class = "prop">

**Proposition 9.1.** Assume that the market for derivatives is free of arbitrage. Then there exists a universal process $\lambda(t,X_t)$ such that, with probability one, and for all $t$, we have

$$
\frac{\mu_F(t,X_t)-r}{\sigma_F(t,X_t)}=\mu(t,X_t),
$$

regardless of the specific choice of the derivative $F$.

</blockquote>

<blockquote class = "prop">

**Proposition 9.2.** Assume absence of arbitrage, the pricing function $F(t,x)$ of the $T$-claim $\Phi(X_T)$ solves the following boundary value problem.

\begin{align*}
F_t(t,x)+\mathcal{A}F(t,x)-rF(t,x)&=0,\hspace{15pt}&(t,x)\in (0,T)\times \mathbb{R},\\
F(T,x)&=\Phi(x), &x\in\mathbb{R},
\end{align*}

where

$$
\mathcal{A}F(t,x)=\left\{\mu(t,x)-\lambda(t,x)\sigma(t,x)\right\}F_x(t,x)+\frac{1}{2}\sigma^2(t,x)F_{xx}(t,x).
$$

</blockquote>

<blockquote class = "prop">

**Proposition 9.3.** **(Risk neutral valuation)** Assuming absence of arbitrage, the pricing function $F(t,x)$ of the $T$-claim $\Phi(X_T)$ is given by the formula

$$
F(t,x)=e^{-r(T-t)}E^Q_{t,x}[\Phi(X_T)].
$$

The dynamics of $X$ under the martingale measure $Q$ are given by

$$
dX_t=\left\{\mu(t,x)-\lambda(t,x)\sigma(t,x)\right\}F_x(t,x)+\sigma(t,x)\ dW^Q_t,
$$

where $W^Q$ is a $Q$-Brownien motion.

</blockquote>

### Exercises Week 7
